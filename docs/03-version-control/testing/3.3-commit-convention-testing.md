# 3.3 커밋 컨벤션 구현 테스팅

## 📋 개요

**목표**: 3.3에서 구현한 커밋 컨벤션이 올바르게 작동하는지 검증  
**소요 시간**: 1-2시간  
**난이도**: 중급

WSL Ubuntu 환경에서 Docker 기반으로 커밋 컨벤션 구현 상태를 체계적으로 테스트합니다.

---

## 🧪 테스트 환경 준비

### 테스트 실행 환경 설정

```bash
# WSL Ubuntu에서 실행
cd /mnt/c/dev/movie-mlops

# 커밋 컨벤션 관련 패키지 설치 확인
pip install commitizen>=3.29.1,<4.0.0
pip install conventional-pre-commit>=3.4.0,<4.0.0
pip install pre-commit>=4.0.1,<5.0.0

# 테스트 디렉터리 이동
cd docs/03-version-control/testing
```

---

## 🎯 1. Commitizen 설치 및 설정 테스트

### 1.1 Commitizen 기본 기능 테스트

```bash
# Commitizen 설치 및 설정 테스트
cat > test_commitizen_setup.py << 'EOF'
#!/usr/bin/env python3
"""
Commitizen 설치 및 설정 테스트
"""
import subprocess
import sys
import json
from pathlib import Path

class CommitizenSetupTest:
    
    def test_commitizen_installation(self):
        """Commitizen 설치 확인"""
        print("🧪 Commitizen 설치 확인...")
        
        try:
            result = subprocess.run(['cz', 'version'], capture_output=True, text=True)
            if result.returncode == 0:
                version = result.stdout.strip()
                print(f"  ✅ Commitizen 설치됨: {version}")
                return True
            else:
                print("  ❌ Commitizen 실행 실패")
                return False
        except FileNotFoundError:
            print("  ❌ Commitizen이 설치되지 않음")
            return False
    
    def test_pyproject_toml_config(self):
        """pyproject.toml 설정 확인"""
        print("\n🧪 pyproject.toml 설정 확인...")
        
        pyproject_path = Path("../../../pyproject.toml")
        
        if not pyproject_path.exists():
            print(f"  ❌ pyproject.toml 파일 없음: {pyproject_path}")
            return False
        
        try:
            # TOML 내용 읽기 (간단한 파싱)
            content = pyproject_path.read_text()
            
            required_sections = [
                "[tool.commitizen]",
                "name = \"cz_conventional_commits\"",
                "message_template",
                "schema_pattern"
            ]
            
            missing_sections = []
            for section in required_sections:
                if section not in content:
                    missing_sections.append(section)
            
            if missing_sections:
                print(f"  ❌ 누락된 설정: {missing_sections}")
                return False
            else:
                print("  ✅ pyproject.toml 설정 완료")
                return True
                
        except Exception as e:
            print(f"  ❌ pyproject.toml 읽기 실패: {e}")
            return False
    
    def test_commitizen_config(self):
        """Commitizen 설정 확인"""
        print("\n🧪 Commitizen 설정 확인...")
        
        try:
            result = subprocess.run(['cz', 'info'], capture_output=True, text=True)
            if result.returncode == 0:
                output = result.stdout
                if "cz_conventional_commits" in output:
                    print("  ✅ Commitizen 설정 로드됨")
                    return True
                else:
                    print("  ❌ Commitizen 설정 문제")
                    return False
            else:
                print(f"  ❌ Commitizen 설정 확인 실패: {result.stderr}")
                return False
        except Exception as e:
            print(f"  ❌ Commitizen 설정 확인 오류: {e}")
            return False
    
    def test_mlops_commit_types(self):
        """MLOps 특화 커밋 타입 확인"""
        print("\n🧪 MLOps 커밋 타입 확인...")
        
        expected_types = [
            'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore',
            'perf', 'ci', 'revert', 'data', 'model', 'pipeline', 'deploy',
            'config', 'infra', 'monitor'
        ]
        
        # pyproject.toml에서 커밋 타입 확인
        pyproject_path = Path("../../../pyproject.toml")
        
        if not pyproject_path.exists():
            print("  ❌ pyproject.toml 파일 없음")
            return False
        
        try:
            content = pyproject_path.read_text()
            
            # MLOps 특화 타입들이 포함되어 있는지 확인
            mlops_types = ['data', 'model', 'pipeline', 'deploy', 'config', 'infra', 'monitor']
            found_types = []
            
            for mlops_type in mlops_types:
                if f'"{mlops_type}"' in content or f"'{mlops_type}'" in content:
                    found_types.append(mlops_type)
            
            if len(found_types) >= 5:  # 대부분의 MLOps 타입이 있어야 함
                print(f"  ✅ MLOps 커밋 타입 설정됨: {found_types}")
                return True
            else:
                print(f"  ❌ MLOps 커밋 타입 부족: {found_types}")
                return False
                
        except Exception as e:
            print(f"  ❌ MLOps 커밋 타입 확인 실패: {e}")
            return False
    
    def run_all_tests(self):
        """모든 테스트 실행"""
        print("🚀 Commitizen 설정 테스트 시작...\n")
        
        tests = [
            ("Commitizen 설치", self.test_commitizen_installation),
            ("pyproject.toml 설정", self.test_pyproject_toml_config),
            ("Commitizen 설정", self.test_commitizen_config),
            ("MLOps 커밋 타입", self.test_mlops_commit_types),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed += 1
                    print(f"✅ {test_name} 테스트 통과\n")
                else:
                    print(f"❌ {test_name} 테스트 실패\n")
            except Exception as e:
                print(f"💥 {test_name} 테스트 오류: {e}\n")
        
        # 결과 요약
        print("📊 Commitizen 설정 테스트 결과:")
        print(f"  통과: {passed}/{total}")
        print(f"  성공률: {(passed/total*100):.1f}%")
        
        return passed == total

if __name__ == "__main__":
    tester = CommitizenSetupTest()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
EOF

chmod +x test_commitizen_setup.py

# 테스트 실행
echo "🧪 Commitizen 설정 테스트 실행..."
python test_commitizen_setup.py
```

---

## 🎯 2. Pre-commit Hook 테스트

### 2.1 Pre-commit 설치 및 설정 테스트

```bash
# Pre-commit Hook 테스트
cat > test_precommit_hooks.py << 'EOF'
#!/usr/bin/env python3
"""
Pre-commit Hook 테스트
"""
import subprocess
import sys
import tempfile
from pathlib import Path

class PrecommitHooksTest:
    
    def test_precommit_installation(self):
        """Pre-commit 설치 확인"""
        print("🧪 Pre-commit 설치 확인...")
        
        try:
            result = subprocess.run(['pre-commit', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                version = result.stdout.strip()
                print(f"  ✅ Pre-commit 설치됨: {version}")
                return True
            else:
                print("  ❌ Pre-commit 실행 실패")
                return False
        except FileNotFoundError:
            print("  ❌ Pre-commit이 설치되지 않음")
            return False
    
    def test_precommit_config_file(self):
        """Pre-commit 설정 파일 확인"""
        print("\n🧪 .pre-commit-config.yaml 확인...")
        
        config_path = Path("../../../.pre-commit-config.yaml")
        
        if not config_path.exists():
            print(f"  ❌ .pre-commit-config.yaml 파일 없음: {config_path}")
            return False
        
        try:
            content = config_path.read_text()
            
            required_hooks = [
                "conventional-pre-commit",
                "black",
                "isort", 
                "flake8"
            ]
            
            missing_hooks = []
            for hook in required_hooks:
                if hook not in content:
                    missing_hooks.append(hook)
            
            if missing_hooks:
                print(f"  ❌ 누락된 훅: {missing_hooks}")
                return False
            else:
                print("  ✅ Pre-commit 설정 파일 확인 완료")
                return True
                
        except Exception as e:
            print(f"  ❌ 설정 파일 읽기 실패: {e}")
            return False
    
    def test_precommit_hooks_installed(self):
        """Pre-commit 훅 설치 확인"""
        print("\n🧪 Pre-commit 훅 설치 확인...")
        
        try:
            # Git 훅 디렉터리 확인
            git_hooks_dir = Path("../../../.git/hooks")
            
            if not git_hooks_dir.exists():
                print("  ❌ Git 훅 디렉터리 없음")
                return False
            
            # pre-commit 훅 파일 확인
            pre_commit_hook = git_hooks_dir / "pre-commit"
            commit_msg_hook = git_hooks_dir / "commit-msg"
            
            hooks_installed = []
            if pre_commit_hook.exists():
                hooks_installed.append("pre-commit")
            if commit_msg_hook.exists():
                hooks_installed.append("commit-msg")
            
            if hooks_installed:
                print(f"  ✅ 설치된 훅: {hooks_installed}")
                return True
            else:
                print("  ❌ Pre-commit 훅이 설치되지 않음")
                print("    다음 명령어로 설치하세요:")
                print("    pre-commit install")
                print("    pre-commit install --hook-type commit-msg")
                return False
                
        except Exception as e:
            print(f"  ❌ 훅 설치 확인 실패: {e}")
            return False
    
    def test_commit_message_validation(self):
        """커밋 메시지 검증 테스트"""
        print("\n🧪 커밋 메시지 검증 테스트...")
        
        # 검증 스크립트 확인
        validation_script = Path("../../../scripts/hooks/validate_commit_message.py")
        
        if not validation_script.exists():
            print(f"  ❌ 커밋 메시지 검증 스크립트 없음: {validation_script}")
            return False
        
        # 테스트 메시지들
        test_messages = [
            # 올바른 메시지
            ("feat(stage1): add TMDB API integration", True),
            ("fix(docker): resolve WSL permission issue", True),
            ("docs: update README with setup instructions", True),
            ("data(stage2): add movie feature engineering", True),
            
            # 잘못된 메시지
            ("add new feature", False),  # 타입 없음
            ("feat add feature", False),  # 콜론 없음
            ("FEAT: add feature", False),  # 대문자
            ("feat: Fix bug.", False),    # 대문자 시작, 마침표
        ]
        
        passed_validations = 0
        total_validations = len(test_messages)
        
        for message, should_pass in test_messages:
            with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
                f.write(message)
                f.flush()
                
                try:
                    result = subprocess.run(
                        ['python', str(validation_script), f.name],
                        capture_output=True, text=True
                    )
                    
                    passed = result.returncode == 0
                    
                    if passed == should_pass:
                        print(f"  ✅ '{message}' - {'통과' if should_pass else '거부'}")
                        passed_validations += 1
                    else:
                        print(f"  ❌ '{message}' - 예상과 다른 결과")
                
                except Exception as e:
                    print(f"  💥 '{message}' - 검증 오류: {e}")
                
                finally:
                    Path(f.name).unlink()
        
        success_rate = (passed_validations / total_validations * 100)
        print(f"  📊 검증 성공률: {success_rate:.1f}%")
        
        return success_rate >= 80  # 80% 이상 성공
    
    def run_all_tests(self):
        """모든 테스트 실행"""
        print("🚀 Pre-commit Hook 테스트 시작...\n")
        
        tests = [
            ("Pre-commit 설치", self.test_precommit_installation),
            ("설정 파일", self.test_precommit_config_file),
            ("훅 설치", self.test_precommit_hooks_installed),
            ("메시지 검증", self.test_commit_message_validation),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed += 1
                    print(f"✅ {test_name} 테스트 통과\n")
                else:
                    print(f"❌ {test_name} 테스트 실패\n")
            except Exception as e:
                print(f"💥 {test_name} 테스트 오류: {e}\n")
        
        # 결과 요약
        print("📊 Pre-commit Hook 테스트 결과:")
        print(f"  통과: {passed}/{total}")
        print(f"  성공률: {(passed/total*100):.1f}%")
        
        return passed == total

if __name__ == "__main__":
    tester = PrecommitHooksTest()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
EOF

chmod +x test_precommit_hooks.py

# 테스트 실행
echo "🧪 Pre-commit Hook 테스트 실행..."
python test_precommit_hooks.py
```

---

## 🎯 3. 스마트 커밋 도구 테스트

### 3.1 스마트 커밋 기능 테스트

```bash
# 스마트 커밋 도구 테스트
cat > test_smart_commit_tools.py << 'EOF'
#!/usr/bin/env python3
"""
스마트 커밋 도구 테스트
"""
import subprocess
import sys
from pathlib import Path

class SmartCommitToolsTest:
    
    def test_smart_commit_script(self):
        """스마트 커밋 스크립트 존재 확인"""
        print("🧪 스마트 커밋 스크립트 확인...")
        
        script_path = Path("../../../scripts/smart_commit.py")
        
        if not script_path.exists():
            print(f"  ❌ 스마트 커밋 스크립트 없음: {script_path}")
            return False
        
        # 실행 권한 확인
        if not script_path.stat().st_mode & 0o111:
            print("  ❌ 스마트 커밋 스크립트에 실행 권한 없음")
            return False
        
        print(f"  ✅ 스마트 커밋 스크립트 확인: {script_path}")
        return True
    
    def test_commit_analysis_script(self):
        """커밋 분석 스크립트 존재 확인"""
        print("\n🧪 커밋 분석 스크립트 확인...")
        
        script_path = Path("../../../scripts/analyze_commits.py")
        
        if not script_path.exists():
            print(f"  ❌ 커밋 분석 스크립트 없음: {script_path}")
            return False
        
        # 실행 권한 확인
        if not script_path.stat().st_mode & 0o111:
            print("  ❌ 커밋 분석 스크립트에 실행 권한 없음")
            return False
        
        print(f"  ✅ 커밋 분석 스크립트 확인: {script_path}")
        return True
    
    def test_git_aliases(self):
        """Git 별칭 설정 확인"""
        print("\n🧪 Git 별칭 설정 확인...")
        
        expected_aliases = [
            'commit-smart',
            'commit-cz', 
            'commit-analyze'
        ]
        
        configured_aliases = []
        
        try:
            result = subprocess.run(['git', 'config', '--list'], capture_output=True, text=True)
            if result.returncode == 0:
                config_lines = result.stdout.split('\n')
                for line in config_lines:
                    if line.startswith('alias.'):
                        alias_name = line.split('=')[0].replace('alias.', '')
                        if alias_name in expected_aliases:
                            configured_aliases.append(alias_name)
        except Exception as e:
            print(f"  ❌ Git 별칭 확인 실패: {e}")
            return False
        
        if configured_aliases:
            print(f"  ✅ 설정된 커밋 별칭: {configured_aliases}")
            return True
        else:
            print("  ⚠️ 커밋 관련 Git 별칭이 설정되지 않음")
            print("    scripts/setup_git_aliases.sh를 실행하세요")
            return False
    
    def test_commit_analysis_functionality(self):
        """커밋 분석 기능 테스트"""
        print("\n🧪 커밋 분석 기능 테스트...")
        
        script_path = Path("../../../scripts/analyze_commits.py")
        
        if not script_path.exists():
            print("  ❌ 커밋 분석 스크립트 없음")
            return False
        
        try:
            # 커밋 분석 스크립트 실행 (간단한 실행 테스트)
            result = subprocess.run(
                ['python', str(script_path)],
                capture_output=True, text=True, timeout=30
            )
            
            if result.returncode == 0:
                print("  ✅ 커밋 분석 스크립트 정상 실행")
                
                # 출력에 기대되는 내용이 있는지 확인
                output = result.stdout
                if "커밋 메시지 품질 리포트" in output or "전체 통계" in output:
                    print("  ✅ 분석 리포트 생성 확인")
                    return True
                else:
                    print("  ⚠️ 분석 리포트 형식 확인 필요")
                    return True  # 실행은 되었으므로 통과
            else:
                print(f"  ❌ 커밋 분석 스크립트 실행 실패: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print("  ⏰ 커밋 분석 스크립트 실행 시간 초과")
            return False
        except Exception as e:
            print(f"  ❌ 커밋 분석 기능 테스트 오류: {e}")
            return False
    
    def test_setup_scripts(self):
        """설정 스크립트 확인"""
        print("\n🧪 설정 스크립트 확인...")
        
        setup_scripts = [
            "../../../scripts/setup_git_aliases.sh",
            "../../../scripts/setup_commit_convention.sh"
        ]
        
        found_scripts = []
        missing_scripts = []
        
        for script_name in setup_scripts:
            script_path = Path(script_name)
            if script_path.exists():
                found_scripts.append(script_path.name)
            else:
                missing_scripts.append(script_path.name)
        
        if found_scripts:
            print(f"  ✅ 발견된 설정 스크립트: {found_scripts}")
        
        if missing_scripts:
            print(f"  ⚠️ 누락된 설정 스크립트: {missing_scripts}")
        
        # 최소 하나의 설정 스크립트가 있으면 통과
        return len(found_scripts) > 0
    
    def run_all_tests(self):
        """모든 테스트 실행"""
        print("🚀 스마트 커밋 도구 테스트 시작...\n")
        
        tests = [
            ("스마트 커밋 스크립트", self.test_smart_commit_script),
            ("커밋 분석 스크립트", self.test_commit_analysis_script),
            ("Git 별칭", self.test_git_aliases),
            ("커밋 분석 기능", self.test_commit_analysis_functionality),
            ("설정 스크립트", self.test_setup_scripts),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed += 1
                    print(f"✅ {test_name} 테스트 통과\n")
                else:
                    print(f"❌ {test_name} 테스트 실패\n")
            except Exception as e:
                print(f"💥 {test_name} 테스트 오류: {e}\n")
        
        # 결과 요약
        print("📊 스마트 커밋 도구 테스트 결과:")
        print(f"  통과: {passed}/{total}")
        print(f"  성공률: {(passed/total*100):.1f}%")
        
        return passed == total

if __name__ == "__main__":
    tester = SmartCommitToolsTest()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
EOF

chmod +x test_smart_commit_tools.py

# 테스트 실행
echo "🧪 스마트 커밋 도구 테스트 실행..."
python test_smart_commit_tools.py
```

---

## 🎯 4. 종합 커밋 컨벤션 테스트

### 4.1 통합 테스트 스크립트

```bash
# 종합 커밋 컨벤션 테스트
cat > comprehensive_commit_test.py << 'EOF'
#!/usr/bin/env python3
"""
종합 커밋 컨벤션 테스트
"""
import subprocess
import sys
import json
from datetime import datetime
from pathlib import Path

class ComprehensiveCommitTest:
    
    def __init__(self):
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'tests': {},
            'overall_score': 0
        }
    
    def run_test_module(self, module_name, description):
        """개별 테스트 모듈 실행"""
        print(f"🔍 {description} 실행 중...")
        
        try:
            result = subprocess.run([sys.executable, f"{module_name}.py"], 
                                  capture_output=True, text=True, timeout=60)
            
            success = result.returncode == 0
            self.test_results['tests'][module_name] = {
                'description': description,
                'passed': success,
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            if success:
                print(f"  ✅ {description} 통과")
            else:
                print(f"  ❌ {description} 실패")
                if result.stderr:
                    print(f"     오류: {result.stderr[:200]}...")
            
            return success
            
        except subprocess.TimeoutExpired:
            print(f"  ⏰ {description} 타임아웃")
            self.test_results['tests'][module_name] = {
                'description': description,
                'passed': False,
                'error': 'Timeout'
            }
            return False
        except Exception as e:
            print(f"  💥 {description} 실행 오류: {e}")
            self.test_results['tests'][module_name] = {
                'description': description,
                'passed': False,
                'error': str(e)
            }
            return False
    
    def generate_report(self):
        """테스트 리포트 생성"""
        passed_tests = sum(1 for test in self.test_results['tests'].values() if test['passed'])
        total_tests = len(self.test_results['tests'])
        
        self.test_results['overall_score'] = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        # JSON 리포트 저장
        report_file = f"commit_convention_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(self.test_results, f, indent=2)
        
        # 마크다운 리포트 생성
        md_report = self.generate_markdown_report()
        md_file = f"commit_convention_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        return report_file, md_file
    
    def generate_markdown_report(self):
        """마크다운 리포트 생성"""
        passed_tests = sum(1 for test in self.test_results['tests'].values() if test['passed'])
        total_tests = len(self.test_results['tests'])
        score = self.test_results['overall_score']
        
        report = f"""# 📝 커밋 컨벤션 테스트 리포트

## 📊 전체 결과
- **테스트 시간**: {self.test_results['timestamp']}
- **총 테스트**: {total_tests}개
- **통과**: {passed_tests}개
- **실패**: {total_tests - passed_tests}개
- **성공률**: {score:.1f}%

"""
        
        # 점수에 따른 상태 표시
        if score >= 90:
            report += "🎉 **상태**: 우수 - 커밋 컨벤션이 완벽하게 구축되었습니다!\n\n"
        elif score >= 70:
            report += "👍 **상태**: 양호 - 대부분의 기능이 정상 작동합니다.\n\n"
        elif score >= 50:
            report += "⚠️ **상태**: 개선 필요 - 일부 설정을 점검해주세요.\n\n"
        else:
            report += "❌ **상태**: 문제 있음 - 커밋 컨벤션 재설정이 필요합니다.\n\n"
        
        # 개별 테스트 결과
        report += "## 📋 상세 테스트 결과\n\n"
        
        for module_name, test_result in self.test_results['tests'].items():
            status_icon = "✅" if test_result['passed'] else "❌"
            report += f"### {status_icon} {test_result['description']}\n"
            report += f"- **모듈**: `{module_name}.py`\n"
            report += f"- **결과**: {'통과' if test_result['passed'] else '실패'}\n"
            
            if not test_result['passed']:
                error_msg = test_result.get('error', test_result.get('stderr', 'Unknown error'))
                report += f"- **오류**: {error_msg[:200]}...\n"
            
            report += "\n"
        
        # 권장사항
        report += "## 💡 권장사항\n\n"
        
        failed_tests = [name for name, result in self.test_results['tests'].items() if not result['passed']]
        
        if not failed_tests:
            report += "- 모든 테스트를 통과했습니다! 🎉\n"
            report += "- `cz commit` 명령어로 일관된 커밋 메시지를 작성하세요.\n"
            report += "- 정기적으로 커밋 품질을 분석하세요.\n"
            report += "- 팀원들에게 커밋 컨벤션을 공유하세요.\n"
        else:
            report += f"- 실패한 테스트들을 확인하고 수정하세요: {', '.join(failed_tests)}\n"
            if 'test_commitizen_setup' in failed_tests:
                report += "- Commitizen 설치: `pip install commitizen`\n"
            if 'test_precommit_hooks' in failed_tests:
                report += "- Pre-commit 설치: `pip install pre-commit`\n"
                report += "- 훅 설치: `pre-commit install && pre-commit install --hook-type commit-msg`\n"
            if 'test_smart_commit_tools' in failed_tests:
                report += "- 스마트 커밋 도구 설정: `bash scripts/setup_commit_convention.sh`\n"
        
        report += "\n## 🚀 다음 단계\n\n"
        report += "1. **커밋 컨벤션 사용**:\n"
        report += "   ```bash\n"
        report += "   cz commit  # 대화형 커밋\n"
        report += "   git commit-smart  # 스마트 커밋 (별칭 설정 시)\n"
        report += "   ```\n\n"
        report += "2. **품질 분석**:\n"
        report += "   ```bash\n"
        report += "   python scripts/analyze_commits.py\n"
        report += "   ```\n\n"
        report += "3. **팀 교육 및 가이드 공유**\n\n"
        
        report += "---\n*이 리포트는 자동 생성되었습니다.*\n"
        
        return report
    
    def run_all_tests(self):
        """모든 테스트 실행"""
        print("🚀 커밋 컨벤션 종합 테스트 시작...\n")
        
        test_modules = [
            ("test_commitizen_setup", "Commitizen 설정 테스트"),
            ("test_precommit_hooks", "Pre-commit Hook 테스트"),
            ("test_smart_commit_tools", "스마트 커밋 도구 테스트"),
        ]
        
        passed = 0
        total = len(test_modules)
        
        for module_name, description in test_modules:
            if self.run_test_module(module_name, description):
                passed += 1
            print()  # 빈 줄 추가
        
        # 리포트 생성
        json_file, md_file = self.generate_report()
        
        # 최종 결과 출력
        print("=" * 60)
        print("📝 커밋 컨벤션 종합 테스트 완료!")
        print("=" * 60)
        print(f"전체 테스트: {total}개")
        print(f"통과: {passed}개")
        print(f"실패: {total - passed}개")
        print(f"성공률: {(passed/total*100):.1f}%")
        print()
        print(f"📄 JSON 리포트: {json_file}")
        print(f"📝 Markdown 리포트: {md_file}")
        
        if passed == total:
            print("\n🎉 모든 테스트를 통과했습니다!")
            print("커밋 컨벤션이 성공적으로 구축되었습니다.")
            print()
            print("💡 다음 명령어들을 사용하세요:")
            print("  cz commit              # 대화형 커밋")
            print("  git commit-smart       # 스마트 커밋 (별칭 설정 시)")
            print("  git commit-analyze     # 커밋 품질 분석")
        else:
            print(f"\n⚠️ {total - passed}개 테스트에서 문제가 발견되었습니다.")
            print("실패한 테스트들을 확인하고 수정해주세요.")
        
        return passed == total

if __name__ == "__main__":
    tester = ComprehensiveCommitTest()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
EOF

chmod +x comprehensive_commit_test.py

# 종합 테스트 실행
echo "🚀 커밋 컨벤션 종합 테스트 실행..."
python comprehensive_commit_test.py
```

---

## 🎯 5. 테스트 자동화 및 실행

### 5.1 테스트 자동화 스크립트

```bash
# 커밋 컨벤션 테스트 자동화 스크립트
cat > run_commit_convention_tests.sh << 'EOF'
#!/bin/bash
# 커밋 컨벤션 테스트 자동화 스크립트

set -e

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}📝 커밋 컨벤션 테스트 자동화 시작...${NC}"
echo

# 테스트 환경 준비
echo -e "${YELLOW}📋 테스트 환경 준비 중...${NC}"

# 필요한 Python 패키지 확인
missing_packages=()

if ! python -c "import subprocess, sys, json, pathlib" 2>/dev/null; then
    missing_packages+=("기본 Python 모듈")
fi

# Commitizen 설치 확인
if ! command -v cz >/dev/null 2>&1; then
    missing_packages+=("commitizen")
fi

# Pre-commit 설치 확인
if ! command -v pre-commit >/dev/null 2>&1; then
    missing_packages+=("pre-commit")
fi

if [ ${#missing_packages[@]} -ne 0 ]; then
    echo -e "${RED}❌ 다음 패키지들이 누락되었습니다: ${missing_packages[*]}${NC}"
    echo "다음 명령어로 패키지를 설치하세요:"
    echo "pip install commitizen pre-commit conventional-pre-commit"
    exit 1
fi

# Git 저장소 확인
if ! git status >/dev/null 2>&1; then
    echo -e "${RED}❌ Git 저장소가 아니거나 Git이 설치되지 않았습니다.${NC}"
    exit 1
fi

echo -e "${GREEN}✅ 테스트 환경 준비 완료${NC}"
echo

# 개별 테스트 실행
echo -e "${BLUE}🧪 개별 테스트 실행 중...${NC}"

test_scripts=(
    "test_commitizen_setup.py:Commitizen 설정"
    "test_precommit_hooks.py:Pre-commit Hook"
    "test_smart_commit_tools.py:스마트 커밋 도구"
)

failed_tests=()

for test_info in "${test_scripts[@]}"; do
    IFS=':' read -r script_name test_description <<< "$test_info"
    
    echo -e "${YELLOW}▶ ${test_description} 테스트...${NC}"
    
    if python "$script_name" >/dev/null 2>&1; then
        echo -e "${GREEN}  ✅ 통과${NC}"
    else
        echo -e "${RED}  ❌ 실패${NC}"
        failed_tests+=("$test_description")
    fi
done

echo

# 종합 테스트 실행
echo -e "${BLUE}🎯 종합 테스트 실행 중...${NC}"

if python comprehensive_commit_test.py; then
    echo -e "${GREEN}✅ 종합 테스트 통과${NC}"
else
    echo -e "${RED}❌ 종합 테스트 실패${NC}"
    failed_tests+=("종합 테스트")
fi

echo

# 결과 요약
if [ ${#failed_tests[@]} -eq 0 ]; then
    echo -e "${GREEN}🎉 모든 커밋 컨벤션 테스트를 통과했습니다!${NC}"
    echo -e "${GREEN}   커밋 컨벤션이 성공적으로 구축되었습니다.${NC}"
    
    # 성공 시 사용법 안내
    echo
    echo -e "${BLUE}📋 사용 방법:${NC}"
    echo "  📝 대화형 커밋: cz commit"
    echo "  🤖 스마트 커밋: git commit-smart (별칭 설정 시)"
    echo "  📊 품질 분석: git commit-analyze (별칭 설정 시)"
    echo "  🔍 모든 검사: pre-commit run --all-files"
    
    echo
    echo -e "${BLUE}🚀 다음 단계:${NC}"
    echo "  1. 팀원들에게 커밋 컨벤션 가이드 공유"
    echo "  2. 정기적인 커밋 품질 분석 실시"
    echo "  3. CI/CD 파이프라인에 커밋 검증 통합"
    echo "  4. 코드 리뷰 시 커밋 메시지도 함께 검토"
    
    exit 0
else
    echo -e "${RED}⚠️ 다음 테스트들에서 문제가 발견되었습니다:${NC}"
    for test in "${failed_tests[@]}"; do
        echo -e "${RED}  - $test${NC}"
    done
    
    echo
    echo -e "${YELLOW}🔧 문제 해결 방법:${NC}"
    echo "  1. 패키지 설치: pip install commitizen pre-commit conventional-pre-commit"
    echo "  2. Pre-commit 훅 설치: pre-commit install --hook-type commit-msg"
    echo "  3. 설정 파일 확인: pyproject.toml, .pre-commit-config.yaml"
    echo "  4. 스크립트 실행 권한: chmod +x scripts/*.py"
    echo "  5. 개별 테스트 재실행하여 상세 오류 확인"
    
    exit 1
fi
EOF

chmod +x run_commit_convention_tests.sh

echo "🤖 커밋 컨벤션 테스트 자동화 스크립트 생성 완료"
```

---

## ✅ 테스트 실행 가이드

### 최종 테스트 실행

```bash
# 모든 테스트 실행
echo "🚀 3.3 커밋 컨벤션 구현 테스트 시작..."

# 1. 로컬 환경에서 테스트
echo "1. 로컬 환경 테스트 실행"
bash run_commit_convention_tests.sh

echo
echo "✅ 3.3 커밋 컨벤션 구현 테스트 구성 완료!"
echo
echo "📋 생성된 테스트 파일들:"
echo "  🧪 개별 테스트:"
echo "    - test_commitizen_setup.py"
echo "    - test_precommit_hooks.py"
echo "    - test_smart_commit_tools.py"
echo "  🎯 종합 테스트:"
echo "    - comprehensive_commit_test.py"
echo "  🤖 자동화:"
echo "    - run_commit_convention_tests.sh"
echo
echo "🚀 사용법:"
echo "  bash run_commit_convention_tests.sh  # 모든 테스트 실행"
echo "  python comprehensive_commit_test.py  # 종합 테스트만"
echo
echo "📊 테스트 리포트가 자동으로 생성됩니다:"
echo "  - commit_convention_test_report_YYYYMMDD_HHMMSS.json"
echo "  - commit_convention_test_report_YYYYMMDD_HHMMSS.md"
echo
echo "💡 커밋 컨벤션 사용법:"
echo "  cz commit                    # 대화형 커밋"
echo "  git commit-smart            # 스마트 커밋 (별칭 설정 시)"
echo "  git commit-analyze          # 품질 분석 (별칭 설정 시)"
echo "  pre-commit run --all-files  # 모든 검사 실행"
```

---

## 📋 테스트 완료 체크리스트

### Commitizen 설정 테스트
- [ ] Commitizen 설치 및 버전 확인
- [ ] pyproject.toml 설정 파일 확인
- [ ] Commitizen 설정 로드 확인
- [ ] MLOps 특화 커밋 타입 확인

### Pre-commit Hook 테스트
- [ ] Pre-commit 설치 확인
- [ ] .pre-commit-config.yaml 설정 확인
- [ ] Git 훅 설치 확인
- [ ] 커밋 메시지 검증 기능 테스트

### 스마트 커밋 도구 테스트
- [ ] 스마트 커밋 스크립트 존재 확인
- [ ] 커밋 분석 스크립트 존재 확인
- [ ] Git 별칭 설정 확인
- [ ] 커밋 분석 기능 테스트

### 종합 테스트 및 자동화
- [ ] 종합 테스트 스크립트 실행
- [ ] 테스트 리포트 자동 생성
- [ ] 자동화 스크립트 실행
- [ ] 문제 해결 가이드 제공

이제 3.3 커밋 컨벤션 구현에 대한 완전한 테스트 시스템이 구축되었습니다!
