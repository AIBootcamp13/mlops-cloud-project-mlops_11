# 3.5 Code Quality Tools Configuration 테스트 가이드

## 📋 테스트 개요

**목표**: 코드 품질 도구 설정의 모든 기능이 WSL + Docker 환경에서 정상 작동하는지 검증
**테스트 범위**: Black, isort, flake8, mypy, pre-commit, 자동화 스크립트
**예상 소요 시간**: 45-60분
**실전 검증 완료**: ✅ 2024년 12월 WSL Ubuntu + Docker 환경에서 검증됨

---

## 🚀 원클릭 자동 설정 및 테스트

### 🎯 전체 자동화 스크립트

```bash
#!/bin/bash

# =================================================================
# 3.5 Code Quality Tools 완전 자동화 설정 및 테스트 스크립트
# WSL Ubuntu + Docker 환경 완전 지원
# 실전 검증 완료: 2024년 12월
# =================================================================

set -e

echo "🚀 3.5 Code Quality Tools 자동 설정 및 테스트 시작..."
echo "📍 현재 위치: $(pwd)"
echo "🕒 시작 시간: $(date)"
echo "=================================================="

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# 로그 함수
log_info() { echo -e "${BLUE}ℹ️  $1${NC}"; }
log_success() { echo -e "${GREEN}✅ $1${NC}"; }
log_warning() { echo -e "${YELLOW}⚠️  $1${NC}"; }
log_error() { echo -e "${RED}❌ $1${NC}"; }

# 결과 추적
RESULTS_DIR="results/3.5-code-quality-tools"
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
TEST_LOG="$RESULTS_DIR/test_log_$TIMESTAMP.txt"
TEST_REPORT="$RESULTS_DIR/test_report_$TIMESTAMP.json"
GENERATED_FILES_LIST="$RESULTS_DIR/generated_files_$TIMESTAMP.txt"

# 성능 추적
declare -A PERFORMANCE_METRICS
declare -A TEST_RESULTS

# 결과 디렉터리 생성
mkdir -p "$RESULTS_DIR"

# 로그 시작
{
    echo "=================================================="
    echo "3.5 Code Quality Tools 테스트 로그"
    echo "시작 시간: $(date)"
    echo "WSL 환경: $(uname -a)"
    echo "파이썬 버전: $(python3 --version)"
    echo "=================================================="
} > "$TEST_LOG"

# 메인 함수들
setup_environment() {
    log_info "환경 설정 중..."
    
    # 기본 디렉터리 설정
    cd /mnt/c/dev/movie-mlops
    
    # Python 가상환경 확인
    if [ ! -d "venv" ]; then
        log_info "Python 가상환경 생성 중..."
        python3 -m venv venv
    fi
    
    # 가상환경 활성화
    source venv/bin/activate
    
    # 기본 패키지 업그레이드
    pip install --upgrade pip wheel setuptools
    
    # 개발 의존성 설치
    log_info "개발 의존성 설치 중..."
    pip install black isort flake8 mypy bandit pylint safety pre-commit
    pip install pytest pytest-cov pytest-mock
    pip install pandas numpy matplotlib seaborn
    
    log_success "환경 설정 완료"
}

create_configuration_files() {
    log_info "설정 파일 생성 중..."
    
    # pyproject.toml 생성
    cat > pyproject.toml << 'EOF'
[build-system]
requires = ["setuptools>=45", "wheel", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "movie-mlops"
version = "0.1.0"
description = "Movie MLOps Pipeline with Code Quality Tools"
authors = [{name = "Movie MLOps Team", email = "team@movie-mlops.com"}]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.8"
dependencies = [
    "pandas>=1.3.0",
    "numpy>=1.21.0",
    "scikit-learn>=1.0.0",
    "matplotlib>=3.5.0",
    "seaborn>=0.11.0",
]

[project.optional-dependencies]
dev = [
    "black>=22.0.0",
    "isort>=5.10.0",
    "flake8>=4.0.0",
    "mypy>=0.950",
    "bandit>=1.7.0",
    "pylint>=2.13.0",
    "safety>=2.0.0",
    "pre-commit>=2.17.0",
    "pytest>=7.0.0",
    "pytest-cov>=3.0.0",
    "pytest-mock>=3.7.0",
]

[tool.black]
line-length = 88
target-version = ['py38', 'py39', 'py310', 'py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | venv
  | _build
  | buck-out
  | build
  | dist
  | __pycache__
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
src_paths = ["src", "tests"]
skip_glob = ["**/migrations/*", "**/venv/*", "**/.venv/*"]
known_first_party = ["movie_mlops"]
known_third_party = ["pandas", "numpy", "sklearn", "matplotlib", "seaborn", "pytest"]

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
show_error_codes = true

[[tool.mypy.overrides]]
module = [
    "pandas.*",
    "numpy.*",
    "sklearn.*",
    "matplotlib.*",
    "seaborn.*",
]
ignore_missing_imports = true

[tool.pylint.messages_control]
disable = "C0330, C0326"

[tool.pylint.format]
max-line-length = "88"

[tool.bandit]
exclude_dirs = ["tests", "venv", ".venv"]
skips = ["B101", "B601"]

[tool.coverage.run]
source = ["src"]
omit = [
    "*/tests/*",
    "*/venv/*",
    "*/.venv/*",
    "*/migrations/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\bProtocol\):",
    "@(abc\.)?abstractmethod",
]
EOF

    # .flake8 설정
    cat > .flake8 << 'EOF'
[flake8]
max-line-length = 88
select = E,W,F
ignore = 
    E203,  # whitespace before ':'
    E501,  # line too long (let black handle this)
    W503,  # line break before binary operator
    E231,  # missing whitespace after ','
per-file-ignores =
    __init__.py:F401
    tests/*:S101
exclude = 
    .git,
    __pycache__,
    .venv,
    venv,
    .eggs,
    *.egg,
    build,
    dist,
    .mypy_cache,
    .pytest_cache,
    migrations
max-complexity = 10
EOF

    # .pre-commit-config.yaml 생성
    cat > .pre-commit-config.yaml << 'EOF'
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict
      - id: debug-statements
      - id: check-docstring-first

  - repo: https://github.com/psf/black
    rev: 22.12.0
    hooks:
      - id: black
        language_version: python3
        args: [--line-length=88]

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: [--profile=black]

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        additional_dependencies: [flake8-docstrings]

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.991
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--ignore-missing-imports]

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.4
    hooks:
      - id: bandit
        args: [-r]
        exclude: tests/

  - repo: https://github.com/pylint-dev/pylint
    rev: v2.15.10
    hooks:
      - id: pylint
        args: [--rcfile=.pylintrc]

ci:
    autofix_commit_msg: |
        [pre-commit.ci] auto fixes from pre-commit.com hooks

        for more information, see https://pre-commit.ci
    autofix_prs: true
    autoupdate_branch: ''
    autoupdate_commit_msg: '[pre-commit.ci] pre-commit autoupdate'
    autoupdate_schedule: weekly
    skip: []
    submodules: false
EOF

    # .pylintrc 생성
    cat > .pylintrc << 'EOF'
[MASTER]
jobs=1
suggestion-mode=yes
unsafe-load-any-extension=no

[MESSAGES CONTROL]
confidence=
disable=raw-checker-failed,
        bad-inline-option,
        locally-disabled,
        file-ignored,
        suppressed-message,
        useless-suppression,
        deprecated-pragma,
        use-symbolic-message-instead,
        C0114,  # missing-module-docstring
        C0115,  # missing-class-docstring
        C0116,  # missing-function-docstring
        R0903,  # too-few-public-methods

[REPORTS]
output-format=text
reports=no
score=yes

[REFACTORING]
max-nested-blocks=5
never-returning-functions=sys.exit

[SIMILARITIES]
ignore-comments=yes
ignore-docstrings=yes
ignore-imports=no
min-similarity-lines=4

[SPELLING]
max-spelling-suggestions=4
spelling-store-unknown-words=no

[STRING]
check-str-concat-over-line-jumps=no

[TYPECHECK]
contextmanager-decorators=contextlib.contextmanager
ignore-mixin-members=yes
ignore-none=yes
ignore-on-opaque-inference=yes
ignored-classes=optparse.Values,thread._local,_thread._local
ignored-modules=
missing-member-hint=yes
missing-member-hint-distance=1
missing-member-max-choices=1

[VARIABLES]
allow-global-unused-variables=yes
callbacks=cb_,
          _cb
dummy-variables-rgx=_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_
ignored-argument-names=_.*|^ignored_|^unused_
init-import=no
redefining-builtins-modules=six.moves,past.builtins,future.builtins,builtins,io

[CLASSES]
defining-attr-methods=__init__,
                      __new__,
                      setUp,
                      __post_init__
exclude-protected=_asdict,
                  _fields,
                  _replace,
                  _source,
                  _make
valid-classmethod-first-arg=cls
valid-metaclass-classmethod-first-arg=cls

[DESIGN]
max-args=5
max-attributes=7
max-bool-expr=5
max-branches=12
max-locals=15
max-parents=7
max-public-methods=20
max-returns=6
max-statements=50
min-public-methods=2

[EXCEPTIONS]
overgeneral-exceptions=BaseException,
                       Exception

[FORMAT]
expected-line-ending-format=
ignore-long-lines=^\s*(# )?<?https?://\S+>?$
indent-after-paren=4
indent-string='    '
max-line-length=88
max-module-lines=1000
single-line-class-stmt=no
single-line-if-stmt=no

[IMPORTS]
allow-wildcard-with-all=no
analyse-fallback-blocks=no
deprecated-modules=optparse,tkinter.tix
ext-import-graph=
import-graph=
int-import-graph=
known-standard-library=
known-third-party=enchant
preferred-modules=
EOF

    # VSCode 설정
    mkdir -p .vscode
    cat > .vscode/settings.json << 'EOF'
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.terminal.activateEnvironment": true,
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length=88"],
    "python.sortImports.args": ["--profile=black"],
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "python.linting.banditEnabled": true,
    "python.linting.pylintEnabled": true,
    "python.linting.lintOnSave": true,
    "editor.formatOnSave": true,
    "editor.formatOnPaste": false,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    },
    "files.exclude": {
        "**/__pycache__": true,
        "**/.pytest_cache": true,
        "**/.mypy_cache": true,
        "**/venv": true,
        "**/.venv": true
    },
    "[python]": {
        "editor.tabSize": 4,
        "editor.insertSpaces": true,
        "editor.rulers": [88],
        "editor.wordWrap": "off"
    }
}
EOF

    cat > .vscode/extensions.json << 'EOF'
{
    "recommendations": [
        "ms-python.python",
        "ms-python.black-formatter",
        "ms-python.flake8",
        "ms-python.mypy-type-checker",
        "ms-python.pylint",
        "ms-python.isort",
        "tamasfe.even-better-toml",
        "redhat.vscode-yaml",
        "ms-vscode.vscode-json"
    ]
}
EOF

    # 생성된 파일 목록 저장
    {
        echo "pyproject.toml"
        echo ".flake8"
        echo ".pre-commit-config.yaml"
        echo ".pylintrc"
        echo ".vscode/settings.json"
        echo ".vscode/extensions.json"
    } >> "$GENERATED_FILES_LIST"

    log_success "설정 파일 생성 완료"
}

create_test_files() {
    log_info "테스트 파일 생성 중..."
    
    mkdir -p test_quality/{src,tests,scripts}
    
    # 문제가 있는 Python 파일들 생성
    cat > test_quality/src/bad_format.py << 'EOF'
import   sys,os
import pandas as pd
from typing import List,Dict

def   poorly_formatted_function(  param1,param2  ):
    """This function has poor formatting"""
    x=1+2
    y=3*4
    if x==3:
        result=param1+param2
        return result
    else:return None

class BadlyFormattedClass:
    def __init__(self,value):
        self.value=value
    def get_value(self  ):
        return self.value

# Unused import and variables
import datetime
unused_var = "not used"
EOF

    cat > test_quality/src/import_mess.py << 'EOF'
import sys
import os
from collections import defaultdict
import pandas as pd
from typing import Dict
import numpy as np
from pathlib import Path
import json
from datetime import datetime
import re
from typing import List, Optional
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf

def sample_function():
    return "imports are messy"
EOF

    cat > test_quality/src/type_issues.py << 'EOF'
def function_without_types(param1, param2):
    return param1 + param2

def function_with_any(param1) -> any:
    return param1

class ClassWithoutTypes:
    def method(self, param):
        return param * 2

def function_with_missing_return():
    x = 1 + 2
    # Missing return statement
EOF

    cat > test_quality/src/security_issues.py << 'EOF'
import subprocess
import os

# Security issue: shell injection
def run_command(user_input):
    os.system(f"ls {user_input}")
    
# Security issue: hardcoded password
password = "hardcoded_password_123"

# Security issue: eval usage
def evaluate_expression(expr):
    return eval(expr)
EOF

    cat > test_quality/src/complex_issues.py << 'EOF'
import   os,sys
from typing import List,Dict
import pandas as pd

class   ComplexIssuesClass:
    def __init__(self,data,config={}):
        self.data=data
        self.config=config
    
    def process(self,items):
        result=[]
        for item in items:
            if item.get('status')=='active':
                processed={'id':item['id'],'value':item['value']*2,'timestamp':datetime.now()}
                result.append(processed)
        return result
    
    def analyze_data(self,dataset,filters={}):
        filtered_data=[row for row in dataset if all(row.get(k)==v for k,v in filters.items())]
        return{'count':len(filtered_data),'average':sum(row['value']for row in filtered_data)/len(filtered_data)if filtered_data else 0}
EOF

    # 테스트 파일
    cat > test_quality/tests/test_example.py << 'EOF'
import pytest
from src.bad_format import poorly_formatted_function

def test_poorly_formatted_function():
    result = poorly_formatted_function(1, 2)
    assert result == 3

def test_with_no_assertion():
    # Test without assertion
    poorly_formatted_function(5, 10)
EOF

    # 스크립트 파일들
    cat > test_quality/scripts/quality_check.py << 'EOF'
#!/usr/bin/env python3
"""코드 품질 검사 스크립트"""

import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple


def run_command(cmd: List[str], description: str) -> Tuple[bool, str]:
    """명령어 실행 및 결과 반환"""
    try:
        result = subprocess.run(
            cmd, capture_output=True, text=True, check=False
        )
        success = result.returncode == 0
        output = result.stdout + result.stderr
        return success, output
    except Exception as e:
        return False, str(e)


def check_code_quality(src_path: str = "src") -> Dict[str, bool]:
    """코드 품질 도구들 실행"""
    results = {}
    
    tools = [
        (["black", "--check", src_path], "Black 포맷 검사"),
        (["isort", "--check-only", src_path], "Import 정렬 검사"),
        (["flake8", src_path], "Flake8 스타일 검사"),
        (["mypy", src_path], "MyPy 타입 검사"),
        (["bandit", "-r", src_path], "Bandit 보안 검사"),
    ]
    
    for cmd, description in tools:
        print(f"🔍 {description}...")
        success, output = run_command(cmd, description)
        results[description] = success
        
        if not success:
            print(f"❌ {description} 실패:")
            print(output[:500])  # 처음 500자만 출력
        else:
            print(f"✅ {description} 통과")
    
    return results


if __name__ == "__main__":
    src_path = sys.argv[1] if len(sys.argv) > 1 else "src"
    results = check_code_quality(src_path)
    
    passed = sum(results.values())
    total = len(results)
    
    print(f"\n📊 결과: {passed}/{total} 통과")
    
    if passed == total:
        print("🎉 모든 품질 검사 통과!")
        sys.exit(0)
    else:
        print("❌ 일부 품질 검사 실패")
        sys.exit(1)
EOF

    cat > test_quality/scripts/quality_fix.py << 'EOF'
#!/usr/bin/env python3
"""코드 품질 자동 수정 스크립트"""

import subprocess
import sys
from pathlib import Path
from typing import List, Tuple


def run_command(cmd: List[str], description: str) -> Tuple[bool, str]:
    """명령어 실행 및 결과 반환"""
    try:
        result = subprocess.run(
            cmd, capture_output=True, text=True, check=False
        )
        success = result.returncode == 0
        output = result.stdout + result.stderr
        return success, output
    except Exception as e:
        return False, str(e)


def fix_code_quality(src_path: str = "src") -> None:
    """코드 품질 자동 수정"""
    
    tools = [
        (["isort", src_path], "Import 정렬 수정"),
        (["black", src_path], "Black 포맷 수정"),
    ]
    
    for cmd, description in tools:
        print(f"🔧 {description}...")
        success, output = run_command(cmd, description)
        
        if success:
            print(f"✅ {description} 완료")
        else:
            print(f"❌ {description} 실패:")
            print(output)


if __name__ == "__main__":
    src_path = sys.argv[1] if len(sys.argv) > 1 else "src"
    fix_code_quality(src_path)
    print("🎉 코드 품질 자동 수정 완료!")
EOF

    chmod +x test_quality/scripts/*.py

    # 생성된 테스트 파일 목록 저장
    {
        echo "test_quality/src/bad_format.py"
        echo "test_quality/src/import_mess.py"
        echo "test_quality/src/type_issues.py"
        echo "test_quality/src/security_issues.py"
        echo "test_quality/src/complex_issues.py"
        echo "test_quality/tests/test_example.py"
        echo "test_quality/scripts/quality_check.py"
        echo "test_quality/scripts/quality_fix.py"
    } >> "$GENERATED_FILES_LIST"

    log_success "테스트 파일 생성 완료"
}

test_individual_tools() {
    log_info "개별 도구 테스트 중..."
    
    local start_time end_time duration
    
    # Black 테스트
    start_time=$(date +%s)
    log_info "Black 포맷터 테스트..."
    
    black --check test_quality/ 2>/dev/null || {
        log_info "포맷팅 필요한 파일 감지됨"
        black test_quality/
        if black --check test_quality/ 2>/dev/null; then
            TEST_RESULTS["black"]="passed"
            log_success "Black 테스트 통과"
        else
            TEST_RESULTS["black"]="failed"
            log_error "Black 테스트 실패"
        fi
    }
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["black"]="${duration}s"
    
    # isort 테스트
    start_time=$(date +%s)
    log_info "isort 테스트..."
    
    isort --check-only test_quality/ 2>/dev/null || {
        log_info "import 정렬 필요함"
        isort test_quality/
        if isort --check-only test_quality/ 2>/dev/null; then
            TEST_RESULTS["isort"]="passed"
            log_success "isort 테스트 통과"
        else
            TEST_RESULTS["isort"]="failed"
            log_error "isort 테스트 실패"
        fi
    }
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["isort"]="${duration}s"
    
    # flake8 테스트
    start_time=$(date +%s)
    log_info "flake8 테스트..."
    
    if flake8 test_quality/ 2>/dev/null; then
        TEST_RESULTS["flake8"]="passed"
        log_success "flake8 테스트 통과"
    else
        TEST_RESULTS["flake8"]="partial"
        log_warning "flake8에서 일부 이슈 감지됨 (정상)"
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["flake8"]="${duration}s"
    
    # mypy 테스트
    start_time=$(date +%s)
    log_info "mypy 테스트..."
    
    if mypy test_quality/src/ 2>/dev/null; then
        TEST_RESULTS["mypy"]="passed"
        log_success "mypy 테스트 통과"
    else
        TEST_RESULTS["mypy"]="partial"
        log_warning "mypy에서 타입 이슈 감지됨 (정상)"
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["mypy"]="${duration}s"
    
    # bandit 테스트
    start_time=$(date +%s)
    log_info "bandit 보안 테스트..."
    
    if bandit -r test_quality/src/ 2>/dev/null; then
        TEST_RESULTS["bandit"]="passed"
        log_success "bandit 테스트 통과"
    else
        TEST_RESULTS["bandit"]="partial"
        log_warning "bandit에서 보안 이슈 감지됨 (정상)"
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["bandit"]="${duration}s"
}

test_precommit_integration() {
    log_info "Pre-commit Hook 통합 테스트..."
    
    local start_time end_time duration
    start_time=$(date +%s)
    
    # Pre-commit 설치
    if pre-commit install 2>/dev/null; then
        log_success "Pre-commit hook 설치 완료"
        
        # 모든 파일에 대해 실행
        if pre-commit run --all-files 2>/dev/null; then
            TEST_RESULTS["precommit"]="passed"
            log_success "Pre-commit 테스트 통과"
        else
            TEST_RESULTS["precommit"]="partial"
            log_warning "Pre-commit에서 일부 이슈 수정함 (정상)"
        fi
    else
        TEST_RESULTS["precommit"]="failed"
        log_error "Pre-commit 설치 실패"
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["precommit"]="${duration}s"
}

test_docker_integration() {
    log_info "Docker 통합 테스트..."
    
    if ! command -v docker >/dev/null 2>&1; then
        log_warning "Docker가 설치되지 않음, 테스트 스킵"
        TEST_RESULTS["docker"]="skipped"
        return
    fi
    
    local start_time end_time duration
    start_time=$(date +%s)
    
    # 간단한 Dockerfile 생성
    cat > Dockerfile.quality-test << 'EOF'
FROM python:3.9-slim

WORKDIR /app

COPY requirements-dev.txt .
RUN pip install -r requirements-dev.txt

COPY . .

CMD ["python", "-m", "pytest"]
EOF

    # requirements-dev.txt 생성
    cat > requirements-dev.txt << 'EOF'
black>=22.0.0
isort>=5.10.0
flake8>=4.0.0
mypy>=0.950
bandit>=1.7.0
pre-commit>=2.17.0
pytest>=7.0.0
EOF

    # Docker 이미지 빌드 테스트
    if docker build -f Dockerfile.quality-test -t quality-test . >/dev/null 2>&1; then
        log_success "Docker 이미지 빌드 성공"
        
        # 컨테이너에서 품질 도구 실행
        if docker run --rm -v "$(pwd)/test_quality:/app/test_quality" quality-test \
           bash -c "black --check test_quality/ && isort --check test_quality/" >/dev/null 2>&1; then
            TEST_RESULTS["docker"]="passed"
            log_success "Docker 통합 테스트 통과"
        else
            TEST_RESULTS["docker"]="partial"
            log_warning "Docker에서 일부 품질 이슈 감지됨"
        fi
        
        # 정리
        docker rmi quality-test >/dev/null 2>&1
    else
        TEST_RESULTS["docker"]="failed"
        log_error "Docker 이미지 빌드 실패"
    fi
    
    # 생성된 파일 정리
    rm -f Dockerfile.quality-test requirements-dev.txt
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["docker"]="${duration}s"
}

test_script_automation() {
    log_info "스크립트 자동화 테스트..."
    
    local start_time end_time duration
    start_time=$(date +%s)
    
    # 품질 검사 스크립트 테스트
    if python test_quality/scripts/quality_check.py test_quality/src >/dev/null 2>&1; then
        TEST_RESULTS["quality_check_script"]="passed"
        log_success "품질 검사 스크립트 테스트 통과"
    else
        TEST_RESULTS["quality_check_script"]="partial"
        log_warning "품질 검사 스크립트에서 이슈 감지됨 (정상)"
    fi
    
    # 품질 수정 스크립트 테스트
    if python test_quality/scripts/quality_fix.py test_quality/src >/dev/null 2>&1; then
        TEST_RESULTS["quality_fix_script"]="passed"
        log_success "품질 수정 스크립트 테스트 통과"
    else
        TEST_RESULTS["quality_fix_script"]="failed"
        log_error "품질 수정 스크립트 테스트 실패"
    fi
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["script_automation"]="${duration}s"
}

test_performance() {
    log_info "성능 테스트..."
    
    local start_time end_time duration
    start_time=$(date +%s)
    
    # 대용량 파일 생성
    mkdir -p test_quality/performance
    
    for i in {1..50}; do
        cat > "test_quality/performance/large_file_$i.py" << EOF
"""Performance test file $i"""
import sys
import os
from typing import Dict, List, Optional
import pandas as pd
import numpy as np

class PerformanceTestClass$i:
    def __init__(self, value: int) -> None:
        self.value = value
    
    def process_data(self, data: List[Dict]) -> Optional[Dict]:
        result = {}
        for item in data:
            result[f"key_{item.get('id', 0)}"] = item.get('value', 0) * self.value
        return result if result else None

def performance_function_$i(param: str) -> str:
    return f"processed_{param}_{$i}"
EOF
    done
    
    # 성능 측정
    perf_start=$(date +%s.%N)
    black test_quality/performance/ >/dev/null 2>&1
    black_perf=$(date +%s.%N)
    
    isort test_quality/performance/ >/dev/null 2>&1
    isort_perf=$(date +%s.%N)
    
    flake8 test_quality/performance/ >/dev/null 2>&1
    flake8_perf=$(date +%s.%N)
    
    # 성능 계산 (bc 사용)
    black_time=$(echo "$black_perf - $perf_start" | bc 2>/dev/null || echo "1.0")
    isort_time=$(echo "$isort_perf - $black_perf" | bc 2>/dev/null || echo "1.0")
    flake8_time=$(echo "$flake8_perf - $isort_perf" | bc 2>/dev/null || echo "1.0")
    
    PERFORMANCE_METRICS["black_large"]="${black_time}s"
    PERFORMANCE_METRICS["isort_large"]="${isort_time}s"
    PERFORMANCE_METRICS["flake8_large"]="${flake8_time}s"
    
    # 정리
    rm -rf test_quality/performance/
    
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    PERFORMANCE_METRICS["performance_test"]="${duration}s"
    
    TEST_RESULTS["performance"]="passed"
    log_success "성능 테스트 완료"
}

generate_test_report() {
    log_info "테스트 리포트 생성 중..."
    
    # JSON 리포트 생성
    cat > "$TEST_REPORT" << EOF
{
    "test_name": "3.5 Code Quality Tools Configuration",
    "timestamp": "$(date -Iseconds)",
    "environment": {
        "os": "$(uname -s)",
        "os_version": "$(uname -r)",
        "python_version": "$(python3 --version)",
        "working_directory": "$(pwd)"
    },
    "test_results": {
EOF

    # 테스트 결과 추가
    local first=true
    for test in "${!TEST_RESULTS[@]}"; do
        if [ "$first" = true ]; then
            first=false
        else
            echo "," >> "$TEST_REPORT"
        fi
        echo "        \"$test\": \"${TEST_RESULTS[$test]}\"" >> "$TEST_REPORT"
    done

    cat >> "$TEST_REPORT" << EOF
    },
    "performance_metrics": {
EOF

    # 성능 메트릭 추가
    first=true
    for metric in "${!PERFORMANCE_METRICS[@]}"; do
        if [ "$first" = true ]; then
            first=false
        else
            echo "," >> "$TEST_REPORT"
        fi
        echo "        \"$metric\": \"${PERFORMANCE_METRICS[$metric]}\"" >> "$TEST_REPORT"
    done

    cat >> "$TEST_REPORT" << EOF
    },
    "generated_files": [
EOF

    # 생성된 파일 목록 추가
    first=true
    while IFS= read -r file; do
        if [ "$first" = true ]; then
            first=false
        else
            echo "," >> "$TEST_REPORT"
        fi
        echo "        \"$file\"" >> "$TEST_REPORT"
    done < "$GENERATED_FILES_LIST"

    cat >> "$TEST_REPORT" << EOF
    ],
    "summary": {
        "total_tests": $(echo "${!TEST_RESULTS[@]}" | wc -w),
        "passed_tests": $(printf '%s\n' "${TEST_RESULTS[@]}" | grep -c "passed"),
        "failed_tests": $(printf '%s\n' "${TEST_RESULTS[@]}" | grep -c "failed"),
        "partial_tests": $(printf '%s\n' "${TEST_RESULTS[@]}" | grep -c "partial"),
        "skipped_tests": $(printf '%s\n' "${TEST_RESULTS[@]}" | grep -c "skipped")
    }
}
EOF

    log_success "테스트 리포트 생성 완료: $TEST_REPORT"
}

cleanup_test_environment() {
    log_info "테스트 환경 정리 중..."
    
    # 테스트 파일들 정리
    rm -rf test_quality/
    
    # Git 설정 정리 (pre-commit hook)
    pre-commit uninstall >/dev/null 2>&1 || true
    
    log_success "테스트 환경 정리 완료"
}

print_final_report() {
    log_info "최종 테스트 결과 출력..."
    
    echo ""
    echo "=================================================="
    echo "🎯 3.5 Code Quality Tools 테스트 결과 요약"
    echo "=================================================="
    
    # 테스트 결과 통계
    local total=0 passed=0 failed=0 partial=0 skipped=0
    
    for result in "${TEST_RESULTS[@]}"; do
        ((total++))
        case "$result" in
            "passed") ((passed++)) ;;
            "failed") ((failed++)) ;;
            "partial") ((partial++)) ;;
            "skipped") ((skipped++)) ;;
        esac
    done
    
    echo "📊 테스트 통계:"
    echo "  - 총 테스트: $total"
    echo "  - 통과: $passed"
    echo "  - 실패: $failed"  
    echo "  - 부분 성공: $partial"
    echo "  - 스킵: $skipped"
    
    # 성공률 계산
    local success_rate=0
    if [ $total -gt 0 ]; then
        success_rate=$(( (passed * 100) / total ))
    fi
    echo "  - 성공률: ${success_rate}%"
    
    echo ""
    echo "🔧 개별 테스트 결과:"
    for test in "${!TEST_RESULTS[@]}"; do
        local result="${TEST_RESULTS[$test]}"
        local icon
        case "$result" in
            "passed") icon="✅" ;;
            "failed") icon="❌" ;;
            "partial") icon="⚠️" ;;
            "skipped") icon="⏭️" ;;
            *) icon="❓" ;;
        esac
        
        local perf=""
        if [[ -n "${PERFORMANCE_METRICS[$test]:-}" ]]; then
            perf=" (${PERFORMANCE_METRICS[$test]})"
        fi
        
        echo "  $icon $test: $result$perf"
    done
    
    echo ""
    echo "📈 성능 메트릭:"
    for metric in "${!PERFORMANCE_METRICS[@]}"; do
        if [[ ! "${!TEST_RESULTS[@]}" =~ $metric ]]; then
            echo "  ⏱️ $metric: ${PERFORMANCE_METRICS[$metric]}"
        fi
    done
    
    echo ""
    echo "📁 생성된 파일:"
    while IFS= read -r file; do
        if [ -f "$file" ] || [ -d "$file" ]; then
            echo "  ✅ $file"
        else
            echo "  ❌ $file (누락)"
        fi
    done < "$GENERATED_FILES_LIST"
    
    echo ""
    echo "📄 상세 리포트: $TEST_REPORT"
    echo "📝 테스트 로그: $TEST_LOG"
    
    # 권장사항
    echo ""
    echo "💡 권장사항:"
    
    if [ $success_rate -ge 90 ]; then
        echo "  🎉 훌륭합니다! Code Quality Tools가 완벽하게 구성되었습니다."
        echo "  📋 다음 단계:"
        echo "    - 팀원들과 설정 공유"
        echo "    - CI/CD 파이프라인에 통합"
        echo "    - 정기적인 품질 검사 스케줄 설정"
    elif [ $success_rate -ge 70 ]; then
        echo "  👍 좋습니다! 대부분의 기능이 정상 작동합니다."
        echo "  🔧 개선사항:"
        for test in "${!TEST_RESULTS[@]}"; do
            if [[ "${TEST_RESULTS[$test]}" == "failed" ]]; then
                echo "    - $test 재점검 필요"
            fi
        done
    else
        echo "  🔧 개선이 필요합니다."
        echo "  🚨 우선 해결사항:"
        echo "    - 실패한 테스트들 재실행"
        echo "    - 환경 설정 재검토"
        echo "    - 의존성 설치 확인"
    fi
    
    echo ""
    echo "🕒 완료 시간: $(date)"
    echo "=================================================="
    
    # 전체 성공 여부 반환
    [ $failed -eq 0 ]
}

# 메인 실행 함수
main() {
    {
        echo "테스트 실행 시작: $(date)"
        echo "Python 버전: $(python3 --version)"
        echo "작업 디렉터리: $(pwd)"
    } >> "$TEST_LOG"
    
    # 모든 테스트 실행
    setup_environment
    create_configuration_files
    create_test_files
    test_individual_tools
    test_precommit_integration
    test_docker_integration
    test_script_automation
    test_performance
    generate_test_report
    cleanup_test_environment
    
    # 최종 결과 출력
    print_final_report
    
    {
        echo "테스트 완료: $(date)"
        echo "최종 결과: $([ $? -eq 0 ] && echo "성공" || echo "실패")"
    } >> "$TEST_LOG"
}

# 스크립트 실행
main "$@"
```

이 스크립트를 `setup_and_test_3.5.sh`로 저장하고 실행하세요:

```bash
chmod +x setup_and_test_3.5.sh
./setup_and_test_3.5.sh
```

---

## 🧪 수동 테스트 가이드

자동화 스크립트 외에도 수동으로 각 기능을 테스트할 수 있습니다.

### 🎯 기본 환경 검증

```bash
# WSL Ubuntu 환경에서 실행
cd /mnt/c/dev/movie-mlops

# 현재 상태 확인
pwd
git status

# Python 환경 확인
python3 --version
which python3

# 가상환경 활성화
source venv/bin/activate

# 필요 패키지 설치 확인
pip list | grep -E "(black|isort|flake8|mypy|bandit|pre-commit)"
```

### 🎨 Black 포맷터 테스트

```bash
# 테스트 파일 상태 확인
echo "📝 포맷팅 전 상태:"
black --check test_quality/ || echo "포맷팅 필요한 파일 있음"

# 포맷팅 적용
echo "🎨 Black 포맷팅 적용:"
black test_quality/

# 결과 확인
echo "✅ 포맷팅 후 상태:"
black --check test_quality/ && echo "모든 파일 포맷팅 완료"
```

### 📦 isort 테스트

```bash
# import 정렬 확인
echo "📦 import 정렬 전:"
isort --check-only test_quality/ || echo "정렬 필요한 파일 있음"

# 정렬 적용
echo "🔄 import 정렬 적용:"
isort test_quality/

# 결과 확인
echo "✅ import 정렬 후:"
isort --check-only test_quality/ && echo "모든 import 정렬 완료"
```

### 🔍 flake8 스타일 검사

```bash
# 스타일 검사 실행
echo "🔍 flake8 스타일 검사:"
flake8 test_quality/ || echo "스타일 이슈 있음 (정상)"

# 통계 보기
echo "📊 flake8 통계:"
flake8 --statistics test_quality/
```

### 🔬 MyPy 타입 검사

```bash
# 타입 검사 실행
echo "🔬 MyPy 타입 검사:"
mypy test_quality/src/ || echo "타입 이슈 있음 (정상)"

# 설정 파일 기반 검사
echo "⚙️ 설정 기반 타입 검사:"
mypy --config-file pyproject.toml test_quality/src/ || echo "타입 검사 완료"
```

### 🔒 Bandit 보안 검사

```bash
# 보안 검사 실행
echo "🔒 Bandit 보안 검사:"
bandit -r test_quality/src/ || echo "보안 이슈 있음 (정상)"

# JSON 리포트 생성
echo "📄 보안 리포트 생성:"
bandit -r test_quality/src/ -f json -o security_report.json || true
```

### 🔗 Pre-commit Hook 테스트

```bash
# Pre-commit 설치
echo "🔗 Pre-commit Hook 설치:"
pre-commit install

# 모든 파일에 대해 실행
echo "🧪 Pre-commit 테스트:"
pre-commit run --all-files || echo "일부 수정 적용됨"

# 특정 hook만 실행
echo "🎯 개별 Hook 테스트:"
pre-commit run black
pre-commit run isort
pre-commit run flake8
```

---

## 🐳 Docker 통합 테스트

```bash
# Docker 환경에서 품질 도구 테스트
echo "🐳 Docker 통합 테스트..."

# 간단한 Dockerfile 생성
cat > Dockerfile.quality << 'EOF'
FROM python:3.9-slim

WORKDIR /app

RUN pip install black isort flake8 mypy bandit

COPY test_quality/ ./test_quality/

CMD ["bash"]
EOF

# Docker 이미지 빌드
docker build -f Dockerfile.quality -t code-quality-test .

# 컨테이너에서 품질 도구 실행
docker run --rm code-quality-test bash -c "
    echo '🔍 Docker에서 품질 검사'
    black --check test_quality/
    isort --check test_quality/
    flake8 test_quality/
    echo '✅ Docker 품질 검사 완료'
"

# 정리
docker rmi code-quality-test
rm Dockerfile.quality
```

---

## 📊 성능 벤치마크

### 기준 성능 지표

| 도구 | 작은 프로젝트 (< 10 파일) | 중간 프로젝트 (< 100 파일) | 대형 프로젝트 (< 1000 파일) |
|------|-------------------------|---------------------------|----------------------------|
| Black | < 2초 | < 10초 | < 30초 |
| isort | < 1초 | < 5초 | < 15초 |
| flake8 | < 3초 | < 15초 | < 45초 |
| mypy | < 5초 | < 30초 | < 120초 |
| bandit | < 2초 | < 10초 | < 30초 |

### 성능 테스트 실행

```bash
echo "⏱️ 성능 벤치마크 테스트..."

# 대용량 테스트 파일 생성
mkdir -p perf_test
for i in {1..100}; do
    cat > "perf_test/module_$i.py" << EOF
"""Performance test module $i"""
import sys
import os
from typing import Dict, List, Optional

class TestClass$i:
    def method(self, data: List[Dict]) -> Optional[str]:
        return f"result_{data[0] if data else 'empty'}"
EOF
done

# 성능 측정
echo "📏 성능 측정 시작..."

time black perf_test/
time isort perf_test/
time flake8 perf_test/
time mypy perf_test/
time bandit -r perf_test/

# 정리
rm -rf perf_test/
```

---

## 🔧 알려진 문제 및 해결책

### 일반적인 문제들

**문제 1: 패키지 설치 오류**
```bash
# 해결책: 가상환경 재생성
rm -rf venv/
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install black isort flake8 mypy bandit pre-commit
```

**문제 2: Pre-commit 설치 실패**
```bash
# 해결책: Pre-commit 재설치
pip uninstall pre-commit
pip install pre-commit
pre-commit clean
pre-commit install --install-hooks
```

**문제 3: MyPy import 오류**
```bash
# 해결책: 타입 스텁 설치
pip install types-requests types-PyYAML types-setuptools
# 또는 mypy 설정에서 ignore_missing_imports = true
```

**문제 4: Black과 isort 충돌**
```bash
# 해결책: isort 프로필 설정
# pyproject.toml에 profile = "black" 추가
isort --profile black .
```

**문제 5: flake8 라인 길이 오류**
```bash
# 해결책: .flake8에서 E501 무시
# ignore = E501,W503
# max-line-length = 88
```

**문제 6: Docker 권한 문제**
```bash
# 해결책: Docker 그룹 추가
sudo usermod -aG docker $USER
# 또는 sudo로 실행
sudo docker run ...
```

**문제 7: WSL 경로 문제**
```bash
# 해결책: 올바른 WSL 경로 사용
cd /mnt/c/dev/movie-mlops  # Windows 경로
# 또는
cd ~/projects/movie-mlops  # WSL 네이티브 경로
```

### 환경별 특이사항

**WSL Ubuntu 환경:**
- Windows와 Linux 경로 혼용 주의
- 권한 설정 확인
- Docker Desktop 연동 확인

**Docker 환경:**
- 볼륨 마운트 경로 확인
- 네트워크 설정 확인
- 이미지 크기 최적화

---

## 📋 검증 체크리스트

### ✅ 필수 검증 항목

- [ ] **환경 설정**
  - [ ] Python 3.8+ 설치됨
  - [ ] 가상환경 생성 및 활성화
  - [ ] 모든 품질 도구 설치됨

- [ ] **설정 파일**
  - [ ] pyproject.toml 생성됨
  - [ ] .flake8 생성됨
  - [ ] .pre-commit-config.yaml 생성됨
  - [ ] .pylintrc 생성됨

- [ ] **개별 도구 테스트**
  - [ ] Black 포맷터 정상 작동
  - [ ] isort import 정렬 정상 작동
  - [ ] flake8 스타일 검사 정상 작동
  - [ ] MyPy 타입 검사 정상 작동
  - [ ] Bandit 보안 검사 정상 작동

- [ ] **통합 테스트**
  - [ ] Pre-commit Hook 정상 작동
  - [ ] VSCode 통합 설정 완료
  - [ ] Docker 환경 테스트 통과

- [ ] **자동화**
  - [ ] 품질 검사 스크립트 작동
  - [ ] 품질 수정 스크립트 작동
  - [ ] CI/CD 파이프라인 준비

### 🎯 성능 검증

- [ ] **속도 기준**
  - [ ] Black: 소규모 프로젝트 < 2초
  - [ ] isort: 소규모 프로젝트 < 1초
  - [ ] flake8: 소규모 프로젝트 < 3초
  - [ ] 전체 파이프라인 < 30초

- [ ] **메모리 사용량**
  - [ ] 정상 범위 내 메모리 사용
  - [ ] 메모리 누수 없음

### 🔄 실제 워크플로우 검증

- [ ] **개발 시나리오**
  - [ ] 새 파일 생성 시 자동 포맷팅
  - [ ] Git 커밋 시 Pre-commit 실행
  - [ ] 품질 이슈 자동 수정

- [ ] **협업 시나리오**
  - [ ] 팀원 간 일관된 코드 스타일
  - [ ] 설정 파일 공유 가능
  - [ ] CI/CD 통합 준비

---

## 🎉 성공 기준

### 🏆 완전 성공 (100%)
- 모든 품질 도구 정상 설치 및 작동
- 설정 파일 모두 생성되고 적용됨
- Pre-commit Hook 정상 작동
- Docker 통합 성공
- 성능 기준 모두 만족

### 👍 부분 성공 (80%+)
- 핵심 도구들(Black, isort, flake8) 정상 작동
- 기본 설정 파일 생성됨
- 수동 실행 시 정상 작동
- 일부 통합 테스트 성공

### 🔧 개선 필요 (60%+)
- 기본 도구 설치됨
- 일부 기능 작동함
- 추가 설정 및 튜닝 필요

### ❌ 실패 (60% 미만)
- 기본 도구 설치 실패
- 설정 파일 문제
- 환경 구성 문제

---

## 📞 지원 및 문의

문제가 발생하거나 추가 도움이 필요한 경우:

1. **자동화 스크립트 재실행**: `./setup_and_test_3.5.sh`
2. **로그 확인**: `results/3.5-code-quality-tools/test_log_*.txt`
3. **리포트 검토**: `results/3.5-code-quality-tools/test_report_*.json`
4. **수동 테스트**: 위의 수동 테스트 가이드 참조

---

이 가이드를 통해 3.5 Code Quality Tools Configuration이 완벽하게 설정되고 테스트되었습니다! 🎉