# 9단계: 이벤트 기반 아키텍처 완성 - 상세 구현 가이드

## 📋 단계 개요

**목표**: 완전 자율적인 이벤트 기반 ML 생태계 구축하여 지능형 자동화 시스템 완성

**핵심 가치**: 시스템이 이벤트에 자동으로 반응하여 데이터 변화, 모델 성능 저하, 비즈니스 요구사항에 즉시 대응하는 완전 자율 운영 시스템

---

## 🎯 9.1 Apache Kafka 설치 및 설정

### 목표
고성능 분산 이벤트 스트리밍 플랫폼으로 실시간 이벤트 처리 체계 구축

### 상세 구현 사항

#### **9.1.1 Kafka 클러스터 설정**
- **Docker Compose를 활용한 Kafka 환경 구축**
  ```yaml
  # docker-compose.kafka.yml
  version: '3.8'
  
  services:
    zookeeper:
      image: confluentinc/cp-zookeeper:7.7.1
      hostname: zookeeper
      container_name: zookeeper
      ports:
        - "2181:2181"
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181
        ZOOKEEPER_TICK_TIME: 2000
      volumes:
        - zookeeper_data:/var/lib/zookeeper/data
        - zookeeper_logs:/var/lib/zookeeper/log
  
    kafka:
      image: confluentinc/cp-kafka:7.7.1
      hostname: kafka
      container_name: kafka
      depends_on:
        - zookeeper
      ports:
        - "9092:9092"
        - "19092:19092"
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_JMX_PORT: 9101
        KAFKA_JMX_HOSTNAME: localhost
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      volumes:
        - kafka_data:/var/lib/kafka/data
  
    schema-registry:
      image: confluentinc/cp-schema-registry:7.7.1
      hostname: schema-registry
      container_name: schema-registry
      depends_on:
        - kafka
      ports:
        - "8081:8081"
      environment:
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:29092'
        SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  
    kafka-ui:
      image: provectuslabs/kafka-ui:latest
      container_name: kafka-ui
      depends_on:
        - kafka
        - schema-registry
      ports:
        - "8080:8080"
      environment:
        KAFKA_CLUSTERS_0_NAME: local
        KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
        KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
        DYNAMIC_CONFIG_ENABLED: 'true'
  
  volumes:
    zookeeper_data:
    zookeeper_logs:
    kafka_data:
  ```

#### **9.1.2 토픽 설계 및 생성**
- **MLOps 이벤트 토픽 구조**
  ```bash
  # 토픽 생성 스크립트
  #!/bin/bash
  
  # Kafka 브로커 주소
  KAFKA_BROKER="localhost:9092"
  
  # 데이터 관련 토픽
  kafka-topics --create --topic data.ingested --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  kafka-topics --create --topic data.processed --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  kafka-topics --create --topic data.quality.issues --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic data.drift.detected --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  
  # 모델 관련 토픽
  kafka-topics --create --topic model.training.started --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic model.training.completed --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic model.evaluation.completed --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic model.deployed --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic model.performance.degraded --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  
  # 예측 관련 토픽
  kafka-topics --create --topic prediction.request --bootstrap-server $KAFKA_BROKER --partitions 5 --replication-factor 1
  kafka-topics --create --topic prediction.completed --bootstrap-server $KAFKA_BROKER --partitions 5 --replication-factor 1
  kafka-topics --create --topic prediction.feedback --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  
  # 시스템 모니터링 토픽
  kafka-topics --create --topic system.metrics --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  kafka-topics --create --topic system.alerts --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  kafka-topics --create --topic system.health --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  
  # 비즈니스 이벤트 토픽
  kafka-topics --create --topic business.user.interaction --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  kafka-topics --create --topic business.recommendation.clicked --bootstrap-server $KAFKA_BROKER --partitions 3 --replication-factor 1
  kafka-topics --create --topic business.feedback.received --bootstrap-server $KAFKA_BROKER --partitions 2 --replication-factor 1
  
  echo "✅ 모든 Kafka 토픽 생성 완료"
  ```

---

## 🎯 9.2 이벤트 기반 트리거 시스템 구축

### 목표
다양한 이벤트에 자동으로 반응하는 지능형 트리거 시스템 구현

### 상세 구현 사항

#### **9.2.1 이벤트 생산자 및 소비자 구현**
- **통합 이벤트 처리 시스템**
  ```python
  # src/events/event_manager.py
  import asyncio
  import json
  from typing import Dict, Any, List, Callable
  from kafka import KafkaProducer, KafkaConsumer
  from kafka.errors import KafkaError
  import logging
  from datetime import datetime
  import uuid
  
  class EventManager:
      \"\"\"통합 이벤트 관리자\"\"\"
      
      def __init__(self, bootstrap_servers: str = "localhost:9092"):
          self.bootstrap_servers = bootstrap_servers
          self.producer = None
          self.consumers = {}
          self.event_handlers = {}
          self.logger = logging.getLogger(__name__)
          
      def connect_producer(self):
          \"\"\"Kafka 프로듀서 연결\"\"\"
          try:
              self.producer = KafkaProducer(
                  bootstrap_servers=self.bootstrap_servers,
                  value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8'),
                  key_serializer=lambda k: str(k).encode('utf-8') if k else None,
                  acks='all',
                  retries=3,
                  retry_backoff_ms=1000
              )
              self.logger.info("Kafka 프로듀서 연결 성공")
              
          except Exception as e:
              self.logger.error(f"Kafka 프로듀서 연결 실패: {e}")
              raise
              
      def publish_event(self, topic: str, event_data: Dict[str, Any], 
                       key: str = None) -> bool:
          \"\"\"이벤트 발행\"\"\"
          if not self.producer:
              self.connect_producer()
              
          try:
              # 이벤트 메타데이터 추가
              enriched_event = {
                  **event_data,
                  "event_id": str(uuid.uuid4()),
                  "timestamp": datetime.now().isoformat(),
                  "source": "mlops_system"
              }
              
              future = self.producer.send(topic, value=enriched_event, key=key)
              record_metadata = future.get(timeout=10)
              
              self.logger.info(
                  f"이벤트 발행 성공: {topic}",
                  extra={"topic": topic, "event_id": enriched_event["event_id"]}
              )
              
              return True
              
          except Exception as e:
              self.logger.error(f"이벤트 발행 실패: {e}")
              return False
              
      def register_handler(self, topic: str, handler: Callable):
          \"\"\"이벤트 핸들러 등록\"\"\"
          if topic not in self.event_handlers:
              self.event_handlers[topic] = []
          self.event_handlers[topic].append(handler)
          
      async def start_consuming(self, topics: List[str], group_id: str):
          \"\"\"이벤트 소비 시작\"\"\"
          try:
              consumer = KafkaConsumer(
                  *topics,
                  bootstrap_servers=self.bootstrap_servers,
                  group_id=group_id,
                  value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                  auto_offset_reset='latest',
                  enable_auto_commit=True
              )
              
              self.consumers[group_id] = consumer
              self.logger.info(f"이벤트 소비 시작: {topics} (그룹: {group_id})")
              
              while True:
                  message_batch = consumer.poll(timeout_ms=1000)
                  
                  for topic_partition, messages in message_batch.items():
                      for message in messages:
                          await self._process_message(message.topic, message.value)
                          
          except Exception as e:
              self.logger.error(f"이벤트 소비 실패: {e}")
              
      async def _process_message(self, topic: str, event_data: Dict[str, Any]):
          \"\"\"메시지 처리\"\"\"
          if topic in self.event_handlers:
              for handler in self.event_handlers[topic]:
                  try:
                      await handler(event_data)
                  except Exception as e:
                      self.logger.error(
                          f"이벤트 핸들러 실행 실패: {e}",
                          extra={"topic": topic, "handler": handler.__name__}
                      )
  
  # 자동 재훈련 트리거
  class AutoRetrainingTrigger:
      \"\"\"자동 재훈련 트리거\"\"\"
      
      def __init__(self, event_manager: EventManager, retraining_service):
          self.event_manager = event_manager
          self.retraining_service = retraining_service
          self.logger = logging.getLogger(__name__)
          
          # 핸들러 등록
          self.event_manager.register_handler("data.drift.detected", self.handle_data_drift)
          self.event_manager.register_handler("model.performance.degraded", self.handle_performance_degradation)
          
      async def handle_data_drift(self, event_data: Dict[str, Any]):
          \"\"\"데이터 드리프트 처리\"\"\"
          severity = event_data.get("severity", "LOW")
          model_version = event_data.get("model_version", "unknown")
          
          self.logger.info(
              f"데이터 드리프트 감지됨: {severity}",
              extra={"model_version": model_version, "severity": severity}
          )
          
          # 심각도에 따른 자동 대응
          if severity in ["HIGH", "CRITICAL"]:
              await self._trigger_emergency_retraining(event_data)
          elif severity == "MEDIUM":
              await self._schedule_retraining(event_data)
          
          # 알림 발송
          await self._send_drift_alert(event_data)
          
      async def handle_performance_degradation(self, event_data: Dict[str, Any]):
          \"\"\"성능 저하 처리\"\"\"
          action_required = event_data.get("action_required", "NONE")
          model_name = event_data.get("model_name")
          
          self.logger.info(
              f"모델 성능 저하 감지: {model_name}",
              extra={"model_name": model_name, "action": action_required}
          )
          
          if action_required == "RETRAIN":
              await self._trigger_performance_retraining(event_data)
          elif action_required == "ROLLBACK":
              await self._trigger_rollback(event_data)
              
      async def _trigger_emergency_retraining(self, event_data: Dict[str, Any]):
          \"\"\"긴급 재훈련 트리거\"\"\"
          model_version = event_data.get("model_version")
          
          retraining_job = await self.retraining_service.start_retraining(
              model_name=model_version.split("@")[0] if "@" in model_version else "movie_recommender",
              reason="data_drift_critical",
              priority="high",
              metadata=event_data
          )
          
          self.logger.info(f"긴급 재훈련 시작: {retraining_job['job_id']}")
          
      async def _schedule_retraining(self, event_data: Dict[str, Any]):
          \"\"\"재훈련 스케줄링\"\"\"
          model_version = event_data.get("model_version")
          
          scheduled_job = await self.retraining_service.schedule_retraining(
              model_name=model_version.split("@")[0] if "@" in model_version else "movie_recommender",
              reason="data_drift_medium",
              schedule_time="next_maintenance_window"
          )
          
          self.logger.info(f"재훈련 스케줄됨: {scheduled_job['job_id']}")
          
      async def _send_drift_alert(self, event_data: Dict[str, Any]):
          \"\"\"드리프트 알림 발송\"\"\"
          alert_event = {
              "event_type": "drift_alert",
              "severity": event_data.get("severity"),
              "model_version": event_data.get("model_version"),
              "drift_score": event_data.get("drift_score"),
              "message": f"데이터 드리프트 감지: {event_data.get('severity')} 수준"
          }
          
          self.event_manager.publish_event("system.alerts", alert_event)
  ```

---

## 🎯 9.3 자동 대응 시스템

### 목표
드리프트 감지, 성능 저하, 모델 승급 등의 이벤트에 자동으로 대응하는 시스템 구현

### 상세 구현 사항

#### **9.3.1 자동 대응 로직**
- **지능형 대응 시스템**
  ```python
  # src/automation/auto_response_system.py
  import asyncio
  from typing import Dict, Any, List, Optional
  from datetime import datetime, timedelta
  from enum import Enum
  import logging
  
  class ResponseAction(Enum):
      RETRAIN = "retrain"
      ROLLBACK = "rollback"
      SCALE_UP = "scale_up"
      SCALE_DOWN = "scale_down"
      ALERT = "alert"
      MONITOR = "monitor"
      IGNORE = "ignore"
  
  class ResponseSeverity(Enum):
      LOW = "low"
      MEDIUM = "medium"
      HIGH = "high"
      CRITICAL = "critical"
  
  class AutoResponseSystem:
      \"\"\"자동 대응 시스템\"\"\"
      
      def __init__(self, event_manager, model_service, deployment_service, alert_service):
          self.event_manager = event_manager
          self.model_service = model_service
          self.deployment_service = deployment_service
          self.alert_service = alert_service
          self.logger = logging.getLogger(__name__)
          
          # 대응 규칙 정의
          self.response_rules = self._define_response_rules()
          
          # 대응 히스토리
          self.response_history = []
          
          # 쿨다운 관리 (중복 대응 방지)
          self.cooldown_periods = {}
          
      def _define_response_rules(self) -> Dict[str, Dict]:
          \"\"\"대응 규칙 정의\"\"\"
          return {
              "data_drift_detected": {
                  "LOW": ResponseAction.MONITOR,
                  "MEDIUM": ResponseAction.RETRAIN,
                  "HIGH": ResponseAction.RETRAIN,
                  "CRITICAL": ResponseAction.RETRAIN
              },
              "model_performance_degraded": {
                  "LOW": ResponseAction.MONITOR,
                  "MEDIUM": ResponseAction.RETRAIN,
                  "HIGH": ResponseAction.ROLLBACK,
                  "CRITICAL": ResponseAction.ROLLBACK
              },
              "system_overload": {
                  "LOW": ResponseAction.MONITOR,
                  "MEDIUM": ResponseAction.SCALE_UP,
                  "HIGH": ResponseAction.SCALE_UP,
                  "CRITICAL": ResponseAction.SCALE_UP
              },
              "prediction_latency_high": {
                  "LOW": ResponseAction.MONITOR,
                  "MEDIUM": ResponseAction.SCALE_UP,
                  "HIGH": ResponseAction.SCALE_UP,
                  "CRITICAL": ResponseAction.SCALE_UP
              },
              "service_health_check_failed": {
                  "LOW": ResponseAction.ALERT,
                  "MEDIUM": ResponseAction.ROLLBACK,
                  "HIGH": ResponseAction.ROLLBACK,
                  "CRITICAL": ResponseAction.ROLLBACK
              }
          }
          
      async def process_event(self, event_type: str, event_data: Dict[str, Any]):
          \"\"\"이벤트 처리 및 자동 대응\"\"\"
          try:
              # 심각도 평가
              severity = self._assess_severity(event_type, event_data)
              
              # 대응 액션 결정
              action = self._determine_action(event_type, severity)
              
              # 쿨다운 확인
              if self._is_in_cooldown(event_type, action):
                  self.logger.info(f"쿨다운 중이므로 대응 생략: {event_type} - {action.value}")
                  return
              
              # 대응 실행
              success = await self._execute_response(action, event_data)
              
              # 대응 기록
              self._record_response(event_type, action, success, event_data)
              
              # 쿨다운 설정
              self._set_cooldown(event_type, action)
              
              self.logger.info(
                  f"자동 대응 완료: {event_type} -> {action.value} (성공: {success})",
                  extra={
                      "event_type": event_type,
                      "action": action.value,
                      "severity": severity.value,
                      "success": success
                  }
              )
              
          except Exception as e:
              self.logger.error(f"자동 대응 실패: {e}")
              
      def _assess_severity(self, event_type: str, event_data: Dict[str, Any]) -> ResponseSeverity:
          \"\"\"이벤트 심각도 평가\"\"\"
          
          # 기본 심각도 (이벤트 데이터에서 추출)
          severity_str = event_data.get("severity", "MEDIUM").upper()
          
          try:
              base_severity = ResponseSeverity(severity_str.lower())
          except ValueError:
              base_severity = ResponseSeverity.MEDIUM
          
          # 컨텍스트 기반 심각도 조정
          if event_type == "data_drift_detected":
              drift_score = event_data.get("drift_score", 0)
              affected_features = len(event_data.get("affected_features", []))
              
              # 드리프트 점수와 영향받은 피처 수에 따른 조정
              if drift_score > 0.8 or affected_features > 5:
                  return ResponseSeverity.CRITICAL
              elif drift_score > 0.6 or affected_features > 3:
                  return ResponseSeverity.HIGH
                  
          elif event_type == "model_performance_degraded":
              performance_drop = event_data.get("performance_drop", 0)
              
              # 성능 저하 정도에 따른 조정
              if performance_drop > 0.15:  # 15% 이상 저하
                  return ResponseSeverity.CRITICAL
              elif performance_drop > 0.10:  # 10% 이상 저하
                  return ResponseSeverity.HIGH
                  
          return base_severity
          
      def _determine_action(self, event_type: str, severity: ResponseSeverity) -> ResponseAction:
          \"\"\"대응 액션 결정\"\"\"
          
          rules = self.response_rules.get(event_type, {})
          action = rules.get(severity.value.upper(), ResponseAction.ALERT)
          
          # 추가 컨텍스트 고려
          current_time = datetime.now()
          
          # 업무 시간 외에는 알림만 발송
          if current_time.hour < 6 or current_time.hour > 22:
              if action in [ResponseAction.RETRAIN, ResponseAction.ROLLBACK]:
                  self.logger.info("업무 시간 외이므로 알림으로 변경")
                  return ResponseAction.ALERT
          
          # 최근 대응 히스토리 확인
          recent_responses = self._get_recent_responses(event_type, hours=1)
          if len(recent_responses) > 3:
              self.logger.info("최근 대응이 빈번하므로 모니터링으로 변경")
              return ResponseAction.MONITOR
              
          return action
          
      async def _execute_response(self, action: ResponseAction, event_data: Dict[str, Any]) -> bool:
          \"\"\"대응 액션 실행\"\"\"
          try:
              if action == ResponseAction.RETRAIN:
                  return await self._execute_retrain(event_data)
                  
              elif action == ResponseAction.ROLLBACK:
                  return await self._execute_rollback(event_data)
                  
              elif action == ResponseAction.SCALE_UP:
                  return await self._execute_scale_up(event_data)
                  
              elif action == ResponseAction.SCALE_DOWN:
                  return await self._execute_scale_down(event_data)
                  
              elif action == ResponseAction.ALERT:
                  return await self._execute_alert(event_data)
                  
              elif action == ResponseAction.MONITOR:
                  return await self._execute_monitor(event_data)
                  
              else:
                  self.logger.info(f"무시됨: {action.value}")
                  return True
                  
          except Exception as e:
              self.logger.error(f"대응 액션 실행 실패: {action.value} - {e}")
              return False
              
      async def _execute_retrain(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"재훈련 실행\"\"\"
          model_name = event_data.get("model_name", "movie_recommender")
          reason = event_data.get("event_type", "unknown")
          
          retraining_job = await self.model_service.start_retraining(
              model_name=model_name,
              reason=reason,
              priority="high"
          )
          
          self.logger.info(f"자동 재훈련 시작: {retraining_job.get('job_id')}")
          return True
          
      async def _execute_rollback(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"모델 롤백 실행\"\"\"
          model_name = event_data.get("model_name", "movie_recommender")
          
          rollback_result = await self.deployment_service.rollback_to_previous_stable(
              model_name=model_name,
              reason="auto_response_rollback"
          )
          
          self.logger.info(f"자동 롤백 완료: {rollback_result.get('previous_version')}")
          return True
          
      async def _execute_scale_up(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"스케일 업 실행\"\"\"
          service_name = event_data.get("service_name", "mlops-api")
          
          scale_result = await self.deployment_service.scale_service(
              service_name=service_name,
              action="up",
              target_instances="+2"
          )
          
          self.logger.info(f"자동 스케일 업 완료: {scale_result.get('new_instance_count')}")
          return True
          
      async def _execute_scale_down(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"스케일 다운 실행\"\"\"
          service_name = event_data.get("service_name", "mlops-api")
          
          scale_result = await self.deployment_service.scale_service(
              service_name=service_name,
              action="down",
              target_instances="-1"
          )
          
          self.logger.info(f"자동 스케일 다운 완료: {scale_result.get('new_instance_count')}")
          return True
          
      async def _execute_alert(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"알림 발송\"\"\"
          alert_data = {
              "title": f"MLOps 시스템 알림: {event_data.get('event_type', 'Unknown')}",
              "message": self._format_alert_message(event_data),
              "severity": event_data.get("severity", "medium"),
              "timestamp": datetime.now().isoformat(),
              "source_event": event_data
          }
          
          await self.alert_service.send_alert(alert_data)
          return True
          
      async def _execute_monitor(self, event_data: Dict[str, Any]) -> bool:
          \"\"\"모니터링 강화\"\"\"
          model_name = event_data.get("model_name", "movie_recommender")
          
          # 모니터링 빈도 증가
          await self.model_service.increase_monitoring_frequency(
              model_name=model_name,
              duration_hours=2,
              check_interval_seconds=30
          )
          
          self.logger.info(f"모니터링 강화됨: {model_name}")
          return True
          
      def _format_alert_message(self, event_data: Dict[str, Any]) -> str:
          \"\"\"알림 메시지 포맷팅\"\"\"
          event_type = event_data.get("event_type", "Unknown")
          
          if event_type == "data_drift_detected":
              return f\"\"\"
              🚨 데이터 드리프트 감지
              
              모델: {event_data.get('model_version', 'Unknown')}
              드리프트 점수: {event_data.get('drift_score', 0):.3f}
              영향받은 피처: {len(event_data.get('affected_features', []))}개
              심각도: {event_data.get('severity', 'Unknown')}
              
              조치가 필요합니다.
              \"\"\"
              
          elif event_type == "model_performance_degraded":
              return f\"\"\"
              ⚠️ 모델 성능 저하
              
              모델: {event_data.get('model_name', 'Unknown')}
              성능 저하: {event_data.get('performance_drop', 0):.2%}
              현재 성능: {event_data.get('current_performance', 0):.3f}
              기준 성능: {event_data.get('baseline_performance', 0):.3f}
              
              검토가 필요합니다.
              \"\"\"
              
          else:
              return f\"MLOps 시스템 이벤트: {event_type}\\n\\n{event_data}\"
              
      def _is_in_cooldown(self, event_type: str, action: ResponseAction) -> bool:
          \"\"\"쿨다운 확인\"\"\"
          key = f"{event_type}:{action.value}"
          
          if key in self.cooldown_periods:
              cooldown_until = self.cooldown_periods[key]
              return datetime.now() < cooldown_until
              
          return False
          
      def _set_cooldown(self, event_type: str, action: ResponseAction):
          \"\"\"쿨다운 설정\"\"\"
          key = f"{event_type}:{action.value}"
          
          # 액션별 쿨다운 시간 설정
          cooldown_minutes = {
              ResponseAction.RETRAIN: 60,    # 1시간
              ResponseAction.ROLLBACK: 30,   # 30분
              ResponseAction.SCALE_UP: 10,   # 10분
              ResponseAction.SCALE_DOWN: 10, # 10분
              ResponseAction.ALERT: 5,       # 5분
              ResponseAction.MONITOR: 2      # 2분
          }
          
          minutes = cooldown_minutes.get(action, 5)
          self.cooldown_periods[key] = datetime.now() + timedelta(minutes=minutes)
          
      def _record_response(self, event_type: str, action: ResponseAction, 
                          success: bool, event_data: Dict[str, Any]):
          \"\"\"대응 기록\"\"\"
          record = {
              "timestamp": datetime.now(),
              "event_type": event_type,
              "action": action.value,
              "success": success,
              "event_data": event_data
          }
          
          self.response_history.append(record)
          
          # 히스토리 크기 제한 (최근 1000개만 유지)
          if len(self.response_history) > 1000:
              self.response_history = self.response_history[-1000:]
              
      def _get_recent_responses(self, event_type: str, hours: int = 24) -> List[Dict]:
          \"\"\"최근 대응 히스토리 조회\"\"\"
          cutoff_time = datetime.now() - timedelta(hours=hours)
          
          return [
              record for record in self.response_history
              if record["timestamp"] >= cutoff_time and record["event_type"] == event_type
          ]
  ```

---

## 🎯 9.4 비즈니스 이벤트 기반 예측 실행

### 목표
비즈니스 이벤트에 즉시 반응하여 실시간 예측 및 추천 서비스 제공

### 상세 구현 사항

#### **9.4.1 실시간 추천 시스템**
- **이벤트 기반 실시간 추천**
  ```python
  # src/recommendations/realtime_recommender.py
  import asyncio
  from typing import Dict, Any, List, Optional
  from datetime import datetime, timedelta
  import logging
  import json
  
  class RealtimeRecommender:
      \"\"\"실시간 추천 시스템\"\"\"
      
      def __init__(self, event_manager, model_service, user_service, cache_service):
          self.event_manager = event_manager
          self.model_service = model_service
          self.user_service = user_service
          self.cache_service = cache_service
          self.logger = logging.getLogger(__name__)
          
          # 사용자 활동 스트림
          self.user_activity_streams = {}
          
          # 이벤트 핸들러 등록
          self.event_manager.register_handler(
              "business.user.interaction", 
              self.handle_user_interaction
          )
          self.event_manager.register_handler(
              "business.recommendation.clicked",
              self.handle_recommendation_click
          )
          
      async def handle_user_interaction(self, event_data: Dict[str, Any]):
          \"\"\"사용자 상호작용 처리\"\"\"
          user_id = event_data.get("user_id")
          interaction_type = event_data.get("interaction_type")
          item_ids = event_data.get("item_ids", [])
          context = event_data.get("context", {})
          
          self.logger.info(
              f"사용자 상호작용 감지: user={user_id}, type={interaction_type}",
              extra={"user_id": user_id, "interaction_type": interaction_type}
          )
          
          # 사용자 활동 스트림 업데이트
          await self._update_user_activity_stream(user_id, event_data)
          
          # 실시간 프로필 업데이트
          await self._update_user_profile_realtime(user_id, interaction_type, item_ids)
          
          # 즉시 추천 갱신 (긍정적 상호작용인 경우)
          if interaction_type in ["like", "click", "purchase", "add_to_cart"]:
              await self._trigger_immediate_recommendation_update(user_id, context)
              
          # 유사 사용자들에게 아이템 추천 강화
          if interaction_type in ["purchase", "high_rating"]:
              await self._boost_item_for_similar_users(user_id, item_ids)
              
      async def handle_recommendation_click(self, event_data: Dict[str, Any]):
          \"\"\"추천 클릭 처리\"\"\"
          user_id = event_data.get("user_id")
          clicked_item_id = event_data.get("item_id")
          recommendation_context = event_data.get("recommendation_context", {})
          
          self.logger.info(
              f"추천 클릭 감지: user={user_id}, item={clicked_item_id}",
              extra={"user_id": user_id, "item_id": clicked_item_id}
          )
          
          # 클릭된 아이템과 유사한 아이템 즉시 추천
          await self._recommend_similar_items(user_id, clicked_item_id)
          
          # 추천 모델 피드백 학습
          await self._learn_from_click_feedback(user_id, clicked_item_id, recommendation_context)
          
          # A/B 테스트 결과 업데이트
          await self._update_ab_test_metrics(recommendation_context)
          
      async def _update_user_activity_stream(self, user_id: int, event_data: Dict[str, Any]):
          \"\"\"사용자 활동 스트림 업데이트\"\"\"
          if user_id not in self.user_activity_streams:
              self.user_activity_streams[user_id] = []
              
          # 활동 추가
          activity = {
              "timestamp": datetime.now(),
              "interaction_type": event_data.get("interaction_type"),
              "item_ids": event_data.get("item_ids", []),
              "context": event_data.get("context", {})
          }
          
          self.user_activity_streams[user_id].append(activity)
          
          # 스트림 크기 제한 (최근 100개 활동만 유지)
          if len(self.user_activity_streams[user_id]) > 100:
              self.user_activity_streams[user_id] = self.user_activity_streams[user_id][-100:]
              
          # 활동 스트림을 캐시에 저장
          await self.cache_service.set(
              f"user_activity_stream:{user_id}",
              json.dumps(self.user_activity_streams[user_id], default=str),
              ttl=3600  # 1시간
          )
          
      async def _update_user_profile_realtime(self, user_id: int, 
                                            interaction_type: str, 
                                            item_ids: List[int]):
          \"\"\"실시간 사용자 프로필 업데이트\"\"\"
          try:
              # 현재 사용자 프로필 조회
              user_profile = await self.user_service.get_user_profile(user_id)
              
              # 상호작용 가중치
              interaction_weights = {
                  "view": 0.1,
                  "click": 0.3,
                  "like": 0.7,
                  "purchase": 1.0,
                  "high_rating": 1.2
              }
              
              weight = interaction_weights.get(interaction_type, 0.1)
              
              # 아이템별 선호도 업데이트
              for item_id in item_ids:
                  item_features = await self._get_item_features(item_id)
                  
                  # 장르 선호도 업데이트
                  for genre in item_features.get("genres", []):
                      current_preference = user_profile.get("genre_preferences", {}).get(genre, 0)
                      new_preference = current_preference + weight * 0.1
                      
                      if "genre_preferences" not in user_profile:
                          user_profile["genre_preferences"] = {}
                      user_profile["genre_preferences"][genre] = min(new_preference, 1.0)
              
              # 업데이트된 프로필 저장
              await self.user_service.update_user_profile(user_id, user_profile)
              
              # 캐시된 추천 무효화
              await self.cache_service.delete(f"recommendations:{user_id}")
              
          except Exception as e:
              self.logger.error(f"사용자 프로필 실시간 업데이트 실패: {e}")
              
      async def _trigger_immediate_recommendation_update(self, user_id: int, 
                                                       context: Dict[str, Any]):
          \"\"\"즉시 추천 갱신 트리거\"\"\"
          try:
              # 실시간 추천 생성
              recommendations = await self.model_service.generate_realtime_recommendations(
                  user_id=user_id,
                  context=context,
                  top_k=20,
                  use_latest_interactions=True
              )
              
              # 캐시에 저장
              await self.cache_service.set(
                  f"realtime_recommendations:{user_id}",
                  json.dumps(recommendations, default=str),
                  ttl=1800  # 30분
              )
              
              # 웹소켓을 통한 실시간 푸시 (구현된 경우)
              await self._push_recommendations_to_user(user_id, recommendations)
              
              self.logger.info(f"실시간 추천 갱신 완료: user={user_id}")
              
          except Exception as e:
              self.logger.error(f"즉시 추천 갱신 실패: {e}")
              
      async def _boost_item_for_similar_users(self, user_id: int, item_ids: List[int]):
          \"\"\"유사 사용자들에게 아이템 추천 강화\"\"\"
          try:
              # 유사 사용자 찾기
              similar_users = await self.user_service.find_similar_users(
                  user_id=user_id,
                  similarity_threshold=0.7,
                  max_users=50
              )
              
              # 각 유사 사용자의 추천에서 해당 아이템들의 가중치 증가
              for similar_user_id in similar_users:
                  await self._boost_items_in_recommendations(similar_user_id, item_ids, boost_factor=1.2)
                  
              self.logger.info(
                  f"유사 사용자 추천 강화 완료: {len(similar_users)}명",
                  extra={"source_user": user_id, "boosted_items": item_ids}
              )
              
          except Exception as e:
              self.logger.error(f"유사 사용자 추천 강화 실패: {e}")
              
      async def _recommend_similar_items(self, user_id: int, clicked_item_id: int):
          \"\"\"유사 아이템 추천\"\"\"
          try:
              # 클릭된 아이템과 유사한 아이템 찾기
              similar_items = await self.model_service.find_similar_items(
                  item_id=clicked_item_id,
                  similarity_threshold=0.8,
                  max_items=10
              )
              
              # 유사 아이템들을 사용자 추천 리스트 상위로 부스트
              await self._boost_items_in_recommendations(
                  user_id, 
                  similar_items, 
                  boost_factor=1.5
              )
              
              # 즉시 추천 업데이트 이벤트 발행
              await self.event_manager.publish_event(
                  "recommendations.updated",
                  {
                      "user_id": user_id,
                      "trigger": "similar_item_click",
                      "source_item": clicked_item_id,
                      "boosted_items": similar_items
                  }
              )
              
          except Exception as e:
              self.logger.error(f"유사 아이템 추천 실패: {e}")
              
      async def _learn_from_click_feedback(self, user_id: int, 
                                         clicked_item_id: int,
                                         recommendation_context: Dict[str, Any]):
          \"\"\"클릭 피드백 학습\"\"\"
          try:
              # 추천 모델에 포지티브 피드백 전달
              await self.model_service.update_model_with_feedback(
                  user_id=user_id,
                  item_id=clicked_item_id,
                  feedback_type="click",
                  feedback_value=1.0,
                  context=recommendation_context
              )
              
              # 클릭률 통계 업데이트
              await self._update_click_through_rate_stats(
                  user_id, 
                  clicked_item_id, 
                  recommendation_context
              )
              
          except Exception as e:
              self.logger.error(f"클릭 피드백 학습 실패: {e}")
              
      async def _push_recommendations_to_user(self, user_id: int, recommendations: List[Dict]):
          \"\"\"사용자에게 실시간 추천 푸시\"\"\"
          # WebSocket이나 Server-Sent Events를 통한 실시간 푸시
          # 실제 구현에서는 WebSocket 매니저나 푸시 서비스 사용
          push_data = {
              "type": "recommendations_update",
              "user_id": user_id,
              "recommendations": recommendations[:10],  # 상위 10개만
              "timestamp": datetime.now().isoformat()
          }
          
          # 푸시 이벤트 발행
          await self.event_manager.publish_event(
              "push.recommendations",
              push_data,
              key=str(user_id)
          )
  ```

---

## ✅ 완료 기준

### 9.4.1 기능적 완료 기준
- [ ] 데이터 변화 시 자동으로 재훈련 파이프라인이 실행됨
- [ ] 모델 성능 저하 감지 시 자동으로 롤백 또는 재훈련됨
- [ ] 비즈니스 이벤트에 즉시 반응하여 실시간 추천 제공
- [ ] 시스템 이상 상황에 자동으로 대응 (스케일링, 알림 등)
- [ ] 완전 무인 운영으로 24시간 자율 동작

### 9.4.2 기술적 완료 기준
- [ ] Apache Kafka 클러스터 안정 운영
- [ ] 이벤트 기반 트리거 시스템 구현 완료
- [ ] 자동 재훈련 및 배포 파이프라인 작동
- [ ] 실시간 추천 시스템 이벤트 연동
- [ ] 지능형 자동 대응 시스템 구현

### 9.4.3 운영적 완료 기준
- [ ] 이벤트 처리 지연시간 1초 이내
- [ ] 자동 대응 성공률 95% 이상
- [ ] 시스템 가용성 99.9% 달성
- [ ] 완전 자율 운영으로 인적 개입 최소화
- [ ] 비즈니스 요구사항 변화에 즉시 대응

---

## 🚀 최종 목표 달성

### 완전 자율적 MLOps 생태계 완성
이 9단계를 완료하면 다음과 같은 완전 자율적인 MLOps 시스템이 구축됩니다:

- **🔄 자동 반응**: 모든 이벤트에 즉시 자동 대응
- **🤖 지능형 의사결정**: AI 기반 자동 판단 및 액션 실행
- **📊 실시간 최적화**: 비즈니스 메트릭 기반 실시간 시스템 조정
- **🛡️ 자가 치유**: 문제 발생 시 자동 복구 및 개선
- **🚀 무한 확장**: 수요에 따른 자동 스케일링

### 비즈니스 가치
- **⏱️ 빠른 대응**: 이슈 발생부터 해결까지 수분 내 완료
- **💰 비용 절감**: 인적 개입 최소화로 운영 비용 대폭 절감
- **📈 성능 향상**: 지속적 자동 최적화로 서비스 품질 향상
- **🔒 안정성**: 24시간 무인 모니터링 및 자동 대응

이것이 바로 **차세대 MLOps의 완성형**입니다! 🎉
