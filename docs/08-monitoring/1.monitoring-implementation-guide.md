# 8단계: 모니터링 및 관측성 강화 - 상세 구현 가이드

## 📋 단계 개요

**목표**: 종합적인 시스템 및 모델 성능 모니터링으로 안정적 운영 보장

**핵심 가치**: 다층 모니터링 체계로 인프라, 애플리케이션, 모델, 비즈니스 성능을 실시간 추적하고 이상 상황 조기 감지

---

## 🎯 8.1 Prometheus 설치 및 메트릭 수집

### 목표
시계열 데이터베이스 기반의 포괄적인 메트릭 수집 시스템 구축

### 상세 구현 사항

#### **8.1.1 Prometheus 서버 설정**
- **설치 및 기본 구성**
  ```yaml
  # prometheus.yml
  global:
    scrape_interval: 15s
    evaluation_interval: 15s
    
  rule_files:
    - "rules/*.yml"
    
  alerting:
    alertmanagers:
      - static_configs:
          - targets:
            - alertmanager:9093
  
  scrape_configs:
    # MLOps API 서버 모니터링
    - job_name: 'mlops-api'
      static_configs:
        - targets: ['localhost:8000']
      metrics_path: '/metrics'
      scrape_interval: 10s
      
    # 시스템 메트릭 수집
    - job_name: 'node-exporter'
      static_configs:
        - targets: ['localhost:9100']
      
    # Redis 모니터링
    - job_name: 'redis'
      static_configs:
        - targets: ['localhost:9121']
        
    # MLflow 모니터링
    - job_name: 'mlflow'
      static_configs:
        - targets: ['localhost:5000']
      metrics_path: '/metrics'
      
    # PostgreSQL 모니터링
    - job_name: 'postgres'
      static_configs:
        - targets: ['localhost:9187']
  ```

- **메트릭 수집 규칙**
  ```yaml
  # rules/mlops_rules.yml
  groups:
    - name: mlops.rules
      rules:
        # API 응답 시간 평균
        - record: mlops:api_response_time_avg
          expr: rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
          
        # 모델 예측 성공률
        - record: mlops:prediction_success_rate
          expr: rate(ml_predictions_total{status="success"}[5m]) / rate(ml_predictions_total[5m])
          
        # 시스템 리소스 사용률
        - record: mlops:cpu_usage_percent
          expr: 100 * (1 - avg by (instance)(rate(node_cpu_seconds_total{mode="idle"}[5m])))
          
        # 메모리 사용률
        - record: mlops:memory_usage_percent
          expr: 100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
  ```

#### **8.1.2 시스템 메트릭 수집기 설정**
- **Node Exporter 설치**
  ```bash
  # Node Exporter 다운로드 및 설치
  wget https://github.com/prometheus/node_exporter/releases/download/v1.8.2/node_exporter-1.8.2.linux-amd64.tar.gz
  tar xvfz node_exporter-1.8.2.linux-amd64.tar.gz
  sudo mv node_exporter-1.8.2.linux-amd64/node_exporter /usr/local/bin/
  
  # 시스템 서비스 등록
  sudo tee /etc/systemd/system/node_exporter.service > /dev/null <<EOF
  [Unit]
  Description=Node Exporter
  Wants=network-online.target
  After=network-online.target
  
  [Service]
  User=prometheus
  Group=prometheus
  Type=simple
  ExecStart=/usr/local/bin/node_exporter
  
  [Install]
  WantedBy=multi-user.target
  EOF
  
  sudo systemctl daemon-reload
  sudo systemctl enable node_exporter
  sudo systemctl start node_exporter
  ```

- **Redis Exporter 설정**
  ```yaml
  # docker-compose.yml에 Redis Exporter 추가
  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      REDIS_ADDR: "redis:6379"
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
    ports:
      - "9121:9121"
    depends_on:
      - redis
  ```

#### **8.1.3 애플리케이션 메트릭 구현**
- **FastAPI 메트릭 미들웨어**
  ```python
  # src/api/middleware/monitoring.py
  from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
  from fastapi import Request, Response
  from fastapi.responses import Response as FastAPIResponse
  import time
  import psutil
  
  # 메트릭 정의
  REQUEST_COUNT = Counter(
      'http_requests_total',
      'Total number of HTTP requests',
      ['method', 'endpoint', 'status_code']
  )
  
  REQUEST_DURATION = Histogram(
      'http_request_duration_seconds',
      'HTTP request duration in seconds',
      ['method', 'endpoint']
  )
  
  PREDICTION_COUNT = Counter(
      'ml_predictions_total',
      'Total number of ML predictions',
      ['model_version', 'status']
  )
  
  PREDICTION_DURATION = Histogram(
      'ml_prediction_duration_seconds',
      'ML prediction duration in seconds',
      ['model_version']
  )
  
  ACTIVE_CONNECTIONS = Gauge(
      'active_connections',
      'Number of active connections'
  )
  
  MODEL_ACCURACY = Gauge(
      'model_accuracy',
      'Current model accuracy',
      ['model_version']
  )
  
  SYSTEM_CPU_USAGE = Gauge(
      'system_cpu_usage_percent',
      'System CPU usage percentage'
  )
  
  SYSTEM_MEMORY_USAGE = Gauge(
      'system_memory_usage_percent',
      'System memory usage percentage'
  )
  
  class MonitoringMiddleware:
      def __init__(self, app):
          self.app = app
          
      async def __call__(self, scope, receive, send):
          if scope["type"] == "http":
              request = Request(scope, receive)
              start_time = time.time()
              
              # 활성 연결 수 증가
              ACTIVE_CONNECTIONS.inc()
              
              try:
                  # 응답 처리
                  response = await self.process_request(request, send)
                  
                  # 메트릭 기록
                  duration = time.time() - start_time
                  method = request.method
                  endpoint = request.url.path
                  status_code = getattr(response, 'status_code', 0)
                  
                  REQUEST_COUNT.labels(
                      method=method,
                      endpoint=endpoint,
                      status_code=status_code
                  ).inc()
                  
                  REQUEST_DURATION.labels(
                      method=method,
                      endpoint=endpoint
                  ).observe(duration)
                  
              finally:
                  # 활성 연결 수 감소
                  ACTIVE_CONNECTIONS.dec()
                  
          else:
              await self.app(scope, receive, send)
      
      async def process_request(self, request: Request, send):
          # 시스템 메트릭 업데이트
          self.update_system_metrics()
          
          # 요청 처리
          response = await self.app(request.scope, request.receive, send)
          return response
      
      def update_system_metrics(self):
          \"\"\"시스템 메트릭 업데이트\"\"\"
          try:
              # CPU 사용률
              cpu_percent = psutil.cpu_percent(interval=None)
              SYSTEM_CPU_USAGE.set(cpu_percent)
              
              # 메모리 사용률
              memory = psutil.virtual_memory()
              SYSTEM_MEMORY_USAGE.set(memory.percent)
              
          except Exception as e:
              print(f"Failed to update system metrics: {e}")
  
  # 메트릭 엔드포인트
  async def metrics_endpoint():
      \"\"\"Prometheus 메트릭 엔드포인트\"\"\"
      return FastAPIResponse(
          content=generate_latest(),
          media_type=CONTENT_TYPE_LATEST
      )
  
  # 모델 예측 메트릭 추적 데코레이터
  def track_prediction(func):
      \"\"\"모델 예측 메트릭 추적 데코레이터\"\"\"
      def wrapper(*args, **kwargs):
          start_time = time.time()
          model_version = "unknown"
          status = "success"
          
          try:
              result = func(*args, **kwargs)
              
              # 모델 버전 추출
              if hasattr(result, 'model_version'):
                  model_version = result.model_version
              
              return result
              
          except Exception as e:
              status = "error"
              raise
          
          finally:
              # 메트릭 기록
              duration = time.time() - start_time
              
              PREDICTION_COUNT.labels(
                  model_version=model_version,
                  status=status
              ).inc()
              
              if status == "success":
                  PREDICTION_DURATION.labels(
                      model_version=model_version
                  ).observe(duration)
      
      return wrapper
  ```

---

## 🎯 8.2 Grafana 대시보드 구축

### 목표
직관적이고 실용적인 시각화 대시보드로 종합적인 시스템 상태 모니터링

### 상세 구현 사항

#### **8.2.1 Grafana 설치 및 설정**
- **Docker Compose로 설치**
  ```yaml
  # docker-compose.monitoring.yml
  version: '3.8'
  
  services:
    prometheus:
      image: prom/prometheus:latest
      container_name: prometheus
      ports:
        - "9090:9090"
      volumes:
        - ./prometheus.yml:/etc/prometheus/prometheus.yml
        - ./rules:/etc/prometheus/rules
        - prometheus_data:/prometheus
      command:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--web.console.templates=/etc/prometheus/consoles'
        - '--storage.tsdb.retention.time=200h'
        - '--web.enable-lifecycle'
        - '--web.enable-admin-api'
    
    grafana:
      image: grafana/grafana:latest
      container_name: grafana
      ports:
        - "3000:3000"
      volumes:
        - grafana_data:/var/lib/grafana
        - ./grafana/provisioning:/etc/grafana/provisioning
        - ./grafana/dashboards:/var/lib/grafana/dashboards
      environment:
        - GF_SECURITY_ADMIN_PASSWORD=admin123
        - GF_USERS_ALLOW_SIGN_UP=false
        - GF_SMTP_ENABLED=true
        - GF_SMTP_HOST=smtp.gmail.com:587
        - GF_SMTP_USER=${SMTP_USER}
        - GF_SMTP_PASSWORD=${SMTP_PASSWORD}
      depends_on:
        - prometheus
    
    alertmanager:
      image: prom/alertmanager:latest
      container_name: alertmanager
      ports:
        - "9093:9093"
      volumes:
        - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
        - alertmanager_data:/alertmanager
  
  volumes:
    prometheus_data:
    grafana_data:
    alertmanager_data:
  ```

- **데이터 소스 자동 설정**
  ```yaml
  # grafana/provisioning/datasources/prometheus.yml
  apiVersion: 1
  
  datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
      editable: true
  ```

#### **8.2.2 MLOps 종합 대시보드 설계**
- **대시보드 JSON 설정**
  ```json
  {
    "dashboard": {
      "id": null,
      "title": "MLOps 종합 모니터링 대시보드",
      "tags": ["mlops", "monitoring"],
      "timezone": "Asia/Seoul",
      "panels": [
        {
          "id": 1,
          "title": "시스템 개요",
          "type": "stat",
          "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
          "targets": [
            {
              "expr": "up{job=\"mlops-api\"}",
              "legendFormat": "API 서버 상태"
            },
            {
              "expr": "mlops:prediction_success_rate",
              "legendFormat": "예측 성공률"
            },
            {
              "expr": "mlops:cpu_usage_percent",
              "legendFormat": "CPU 사용률"
            },
            {
              "expr": "mlops:memory_usage_percent",
              "legendFormat": "메모리 사용률"
            }
          ]
        },
        {
          "id": 2,
          "title": "API 성능 메트릭",
          "type": "graph",
          "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
          "targets": [
            {
              "expr": "rate(http_requests_total[5m])",
              "legendFormat": "요청/초 - {{method}} {{endpoint}}"
            },
            {
              "expr": "mlops:api_response_time_avg",
              "legendFormat": "평균 응답시간"
            }
          ]
        },
        {
          "id": 3,
          "title": "모델 예측 성능",
          "type": "graph",
          "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
          "targets": [
            {
              "expr": "rate(ml_predictions_total[5m])",
              "legendFormat": "예측/초 - {{model_version}} ({{status}})"
            },
            {
              "expr": "histogram_quantile(0.95, rate(ml_prediction_duration_seconds_bucket[5m]))",
              "legendFormat": "95% 예측 지연시간"
            }
          ]
        }
      ],
      "time": {
        "from": "now-1h",
        "to": "now"
      },
      "refresh": "10s"
    }
  }
  ```

#### **8.2.3 특화된 대시보드들**
- **모델 성능 대시보드**
  - 예측 정확도 트렌드
  - 모델 버전별 성능 비교
  - 추론 지연시간 분포
  - 배치 처리 성능

- **인프라 모니터링 대시보드**
  - 시스템 리소스 사용률
  - 네트워크 I/O
  - 디스크 사용량
  - 서비스 가용성

- **비즈니스 메트릭 대시보드**
  - 일일 사용자 수
  - 추천 클릭률
  - 서비스 만족도 지표
  - 수익 관련 메트릭

---

## 🎯 8.3 애플리케이션 로깅 시스템 구축

### 목표
구조화된 로깅으로 애플리케이션 동작 추적 및 디버깅 지원

### 상세 구현 사항

#### **8.3.1 구조화된 로깅 설정**
- **Python 로깅 설정**
  ```python
  # src/core/logging_config.py
  import logging
  import logging.config
  import json
  from datetime import datetime
  import sys
  from pathlib import Path
  
  class JSONFormatter(logging.Formatter):
      \"\"\"JSON 형태 로그 포맷터\"\"\"
      
      def format(self, record):
          log_data = {
              'timestamp': datetime.fromtimestamp(record.created).isoformat(),
              'level': record.levelname,
              'logger': record.name,
              'message': record.getMessage(),
              'module': record.module,
              'function': record.funcName,
              'line': record.lineno
          }
          
          # 추가 필드들
          if hasattr(record, 'user_id'):
              log_data['user_id'] = record.user_id
          if hasattr(record, 'request_id'):
              log_data['request_id'] = record.request_id
          if hasattr(record, 'model_version'):
              log_data['model_version'] = record.model_version
          if hasattr(record, 'execution_time'):
              log_data['execution_time'] = record.execution_time
          
          # 예외 정보
          if record.exc_info:
              log_data['exception'] = self.formatException(record.exc_info)
          
          return json.dumps(log_data, ensure_ascii=False)
  
  def setup_logging(log_level='INFO', log_dir='logs'):
      \"\"\"로깅 시스템 설정\"\"\"
      
      # 로그 디렉토리 생성
      Path(log_dir).mkdir(parents=True, exist_ok=True)
      
      logging_config = {
          'version': 1,
          'disable_existing_loggers': False,
          'formatters': {
              'json': {
                  '()': JSONFormatter,
              },
              'standard': {
                  'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
              }
          },
          'handlers': {
              'console': {
                  'level': log_level,
                  'class': 'logging.StreamHandler',
                  'formatter': 'standard',
                  'stream': sys.stdout
              },
              'file_app': {
                  'level': 'INFO',
                  'class': 'logging.handlers.RotatingFileHandler',
                  'formatter': 'json',
                  'filename': f'{log_dir}/app.log',
                  'maxBytes': 10485760,  # 10MB
                  'backupCount': 10
              },
              'file_error': {
                  'level': 'ERROR',
                  'class': 'logging.handlers.RotatingFileHandler',
                  'formatter': 'json',
                  'filename': f'{log_dir}/error.log',
                  'maxBytes': 10485760,  # 10MB
                  'backupCount': 5
              },
              'file_prediction': {
                  'level': 'INFO',
                  'class': 'logging.handlers.RotatingFileHandler',
                  'formatter': 'json',
                  'filename': f'{log_dir}/prediction.log',
                  'maxBytes': 10485760,  # 10MB
                  'backupCount': 20
              }
          },
          'loggers': {
              '': {  # root logger
                  'handlers': ['console', 'file_app'],
                  'level': log_level,
                  'propagate': False
              },
              'mlops.prediction': {
                  'handlers': ['file_prediction'],
                  'level': 'INFO',
                  'propagate': True
              },
              'mlops.error': {
                  'handlers': ['file_error'],
                  'level': 'ERROR',
                  'propagate': True
              }
          }
      }
      
      logging.config.dictConfig(logging_config)
  
  # 컨텍스트 로거 클래스
  class ContextLogger:
      \"\"\"컨텍스트 정보를 포함하는 로거\"\"\"
      
      def __init__(self, logger_name: str):
          self.logger = logging.getLogger(logger_name)
          self.context = {}
      
      def set_context(self, **kwargs):
          \"\"\"로그 컨텍스트 설정\"\"\"
          self.context.update(kwargs)
      
      def clear_context(self):
          \"\"\"컨텍스트 초기화\"\"\"
          self.context.clear()
      
      def _log_with_context(self, level, msg, *args, **kwargs):
          \"\"\"컨텍스트와 함께 로그 기록\"\"\"
          extra = kwargs.pop('extra', {})
          extra.update(self.context)
          kwargs['extra'] = extra
          getattr(self.logger, level)(msg, *args, **kwargs)
      
      def info(self, msg, *args, **kwargs):
          self._log_with_context('info', msg, *args, **kwargs)
      
      def error(self, msg, *args, **kwargs):
          self._log_with_context('error', msg, *args, **kwargs)
      
      def warning(self, msg, *args, **kwargs):
          self._log_with_context('warning', msg, *args, **kwargs)
      
      def debug(self, msg, *args, **kwargs):
          self._log_with_context('debug', msg, *args, **kwargs)
  ```

#### **8.3.2 로그 수집 및 중앙화**
- **ELK 스택 설정**
  ```yaml
  # docker-compose.logging.yml
  version: '3.8'
  
  services:
    elasticsearch:
      image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
      container_name: elasticsearch
      environment:
        - node.name=elasticsearch
        - cluster.name=mlops-logs
        - discovery.type=single-node
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        - xpack.security.enabled=false
      ulimits:
        memlock:
          soft: -1
          hard: -1
      volumes:
        - elasticsearch_data:/usr/share/elasticsearch/data
      ports:
        - "9200:9200"
    
    logstash:
      image: docker.elastic.co/logstash/logstash:8.15.0
      container_name: logstash
      volumes:
        - ./logstash/config:/usr/share/logstash/pipeline
      ports:
        - "5044:5044"
        - "5000:5000/tcp"
        - "5000:5000/udp"
      environment:
        LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      depends_on:
        - elasticsearch
    
    kibana:
      image: docker.elastic.co/kibana/kibana:8.15.0
      container_name: kibana
      ports:
        - "5601:5601"
      environment:
        ELASTICSEARCH_URL: http://elasticsearch:9200
        ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      depends_on:
        - elasticsearch
    
    filebeat:
      image: docker.elastic.co/beats/filebeat:8.15.0
      container_name: filebeat
      user: root
      volumes:
        - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
        - /var/lib/docker/containers:/var/lib/docker/containers:ro
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - ../logs:/var/log/mlops:ro
      depends_on:
        - logstash
  
  volumes:
    elasticsearch_data:
  ```

- **Filebeat 설정**
  ```yaml
  # filebeat/filebeat.yml
  filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/mlops/*.log
    json.keys_under_root: true
    json.add_error_key: true
    fields:
      service: mlops-api
      environment: production
    fields_under_root: true
    
  - type: docker
    containers.ids:
      - "*"
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"
  
  output.logstash:
    hosts: ["logstash:5044"]
  
  processors:
    - add_host_metadata:
        when.not.contains.tags: forwarded
  ```

---

## 🎯 8.4 데이터 드리프트 감지 시스템

### 목표
모델 입력 데이터의 분포 변화를 실시간 감지하여 모델 성능 저하 예방

### 상세 구현 사항

#### **8.4.1 Evidently 기반 드리프트 감지**
- **드리프트 모니터링 설정**
  ```python
  # src/monitoring/drift_detector.py
  import pandas as pd
  import numpy as np
  from evidently import ColumnMapping
  from evidently.report import Report
  from evidently.metric_preset import DataDriftPreset, DataQualityPreset
  from evidently.metrics import DatasetDriftMetric, ColumnDriftMetric
  from datetime import datetime, timedelta
  import logging
  from typing import Dict, List, Optional, Tuple
  
  class DataDriftDetector:
      \"\"\"데이터 드리프트 감지기\"\"\"
      
      def __init__(self, reference_data: pd.DataFrame, 
                   feature_columns: List[str],
                   target_column: Optional[str] = None,
                   drift_threshold: float = 0.5):
          self.reference_data = reference_data
          self.feature_columns = feature_columns
          self.target_column = target_column
          self.drift_threshold = drift_threshold
          self.logger = logging.getLogger(__name__)
          
          # 컬럼 매핑 설정
          self.column_mapping = ColumnMapping(
              numerical_features=self._get_numerical_features(),
              categorical_features=self._get_categorical_features(),
              target=target_column
          )
      
      def _get_numerical_features(self) -> List[str]:
          \"\"\"수치형 피처 추출\"\"\"
          numerical_features = []
          for col in self.feature_columns:
              if pd.api.types.is_numeric_dtype(self.reference_data[col]):
                  numerical_features.append(col)
          return numerical_features
      
      def _get_categorical_features(self) -> List[str]:
          \"\"\"범주형 피처 추출\"\"\"
          categorical_features = []
          for col in self.feature_columns:
              if not pd.api.types.is_numeric_dtype(self.reference_data[col]):
                  categorical_features.append(col)
          return categorical_features
      
      def detect_drift(self, current_data: pd.DataFrame) -> Dict:
          \"\"\"데이터 드리프트 감지\"\"\"
          try:
              # 데이터 드리프트 리포트 생성
              report = Report(metrics=[
                  DataDriftPreset(),
                  DataQualityPreset(),
                  DatasetDriftMetric()
              ])
              
              report.run(
                  reference_data=self.reference_data,
                  current_data=current_data,
                  column_mapping=self.column_mapping
              )
              
              # 리포트 결과 추출
              result = report.as_dict()
              
              # 드리프트 결과 분석
              drift_info = self._analyze_drift_result(result)
              
              # 알림 필요 여부 결정
              if drift_info['dataset_drift_detected']:
                  self._send_drift_alert(drift_info)
              
              return drift_info
              
          except Exception as e:
              self.logger.error(f"드리프트 감지 실패: {e}")
              raise
      
      def _analyze_drift_result(self, result: Dict) -> Dict:
          \"\"\"드리프트 결과 분석\"\"\"
          metrics = result['metrics']
          
          # 데이터셋 레벨 드리프트
          dataset_drift = None
          for metric in metrics:
              if metric['metric'] == 'DatasetDriftMetric':
                  dataset_drift = metric['result']
                  break
          
          # 컬럼별 드리프트 정보
          column_drifts = {}
          for metric in metrics:
              if metric['metric'] == 'ColumnDriftMetric':
                  column_name = metric['result']['column_name']
                  column_drifts[column_name] = {
                      'drift_detected': metric['result']['drift_detected'],
                      'drift_score': metric['result']['drift_score'],
                      'stattest_name': metric['result']['stattest_name']
                  }
          
          return {
              'timestamp': datetime.now().isoformat(),
              'dataset_drift_detected': dataset_drift['drift_detected'] if dataset_drift else False,
              'drift_share': dataset_drift['drift_share'] if dataset_drift else 0,
              'number_of_drifted_columns': dataset_drift['number_of_drifted_columns'] if dataset_drift else 0,
              'column_drifts': column_drifts,
              'data_quality_issues': self._extract_data_quality_issues(result)
          }
      
      def _extract_data_quality_issues(self, result: Dict) -> Dict:
          \"\"\"데이터 품질 이슈 추출\"\"\"
          issues = {
              'missing_values': {},
              'duplicate_rows': 0,
              'data_type_mismatches': []
          }
          
          # 실제 구현에서는 result에서 데이터 품질 메트릭 추출
          return issues
      
      def _send_drift_alert(self, drift_info: Dict):
          \"\"\"드리프트 알림 전송\"\"\"
          alert_message = f\"\"\"
          🚨 데이터 드리프트 감지됨!
          
          감지 시간: {drift_info['timestamp']}
          드리프트 컬럼 수: {drift_info['number_of_drifted_columns']}
          드리프트 비율: {drift_info['drift_share']:.2%}
          
          영향받은 컬럼들:
          \"\"\"
          
          for col, info in drift_info['column_drifts'].items():
              if info['drift_detected']:
                  alert_message += f\"- {col}: {info['drift_score']:.3f}\\n\"
          
          self.logger.warning(alert_message)
          
          # 실제 알림 시스템으로 전송 (Slack, Email 등)
          # self._send_to_slack(alert_message)
          # self._send_email_alert(alert_message)
      
      def generate_drift_report(self, current_data: pd.DataFrame, 
                              output_path: str = "drift_report.html"):
          \"\"\"드리프트 리포트 HTML 생성\"\"\"
          report = Report(metrics=[
              DataDriftPreset(),
              DataQualityPreset()
          ])
          
          report.run(
              reference_data=self.reference_data,
              current_data=current_data,
              column_mapping=self.column_mapping
          )
          
          report.save_html(output_path)
          self.logger.info(f"드리프트 리포트 저장됨: {output_path}")
  
  # 실시간 드리프트 모니터링 클래스
  class RealTimeDriftMonitor:
      \"\"\"실시간 드리프트 모니터링\"\"\"
      
      def __init__(self, detector: DataDriftDetector, 
                   monitoring_window: int = 1000,
                   check_interval: int = 3600):
          self.detector = detector
          self.monitoring_window = monitoring_window
          self.check_interval = check_interval
          self.current_batch = []
          self.last_check_time = datetime.now()
          self.logger = logging.getLogger(__name__)
      
      def add_prediction_data(self, data: Dict):
          \"\"\"예측 데이터 추가\"\"\"
          self.current_batch.append(data)
          
          # 배치 크기 확인
          if len(self.current_batch) >= self.monitoring_window:
              self._check_drift()
          
          # 시간 기반 확인
          elif (datetime.now() - self.last_check_time).seconds >= self.check_interval:
              if len(self.current_batch) > 0:
                  self._check_drift()
      
      def _check_drift(self):
          \"\"\"드리프트 확인 실행\"\"\"
          try:
              # 배치 데이터를 DataFrame으로 변환
              batch_df = pd.DataFrame(self.current_batch)
              
              # 드리프트 감지
              drift_result = self.detector.detect_drift(batch_df)
              
              # 결과 로깅
              self.logger.info(f"드리프트 체크 완료: {drift_result['dataset_drift_detected']}")
              
              # 배치 초기화
              self.current_batch = []
              self.last_check_time = datetime.now()
              
              return drift_result
              
          except Exception as e:
              self.logger.error(f"드리프트 체크 실패: {e}")
              self.current_batch = []  # 오류 시에도 배치 초기화
  ```

#### **8.4.2 모델 성능 모니터링**
- **성능 지표 추적**
  ```python
  # src/monitoring/model_performance.py
  import pandas as pd
  import numpy as np
  from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
  from typing import Dict, List, Optional, Tuple
  import logging
  from datetime import datetime, timedelta
  
  class ModelPerformanceMonitor:
      \"\"\"모델 성능 모니터링\"\"\"
      
      def __init__(self, model_name: str, baseline_metrics: Dict[str, float]):
          self.model_name = model_name
          self.baseline_metrics = baseline_metrics
          self.performance_history = []
          self.logger = logging.getLogger(__name__)
      
      def log_prediction(self, user_id: int, prediction: List[int], 
                        actual_interaction: Optional[List[int]] = None,
                        feedback_score: Optional[float] = None):
          \"\"\"예측 결과 로깅\"\"\"
          prediction_log = {
              'timestamp': datetime.now(),
              'user_id': user_id,
              'prediction': prediction,
              'actual_interaction': actual_interaction,
              'feedback_score': feedback_score,
              'model_name': self.model_name
          }
          
          self.performance_history.append(prediction_log)
          
          # 성능 평가 (실제 상호작용이 있는 경우)
          if actual_interaction is not None:
              self._evaluate_prediction(prediction, actual_interaction, feedback_score)
      
      def _evaluate_prediction(self, prediction: List[int], 
                             actual: List[int], 
                             feedback_score: Optional[float]):
          \"\"\"개별 예측 평가\"\"\"
          # Hit Rate 계산 (추천 목록에 실제 상호작용한 아이템이 있는지)
          hit_rate = len(set(prediction) & set(actual)) / len(prediction) if prediction else 0
          
          # 피드백 점수 처리
          satisfaction_score = feedback_score if feedback_score is not None else 0
          
          # 메트릭 기록
          self.logger.info(
              f"예측 평가 완료 - Hit Rate: {hit_rate:.3f}, 만족도: {satisfaction_score:.2f}",
              extra={
                  'hit_rate': hit_rate,
                  'satisfaction_score': satisfaction_score,
                  'model_name': self.model_name
              }
          )
      
      def calculate_daily_metrics(self, date: datetime = None) -> Dict[str, float]:
          \"\"\"일일 성능 지표 계산\"\"\"
          if date is None:
              date = datetime.now().date()
          
          # 해당 날짜의 데이터 필터링
          daily_data = [
              log for log in self.performance_history
              if log['timestamp'].date() == date and log['actual_interaction'] is not None
          ]
          
          if not daily_data:
              return {}
          
          # 메트릭 계산
          hit_rates = []
          satisfaction_scores = []
          
          for log in daily_data:
              prediction = log['prediction']
              actual = log['actual_interaction']
              
              # Hit Rate
              hit_rate = len(set(prediction) & set(actual)) / len(prediction) if prediction else 0
              hit_rates.append(hit_rate)
              
              # 만족도 점수
              if log['feedback_score'] is not None:
                  satisfaction_scores.append(log['feedback_score'])
          
          metrics = {
              'date': date.isoformat(),
              'total_predictions': len(daily_data),
              'avg_hit_rate': np.mean(hit_rates) if hit_rates else 0,
              'avg_satisfaction': np.mean(satisfaction_scores) if satisfaction_scores else 0,
              'predictions_with_feedback': len(satisfaction_scores)
          }
          
          # 베이스라인 대비 성능 변화
          if 'hit_rate' in self.baseline_metrics:
              metrics['hit_rate_change'] = metrics['avg_hit_rate'] - self.baseline_metrics['hit_rate']
          
          return metrics
      
      def detect_performance_degradation(self, window_days: int = 7) -> Dict:
          \"\"\"성능 저하 감지\"\"\"
          end_date = datetime.now().date()
          start_date = end_date - timedelta(days=window_days)
          
          # 기간별 메트릭 수집
          daily_metrics = []
          current_date = start_date
          
          while current_date <= end_date:
              metrics = self.calculate_daily_metrics(current_date)
              if metrics:
                  daily_metrics.append(metrics)
              current_date += timedelta(days=1)
          
          if len(daily_metrics) < 2:
              return {'degradation_detected': False, 'message': '충분한 데이터 없음'}
          
          # 트렌드 분석
          recent_performance = np.mean([m['avg_hit_rate'] for m in daily_metrics[-3:]])
          baseline_performance = self.baseline_metrics.get('hit_rate', 0)
          
          degradation_threshold = 0.05  # 5% 성능 저하
          
          performance_drop = baseline_performance - recent_performance
          degradation_detected = performance_drop > degradation_threshold
          
          result = {
              'degradation_detected': degradation_detected,
              'performance_drop': performance_drop,
              'recent_performance': recent_performance,
              'baseline_performance': baseline_performance,
              'window_days': window_days,
              'daily_metrics': daily_metrics
          }
          
          if degradation_detected:
              self._alert_performance_degradation(result)
          
          return result
      
      def _alert_performance_degradation(self, result: Dict):
          \"\"\"성능 저하 알림\"\"\"
          alert_message = f\"\"\"
          ⚠️ 모델 성능 저하 감지!
          
          모델: {self.model_name}
          현재 성능: {result['recent_performance']:.3f}
          기준 성능: {result['baseline_performance']:.3f}
          성능 저하: {result['performance_drop']:.3f}
          \"\"\"
          
          self.logger.warning(alert_message)
  ```

---

## 🎯 8.5 알림 시스템 구축

### 목표
시스템 이상 상황 발생 시 즉시 알림으로 빠른 대응 지원

### 상세 구현 사항

#### **8.5.1 Alertmanager 설정**
- **알림 규칙 정의**
  ```yaml
  # alertmanager.yml
  global:
    smtp_smarthost: 'smtp.gmail.com:587'
    smtp_from: 'mlops-alerts@company.com'
    smtp_auth_username: '${SMTP_USER}'
    smtp_auth_password: '${SMTP_PASSWORD}'
    slack_api_url: '${SLACK_WEBHOOK_URL}'
  
  route:
    group_by: ['alertname']
    group_wait: 10s
    group_interval: 10s
    repeat_interval: 1h
    receiver: 'web.hook'
    routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'
  
  receivers:
  - name: 'web.hook'
    webhook_configs:
    - url: 'http://localhost:5001/'
  
  - name: 'critical-alerts'
    email_configs:
    - to: 'ops-team@company.com'
      subject: '[CRITICAL] MLOps Alert: {{ .GroupLabels.alertname }}'
      body: |
        {{ range .Alerts }}
        Alert: {{ .Annotations.summary }}
        Description: {{ .Annotations.description }}
        {{ end }}
    slack_configs:
    - channel: '#mlops-alerts'
      title: 'CRITICAL MLOps Alert'
      text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
      color: 'danger'
  
  - name: 'warning-alerts'
    slack_configs:
    - channel: '#mlops-monitoring'
      title: 'MLOps Warning'
      text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
      color: 'warning'
  ```

- **Prometheus 알림 규칙**
  ```yaml
  # rules/alerts.yml
  groups:
  - name: mlops-alerts
    rules:
    - alert: APIHighErrorRate
      expr: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.1
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "API 오류율이 높습니다"
        description: "API 오류율이 {{ $value }}%입니다"
    
    - alert: ModelPredictionLatency
      expr: histogram_quantile(0.95, rate(ml_prediction_duration_seconds_bucket[5m])) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "모델 예측 지연시간이 높습니다"
        description: "95% 예측 지연시간이 {{ $value }}초입니다"
    
    - alert: SystemHighCPU
      expr: mlops:cpu_usage_percent > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "시스템 CPU 사용률이 높습니다"
        description: "CPU 사용률이 {{ $value }}%입니다"
    
    - alert: ModelAccuracyDrop
      expr: model_accuracy < 0.8
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "모델 정확도가 떨어졌습니다"
        description: "모델 정확도가 {{ $value }}입니다"
    
    - alert: DataDriftDetected
      expr: increase(data_drift_alerts_total[1h]) > 0
      labels:
        severity: warning
      annotations:
        summary: "데이터 드리프트가 감지되었습니다"
        description: "최근 1시간 동안 데이터 드리프트가 감지되었습니다"
  ```

#### **8.5.2 Slack 통합**
- **Slack 알림 봇 설정**
  ```python
  # src/monitoring/alerting.py
  import requests
  import json
  from typing import Dict, List
  import logging
  from datetime import datetime
  
  class SlackAlerter:
      \"\"\"Slack 알림 발송기\"\"\"
      
      def __init__(self, webhook_url: str, default_channel: str = "#mlops-alerts"):
          self.webhook_url = webhook_url
          self.default_channel = default_channel
          self.logger = logging.getLogger(__name__)
      
      def send_alert(self, title: str, message: str, 
                    severity: str = "info", 
                    channel: str = None) -> bool:
          \"\"\"Slack 알림 전송\"\"\"
          
          color_map = {
              "critical": "danger",
              "warning": "warning", 
              "info": "good"
          }
          
          payload = {
              "channel": channel or self.default_channel,
              "username": "MLOps Monitor",
              "icon_emoji": ":robot_face:",
              "attachments": [{
                  "color": color_map.get(severity, "good"),
                  "title": title,
                  "text": message,
                  "timestamp": int(datetime.now().timestamp()),
                  "fields": [
                      {
                          "title": "Severity",
                          "value": severity.upper(),
                          "short": True
                      },
                      {
                          "title": "Time",
                          "value": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                          "short": True
                      }
                  ]
              }]
          }
          
          try:
              response = requests.post(
                  self.webhook_url,
                  data=json.dumps(payload),
                  headers={'Content-Type': 'application/json'},
                  timeout=10
              )
              
              if response.status_code == 200:
                  self.logger.info(f"Slack 알림 전송 성공: {title}")
                  return True
              else:
                  self.logger.error(f"Slack 알림 전송 실패: {response.status_code}")
                  return False
                  
          except Exception as e:
              self.logger.error(f"Slack 알림 전송 중 오류: {e}")
              return False
      
      def send_drift_alert(self, drift_info: Dict):
          \"\"\"데이터 드리프트 알림\"\"\"
          title = "🚨 Data Drift Detected"
          message = f\"\"\"
          데이터 드리프트가 감지되었습니다!
          
          • 드리프트 컬럼 수: {drift_info['number_of_drifted_columns']}
          • 드리프트 비율: {drift_info['drift_share']:.2%}
          • 감지 시간: {drift_info['timestamp']}
          
          즉시 모델 재훈련을 검토해주세요.
          \"\"\"
          
          self.send_alert(title, message, severity="warning")
      
      def send_performance_alert(self, performance_info: Dict):
          \"\"\"모델 성능 저하 알림\"\"\"
          title = "⚠️ Model Performance Degradation"
          message = f\"\"\"
          모델 성능이 저하되었습니다!
          
          • 현재 성능: {performance_info['recent_performance']:.3f}
          • 기준 성능: {performance_info['baseline_performance']:.3f}
          • 성능 저하: {performance_info['performance_drop']:.3f}
          
          모델 점검이 필요합니다.
          \"\"\"
          
          self.send_alert(title, message, severity="critical")
  
  # 종합 알림 관리자
  class AlertManager:
      \"\"\"알림 관리자\"\"\"
      
      def __init__(self, slack_alerter: SlackAlerter):
          self.slack_alerter = slack_alerter
          self.alert_history = []
          self.logger = logging.getLogger(__name__)
      
      def send_system_alert(self, alert_type: str, details: Dict):
          \"\"\"시스템 알림 전송\"\"\"
          
          alert_templates = {
              "high_cpu": {
                  "title": "🔥 High CPU Usage",
                  "message": f"CPU 사용률이 {details.get('cpu_percent', 0):.1f}%입니다",
                  "severity": "warning"
              },
              "high_memory": {
                  "title": "💾 High Memory Usage", 
                  "message": f"메모리 사용률이 {details.get('memory_percent', 0):.1f}%입니다",
                  "severity": "warning"
              },
              "api_error": {
                  "title": "🚨 API Error Rate High",
                  "message": f"API 오류율이 {details.get('error_rate', 0):.2%}입니다",
                  "severity": "critical"
              },
              "service_down": {
                  "title": "💥 Service Down",
                  "message": f"서비스 {details.get('service_name', 'Unknown')}가 다운되었습니다",
                  "severity": "critical"
              }
          }
          
          template = alert_templates.get(alert_type, {
              "title": f"⚠️ {alert_type}",
              "message": str(details),
              "severity": "info"
          })
          
          success = self.slack_alerter.send_alert(
              title=template["title"],
              message=template["message"],
              severity=template["severity"]
          )
          
          # 알림 히스토리 기록
          self.alert_history.append({
              "timestamp": datetime.now(),
              "type": alert_type,
              "details": details,
              "sent": success
          })
          
          return success
  ```

---

## ✅ 완료 기준

### 8.5.1 기능적 완료 기준
- [ ] 시스템 상태를 실시간으로 모니터링 가능 (CPU, 메모리, 네트워크)
- [ ] 모델 성능 메트릭이 자동으로 수집되고 시각화됨
- [ ] 데이터 드리프트 감지 시스템이 작동하여 이상 상황 감지
- [ ] 임계값 초과 시 즉시 알림 수신 (Slack, Email)
- [ ] 종합 대시보드에서 전체 시스템 상태 한눈에 파악 가능

### 8.5.2 기술적 완료 기준
- [ ] Prometheus + Grafana 모니터링 스택 구축 완료
- [ ] 구조화된 로깅 시스템으로 모든 이벤트 추적
- [ ] ELK 스택으로 로그 중앙화 및 검색 가능
- [ ] Evidently를 활용한 드리프트 감지 자동화
- [ ] 알림 시스템으로 다양한 채널 지원

### 8.5.3 운영적 완료 기준
- [ ] 24시간 모니터링 시스템 안정 운영
- [ ] 장애 발생 시 5분 이내 알림 수신
- [ ] 성능 저하 조기 감지로 사전 대응 가능
- [ ] 모니터링 데이터 기반 시스템 최적화 실행
- [ ] 팀원 대상 모니터링 운영 교육 완료

---

## 🚀 다음 단계 준비

### 9단계 연계 작업
- 모니터링 이벤트를 9단계 이벤트 기반 아키텍처의 트리거로 활용
- 성능 지표 기반 자동 스케일링 및 재훈련 트리거 연동
- 알림 시스템을 전체 MLOps 라이프사이클 이벤트로 확장

### 고도화 계획
- 머신러닝 기반 이상 탐지 시스템 도입
- 예측적 모니터링으로 장애 사전 방지
- 분산 트레이싱으로 마이크로서비스 모니터링
- AI Ops 도입으로 자동 장애 대응

이 8단계를 완료하면 전체 MLOps 시스템의 안정성과 가용성을 보장하는 포괄적인 관측성 체계가 구축됩니다.
