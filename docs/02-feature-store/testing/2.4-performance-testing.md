# 2.4 성능 및 확장성 테스트

## 📋 개요

피처 스토어 시스템의 성능, 확장성, 안정성을 검증하는 포괄적인 테스트 가이드입니다.

---

## 🏃‍♂️ 1. 대용량 데이터 처리 성능 테스트

### 1.1 피처 생성 처리량 테스트

```bash
# 대용량 피처 생성 성능 테스트
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import psutil
import gc

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor

print('📊 대용량 피처 생성 성능 테스트...')

# 시스템 리소스 모니터링 함수
def get_memory_usage():
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024  # MB

def get_cpu_usage():
    return psutil.cpu_percent(interval=1)

print(f'💻 초기 시스템 상태:')
print(f'  메모리 사용량: {get_memory_usage():.1f} MB')

# 테스트 시나리오들
test_scenarios = [
    {'name': '소규모', 'count': 100, 'description': '기본 성능 테스트'},
    {'name': '중규모', 'count': 500, 'description': '중간 규모 처리'},
    {'name': '대규모', 'count': 1000, 'description': '대용량 처리'}
]

results = []

for scenario in test_scenarios:
    print(f'\\n🎯 {scenario[\"name\"]} 테스트 ({scenario[\"count\"]:,}개 영화)...')
    
    # 가비지 컬렉션
    gc.collect()
    initial_memory = get_memory_usage()
    
    # 테스트 데이터 생성
    print('  📊 테스트 데이터 생성 중...')
    test_movies = []
    for i in range(scenario['count']):
        test_movies.append({
            'movie_id': i + 1,
            'title': f'{scenario[\"name\"]} Test Movie {i+1}',
            'release_date': f'202{(i % 4) + 1}-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}',
            'vote_average': 4.0 + (i % 60) * 0.1,
            'vote_count': 100 + i * 10,
            'popularity': 10.0 + (i % 90),
            'genre_ids': [(28 + (i % 5))],  # 다양한 장르
            'adult': i % 10 == 0,
            'original_language': ['en', 'ko', 'ja', 'fr', 'es'][i % 5],
            'overview': f'Test movie description for performance testing. Movie {i+1}.'
        })
    
    # 피처 생성 성능 측정
    print('  ⚙️ 피처 생성 중...')
    feature_start = time.time()
    
    processor = AdvancedTMDBPreProcessor(test_movies)
    features = processor.extract_all_features()
    
    feature_time = time.time() - feature_start
    final_memory = get_memory_usage()
    
    # 결과 계산
    throughput = scenario['count'] / feature_time if feature_time > 0 else 0
    memory_increase = final_memory - initial_memory
    
    result = {
        'scenario': scenario['name'],
        'count': scenario['count'],
        'feature_time': feature_time,
        'throughput': throughput,
        'memory_increase': memory_increase
    }
    
    results.append(result)
    
    print(f'  📈 성능 결과:')
    print(f'    피처 생성: {feature_time:.2f}초')
    print(f'    처리량: {throughput:.1f} movies/second')
    print(f'    메모리 증가: {memory_increase:.1f} MB')
    
    # 메모리 정리
    del test_movies, features, processor
    gc.collect()

# 성능 요약
print('\\n📊 성능 테스트 결과 요약:')
print('=' * 60)
print(f'{\"시나리오\":<10} {\"영화수\":<8} {\"처리시간\":<10} {\"처리량\":<15}')
print('-' * 60)

for result in results:
    print(f'{result[\"scenario\"]:<10} {result[\"count\"]:<8,} {result[\"feature_time\"]:<10.1f} {result[\"throughput\"]:<15.1f}')

# 성능 기준 검증
print('\\n🎯 성능 기준 검증:')
for result in results:
    if result['throughput'] >= 10:
        status = '✅'
    elif result['throughput'] >= 5:
        status = '⚠️'
    else:
        status = '❌'
    
    print(f'{status} {result[\"scenario\"]}: {result[\"throughput\"]:.1f} movies/sec (기준: ≥10)')

print('\\n✅ 대용량 처리 성능 테스트 완료!')
"
```

### 1.2 피처 스토어 저장 성능 테스트

```bash
# 피처 스토어 저장 성능 테스트
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import pandas as pd
import numpy as np

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig

print('💾 피처 스토어 저장 성능 테스트...')

# 다양한 크기의 데이터셋 생성
test_datasets = [
    {'name': 'Small', 'rows': 1000, 'cols': 10},
    {'name': 'Medium', 'rows': 5000, 'cols': 20},
    {'name': 'Large', 'rows': 10000, 'cols': 30}
]

config = FeatureStoreConfig(
    base_path='/app/data/performance_test_store',
    cache_enabled=True,
    compression='snappy'
)
store = SimpleFeatureStore(config)

results = []

for dataset in test_datasets:
    print(f'\\n📊 {dataset[\"name\"]} 데이터셋 테스트...')
    print(f'  크기: {dataset[\"rows\"]:,} 행 x {dataset[\"cols\"]} 컬럼')
    
    # 테스트 데이터 생성
    test_data = pd.DataFrame({
        f'feature_{i}': np.random.random(dataset['rows']) 
        for i in range(dataset['cols'])
    })
    test_data['id'] = range(dataset['rows'])
    
    # 저장 성능 측정
    print('  💾 저장 성능 측정...')
    save_start = time.time()
    
    feature_dict = {f'perf_test_{dataset[\"name\"].lower()}': test_data}
    saved_paths = store.save_features(f'perf_test_group_{dataset[\"name\"].lower()}', feature_dict)
    
    save_time = time.time() - save_start
    
    # 조회 성능 측정
    print('  📋 조회 성능 측정...')
    load_start = time.time()
    
    loaded_data = store.get_features([f'perf_test_{dataset[\"name\"].lower()}'], f'perf_test_group_{dataset[\"name\"].lower()}')
    
    load_time = time.time() - load_start
    
    # 결과 계산
    data_size_mb = test_data.memory_usage(deep=True).sum() / 1024 / 1024
    save_throughput = data_size_mb / save_time
    load_throughput = data_size_mb / load_time
    
    result = {
        'name': dataset['name'],
        'size_mb': data_size_mb,
        'save_time': save_time,
        'load_time': load_time,
        'save_throughput': save_throughput,
        'load_throughput': load_throughput
    }
    
    results.append(result)
    
    print(f'  📈 결과:')
    print(f'    데이터 크기: {data_size_mb:.2f} MB')
    print(f'    저장 시간: {save_time:.2f}초 ({save_throughput:.2f} MB/s)')
    print(f'    조회 시간: {load_time:.2f}초 ({load_throughput:.2f} MB/s)')

# 성능 요약
print('\\n📊 피처 스토어 성능 요약:')
print('=' * 70)
print(f'{\"데이터셋\":<8} {\"크기(MB)\":<10} {\"저장시간\":<10} {\"조회시간\":<10} {\"저장속도\":<12}')
print('-' * 70)

for result in results:
    print(f'{result[\"name\"]:<8} {result[\"size_mb\"]:<10.2f} {result[\"save_time\"]:<10.2f} {result[\"load_time\"]:<10.2f} {result[\"save_throughput\"]:<12.2f}')

print('\\n✅ 피처 스토어 저장 성능 테스트 완료!')
"
```

---

## 🚀 2. 동시성 및 스트레스 테스트

### 2.1 멀티스레드 동시 접근 테스트

```bash
# 멀티스레드 동시 접근 테스트
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import threading
import time
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import numpy as np

print('🚀 멀티스레드 동시 접근 테스트...')

# 결과 수집용 큐
results_queue = queue.Queue()

def concurrent_worker(worker_id, iterations=5):
    '''동시 접근 테스트 워커 함수'''
    worker_results = {
        'worker_id': worker_id,
        'success_count': 0,
        'error_count': 0,
        'errors': []
    }
    
    try:
        # 각 워커별 독립적인 피처 스토어
        config = FeatureStoreConfig(base_path=f'/app/data/concurrent_test_store_{worker_id}')
        store = SimpleFeatureStore(config)
        
        for i in range(iterations):
            try:
                # 테스트 데이터 생성
                test_data = pd.DataFrame({
                    'id': range(50),
                    'worker_id': [worker_id] * 50,
                    'iteration': [i] * 50,
                    'value': np.random.random(50)
                })
                
                # 저장 및 조회
                feature_dict = {f'worker_{worker_id}_data': test_data}
                store.save_features(f'concurrent_group_{worker_id}', feature_dict)
                
                loaded = store.get_features([f'worker_{worker_id}_data'], f'concurrent_group_{worker_id}')
                
                if loaded:
                    worker_results['success_count'] += 1
                else:
                    worker_results['error_count'] += 1
                    
                # 약간의 랜덤 지연
                time.sleep(np.random.uniform(0.01, 0.05))
                
            except Exception as e:
                worker_results['error_count'] += 1
                worker_results['errors'].append(str(e))
    
    except Exception as e:
        worker_results['errors'].append(f'Worker setup error: {e}')
    
    results_queue.put(worker_results)
    return worker_results

# 동시성 테스트 실행
print('🎯 동시성 테스트 시작...')
print('설정: 8개 워커, 각각 5회 반복 = 총 40회 작업')

test_start_time = time.time()

# ThreadPoolExecutor로 동시 실행
with ThreadPoolExecutor(max_workers=8) as executor:
    futures = [executor.submit(concurrent_worker, i, 5) for i in range(8)]
    
    completed_workers = 0
    for future in as_completed(futures):
        try:
            result = future.result()
            completed_workers += 1
            print(f'  워커 {result[\"worker_id\"]} 완료: {result[\"success_count\"]}/5 성공')
        except Exception as e:
            print(f'  워커 실행 오류: {e}')
            completed_workers += 1

test_total_time = time.time() - test_start_time

# 결과 집계
print('\\n📊 동시성 테스트 결과 분석...')

all_results = []
while not results_queue.empty():
    all_results.append(results_queue.get())

total_operations = sum(r['success_count'] + r['error_count'] for r in all_results)
total_successes = sum(r['success_count'] for r in all_results)
total_errors = sum(r['error_count'] for r in all_results)

success_rate = (total_successes / total_operations * 100) if total_operations > 0 else 0

print(f'📈 전체 결과:')
print(f'  총 작업: {total_operations}개')
print(f'  성공: {total_successes}개')
print(f'  실패: {total_errors}개')
print(f'  성공률: {success_rate:.1f}%')
print(f'  총 소요시간: {test_total_time:.2f}초')

# 안정성 검증
if success_rate >= 95:
    print('✅ 성공률: 우수 (≥95%)')
elif success_rate >= 90:
    print('⚠️ 성공률: 양호 (≥90%)')
else:
    print('❌ 성공률: 개선 필요 (<90%)')

print('\\n✅ 멀티스레드 동시 접근 테스트 완료!')
"
```

### 2.2 연속 안정성 테스트

```bash
# 연속 안정성 테스트 (3분간)
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import psutil
import gc
from datetime import datetime

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import numpy as np

print('💪 연속 안정성 테스트 (3분간 연속 동작)...')

# 테스트 설정
test_duration = 180  # 3분
check_interval = 30  # 30초마다 체크
start_time = time.time()
end_time = start_time + test_duration

# 통계 수집
stats = {
    'operations': 0,
    'errors': 0,
    'memory_samples': [],
    'start_time': datetime.now()
}

config = FeatureStoreConfig(base_path='/app/data/stability_test_store')
store = SimpleFeatureStore(config)

print(f'시작 시간: {stats[\"start_time\"]}')

cycle = 0
last_check = start_time

while time.time() < end_time:
    cycle += 1
    
    try:
        # 랜덤 크기의 테스트 데이터 생성
        data_size = np.random.randint(50, 150)
        test_data = pd.DataFrame({
            'cycle': [cycle] * data_size,
            'timestamp': [time.time()] * data_size,
            'feature_1': np.random.random(data_size),
            'feature_2': np.random.normal(0, 1, data_size)
        })
        
        # 피처 스토어 작업
        feature_dict = {f'stability_test_data_{cycle % 5}': test_data}
        store.save_features('stability_test_group', feature_dict)
        
        # 조회 테스트
        loaded = store.get_features([f'stability_test_data_{cycle % 5}'], 'stability_test_group')
        
        if loaded:
            stats['operations'] += 1
        else:
            stats['errors'] += 1
        
    except Exception as e:
        stats['errors'] += 1
        if cycle % 50 == 0:
            print(f'  ❌ 사이클 {cycle} 오류: {e}')
    
    # 30초마다 상태 리포트
    current_time = time.time()
    if current_time - last_check >= check_interval:
        # 메모리 사용량 수집
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        stats['memory_samples'].append(memory_mb)
        
        # 진행 상황 출력
        elapsed = current_time - start_time
        remaining = end_time - current_time
        progress = (elapsed / test_duration) * 100
        
        print(f'\\n⏱️ 진행률: {progress:.1f}% ({elapsed/60:.1f}분 경과, {remaining/60:.1f}분 남음)')
        print(f'  작업: {stats[\"operations\"]}개 성공, {stats[\"errors\"]}개 실패')
        print(f'  메모리: {memory_mb:.1f} MB')
        
        last_check = current_time
        
        # 가비지 컬렉션
        if cycle % 50 == 0:
            gc.collect()
    
    # 적절한 대기 시간
    time.sleep(0.02)

# 최종 결과 분석
final_time = time.time()
total_duration = final_time - start_time

print('\\n' + '='*50)
print('📊 연속 안정성 테스트 최종 결과')
print('='*50)

print(f'테스트 기간: {total_duration/60:.1f}분')
print(f'총 작업: {stats[\"operations\"]}개')
print(f'총 오류: {stats[\"errors\"]}개')

if stats['operations'] + stats['errors'] > 0:
    success_rate = (stats[\"operations\"]/(stats[\"operations\"]+stats[\"errors\"])*100)
    print(f'성공률: {success_rate:.2f}%')

if stats['memory_samples']:
    avg_memory = sum(stats['memory_samples']) / len(stats['memory_samples'])
    max_memory = max(stats['memory_samples'])
    min_memory = min(stats['memory_samples'])
    print(f'메모리 사용량 - 평균: {avg_memory:.1f}MB, 최대: {max_memory:.1f}MB')
    
    memory_growth = max_memory - min_memory
    if memory_growth < 50:
        print('✅ 메모리 안정성: 우수 (증가량 <50MB)')
    elif memory_growth < 150:
        print('⚠️ 메모리 안정성: 양호 (증가량 <150MB)')
    else:
        print('❌ 메모리 안정성: 개선 필요')

print('\\n✅ 연속 안정성 테스트 완료!')
"
```

---

## 📈 3. 메모리 효율성 테스트

### 3.1 메모리 사용량 최적화 테스트

```bash
# 메모리 사용량 최적화 테스트
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import psutil
import gc
import time

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor

print('💾 메모리 사용량 최적화 테스트...')

def get_memory_usage():
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024  # MB

# 초기 메모리 상태
initial_memory = get_memory_usage()
print(f'📊 초기 메모리 사용량: {initial_memory:.1f} MB')

# 메모리 효율성 테스트
print('\\n🧪 메모리 누수 테스트...')

# 반복 처리로 메모리 누수 확인
memory_readings = []

for iteration in range(10):
    # 테스트 데이터 생성
    test_movies = [
        {
            'movie_id': i,
            'title': f'Memory Test Movie {i}',
            'release_date': '2023-01-01',
            'vote_average': 7.0 + (i % 3),
            'vote_count': 1000 + i * 100,
            'popularity': 50.0 + i * 5,
            'genre_ids': [28],
            'adult': False,
            'original_language': 'en',
            'overview': f'Memory efficiency test movie {i}'
        }
        for i in range(100)  # 100개씩 처리
    ]
    
    # 피처 생성
    processor = AdvancedTMDBPreProcessor(test_movies)
    features = processor.extract_all_features()
    
    # 메모리 사용량 측정
    current_memory = get_memory_usage()
    memory_readings.append(current_memory)
    
    print(f'  반복 {iteration + 1}: {current_memory:.1f} MB')
    
    # 명시적 메모리 정리
    del test_movies, processor, features
    gc.collect()
    
    time.sleep(0.1)  # 잠시 대기

# 메모리 누수 분석
if len(memory_readings) >= 2:
    memory_growth = memory_readings[-1] - memory_readings[0]
    avg_per_iteration = memory_growth / len(memory_readings)
    
    print(f'\\n📈 메모리 사용량 분석:')
    print(f'  초기: {memory_readings[0]:.1f} MB')
    print(f'  최종: {memory_readings[-1]:.1f} MB')
    print(f'  총 증가: {memory_growth:.1f} MB')
    print(f'  반복당 평균 증가: {avg_per_iteration:.2f} MB')
    
    if memory_growth < 20:
        print('✅ 메모리 효율성: 우수 (증가량 <20MB)')
    elif memory_growth < 50:
        print('⚠️ 메모리 효율성: 양호 (증가량 <50MB)')
    else:
        print('❌ 메모리 효율성: 개선 필요 (증가량 ≥50MB)')

print('\\n✅ 메모리 사용량 최적화 테스트 완료!')
"
```

---

## ⏱️ 4. 캐시 성능 테스트

### 4.1 캐시 효율성 테스트

```bash
# 캐시 성능 및 효율성 테스트
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import pandas as pd

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig

print('🗄️ 캐시 성능 및 효율성 테스트...')

# 캐시 활성화된 설정
config = FeatureStoreConfig(
    base_path='/app/data/cache_test_store',
    cache_enabled=True,
    cache_max_size=20,
    cache_ttl_seconds=120
)
store = SimpleFeatureStore(config)

# 테스트 데이터 생성
test_features = {}
for i in range(5):
    test_features[f'cache_test_feature_{i}'] = pd.DataFrame({
        'id': range(1000),
        'value': range(1000 * i, 1000 * (i + 1)),
        'feature': [f'data_{j}' for j in range(1000)]
    })

print(f'📊 테스트 데이터: {len(test_features)}개 피처 그룹')

# 캐시 성능 테스트
feature_names = list(test_features.keys())

# 1. 초기 저장 (캐시 없음)
print('\\n1️⃣ 초기 저장 및 조회 (캐시 미스)...')
store.save_features('cache_test_group', test_features)

# 첫 번째 조회 (디스크에서 로드)
start_time = time.time()
first_load = store.get_features(feature_names, 'cache_test_group')
first_load_time = time.time() - start_time

print(f'  첫 번째 조회: {first_load_time*1000:.2f}ms')

# 2. 두 번째 조회 (캐시에서 로드)
print('2️⃣ 두 번째 조회 (캐시 히트)...')
start_time = time.time()
second_load = store.get_features(feature_names, 'cache_test_group')
second_load_time = time.time() - start_time

print(f'  두 번째 조회: {second_load_time*1000:.2f}ms')

# 3. 캐시 성능 분석
if second_load_time < first_load_time:
    speedup = first_load_time / second_load_time
    improvement = ((first_load_time - second_load_time) / first_load_time) * 100
    print(f'\\n📈 캐시 성능 향상:')
    print(f'  속도 향상: {speedup:.1f}배')
    print(f'  성능 개선: {improvement:.1f}%')
    
    if speedup >= 5:
        print('✅ 캐시 효율성: 우수 (≥5배 향상)')
    elif speedup >= 2:
        print('⚠️ 캐시 효율성: 양호 (≥2배 향상)')
    else:
        print('❌ 캐시 효율성: 개선 필요 (<2배 향상)')
else:
    print('❌ 캐시 성능 향상이 확인되지 않음')

# 4. 캐시 통계 확인
if store.cache:
    cache_stats = store.cache.get_stats()
    print(f'\\n📊 캐시 통계:')
    print(f'  캐시 크기: {cache_stats.get(\"size\", 0)}/{cache_stats.get(\"max_size\", 0)}')
    print(f'  TTL: {cache_stats.get(\"ttl_seconds\", 0)}초')

print('\\n✅ 캐시 성능 테스트 완료!')
"
```

---

## ✅ 성공 기준

### 처리 성능 기준
- [ ] **피처 생성 속도**: ≥ 10 movies/second (1000개 영화 기준)
- [ ] **저장 속도**: ≥ 10 MB/second
- [ ] **조회 속도**: ≥ 20 MB/second

### 확장성 기준
- [ ] **동시성**: 8개 스레드 동시 접근 시 ≥ 90% 성공률
- [ ] **대용량 처리**: 1000개 영화 처리 시 < 300MB 메모리 사용
- [ ] **연속 안정성**: 3분간 연속 처리 시 오류율 < 5%

### 메모리 효율성 기준
- [ ] **메모리 증가**: 반복 처리 시 < 20MB 누적 증가
- [ ] **메모리 정리**: 가비지 컬렉션 후 메모리 해제 확인
- [ ] **리소스 사용**: CPU 사용률 평상시 < 50%

### 캐시 성능 기준
- [ ] **캐시 효과**: 두 번째 조회가 첫 번째보다 ≥ 2배 빠름
- [ ] **캐시 적중률**: 연속 조회 시 적중률 > 80%
- [ ] **TTL 관리**: 캐시 만료 후 자동 갱신

### 안정성 기준
- [ ] **오류 복구**: 일시적 오류 후 자동 복구
- [ ] **데이터 무결성**: 동시 접근 시에도 데이터 손실 없음
- [ ] **장시간 안정성**: 연속 동작 시 성능 저하 < 10%

**성능 및 확장성 테스트가 완료되면 다음 단계인 [2.5-feast-integration-testing.md](./2.5-feast-integration-testing.md)로 진행하세요!** 🚀
