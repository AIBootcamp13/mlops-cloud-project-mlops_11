---
title: "2.2 피처 생성 파이프라인 구축 가이드"
description: "자동화된 피처 생성 파이프라인으로 일관성과 재현성 확보"
author: "MLOps Team"
created: "2025-06-05"
updated: "2025-06-05"
version: "1.0"
stage: "2.2"
category: "Feature Pipeline"
tags: ["파이프라인", "자동화", "병렬처리", "YAML설정", "증분처리"]
prerequisites: ["2.1 피처 엔지니어링 로직 완료", "Python 멀티프로세싱", "YAML"]
difficulty: "intermediate"
estimated_time: "6-8시간"
---

# 2.2 피처 생성 파이프라인 구축 가이드

## 📋 개요

**목표**: 자동화된 피처 생성으로 일관성과 재현성 확보

**핵심 가치**: 수동 작업 없이 신뢰할 수 있는 피처를 지속적으로 생성

---

## 🎯 학습 목표

### 이론적 목표
- 파이프라인 설계 원칙과 패턴 이해
- ETL/ELT 프로세스와 피처 파이프라인의 차이점 학습
- 병렬 처리와 최적화 전략 습득

### 실무적 목표
- 단계별 피처 파이프라인 구현
- YAML 기반 설정 관리 시스템 구축
- 증분 처리 및 모니터링 시스템 개발

---

## 🔧 2.2.1 파이프라인 아키텍처 설계

### 핵심 설계 원칙

#### **단계별 분리 (Separation of Concerns)**
```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List
import logging
import time

class PipelineStage(ABC):
    """파이프라인 스테이지 베이스 클래스"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        self.metrics = {}
    
    @abstractmethod
    def process(self, data: Any) -> Any:
        """데이터 처리 로직"""
        pass
    
    def validate_input(self, data: Any) -> bool:
        """입력 데이터 검증"""
        return True
    
    def validate_output(self, data: Any) -> bool:
        """출력 데이터 검증"""
        return True
    
    def get_metrics(self) -> Dict[str, Any]:
        """성능 메트릭 반환"""
        return self.metrics

class FeaturePipeline:
    """피처 생성 메인 파이프라인"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        self.stages = self._initialize_stages()
        self.metrics_collector = MetricsCollector()
    
    def run(self, input_data: Any) -> Any:
        """파이프라인 실행"""
        
        start_time = time.time()
        current_data = input_data
        
        self.logger.info(f"파이프라인 시작: {len(self.stages)}개 스테이지")
        
        try:
            for i, stage in enumerate(self.stages):
                stage_start = time.time()
                
                self.logger.info(f"스테이지 {i+1}/{len(self.stages)} 시작: {stage.__class__.__name__}")
                
                # 입력 검증
                if not stage.validate_input(current_data):
                    raise ValueError(f"스테이지 {stage.__class__.__name__} 입력 검증 실패")
                
                # 데이터 처리
                current_data = stage.process(current_data)
                
                # 출력 검증
                if not stage.validate_output(current_data):
                    raise ValueError(f"스테이지 {stage.__class__.__name__} 출력 검증 실패")
                
                # 메트릭 수집
                stage_metrics = stage.get_metrics()
                stage_metrics['stage_name'] = stage.__class__.__name__
                stage_metrics['stage_duration'] = time.time() - stage_start
                
                self.metrics_collector.add_stage_metrics(stage_metrics)
                
                self.logger.info(
                    f"스테이지 {i+1} 완료: {stage_metrics.get('processing_time', 0):.2f}초"
                )
            
            # 전체 파이프라인 메트릭
            total_duration = time.time() - start_time
            self.metrics_collector.set_pipeline_metrics({
                'total_duration': total_duration,
                'total_stages': len(self.stages),
                'status': 'success'
            })
            
            self.logger.info(f"파이프라인 완료: {total_duration:.2f}초")
            
            return current_data
            
        except Exception as e:
            self.logger.error(f"파이프라인 실행 중 오류: {e}")
            self.metrics_collector.set_pipeline_metrics({
                'total_duration': time.time() - start_time,
                'status': 'failed',
                'error': str(e)
            })
            raise
```

---

## 🔧 2.2.2 YAML 기반 구성 관리

### 파이프라인 설정 스키마

#### **기본 파이프라인 설정**
```yaml
# config/feature_pipeline.yaml

feature_pipeline:
  name: "movie_recommendation_features"
  version: "1.0"
  description: "영화 추천을 위한 피처 생성 파이프라인"
  
  # 입력 설정
  input:
    source_type: "json"
    source_path: "data/raw/movies"
    file_pattern: "*.json"
    encoding: "utf-8"
  
  # 출력 설정
  output:
    destination_type: "parquet"
    destination_path: "data/features"
    compression: "snappy"
    partition_by: ["release_year"]
  
  # 처리 설정
  processing:
    parallel_processing: true
    max_workers: 4
    chunk_size: 1000
    memory_limit: "4GB"
  
  # 스테이지 정의
  stages:
    - name: "data_validation"
      type: "DataValidationStage"
      params:
        required_fields: ["id", "title", "vote_average", "popularity"]
        type_checks:
          id: "int"
          vote_average: "float"
          popularity: "float"
        range_checks:
          vote_average: [0, 10]
          popularity: [0, 1000]
    
    - name: "content_feature_extraction"
      type: "FeatureExtractionStage"
      params:
        extractors:
          - name: "genre_features"
            type: "GenreFeatureExtractor"
            params:
              encoding_type: "one_hot"
              max_genres: 20
          
          - name: "temporal_features"
            type: "TemporalFeatureExtractor"
            params:
              include_era: true
              include_decade: true
              include_age: true

# 실험 설정
experiments:
  baseline:
    feature_pipeline:
      stages:
        # 기본 피처만 사용
        - "data_validation"
        - "content_feature_extraction"
        - "feature_storage"
  
  advanced:
    feature_pipeline:
      stages:
        # 모든 피처 사용
        - "data_validation"
        - "content_feature_extraction"
        - "interaction_feature_generation"
        - "feature_validation"
        - "feature_storage"
```

### 설정 관리 시스템

```python
import yaml
from typing import Dict, Any
import os

class ConfigManager:
    """YAML 기반 설정 관리자"""
    
    def __init__(self, base_config_path: str, environment: str = "development"):
        self.base_config_path = base_config_path
        self.environment = environment
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """설정 파일 로드 및 병합"""
        
        # 기본 설정 로드
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            base_config = yaml.safe_load(f)
        
        # 환경별 설정 로드 및 병합
        env_config_path = f"config/{self.environment}.yaml"
        if os.path.exists(env_config_path):
            with open(env_config_path, 'r', encoding='utf-8') as f:
                env_config = yaml.safe_load(f)
            
            # 딥 병합
            merged_config = self._deep_merge(base_config, env_config)
        else:
            merged_config = base_config
        
        # 환경 변수로 오버라이드
        return self._apply_env_overrides(merged_config)
    
    def get_pipeline_config(self) -> Dict[str, Any]:
        """파이프라인 설정 반환"""
        return self.config.get('feature_pipeline', {})
```

---

## 🔧 2.2.3 증분 처리 시스템

### 변경 분 감지

#### **데이터 변경 추적기**
```python
import hashlib
import json
from datetime import datetime
from pathlib import Path

class DataChangeTracker:
    """데이터 변경 사항 추적"""
    
    def __init__(self, tracking_file: str = "data/.change_tracking.json"):
        self.tracking_file = Path(tracking_file)
        self.tracking_data = self._load_tracking_data()
    
    def has_changed(self, file_path: str) -> bool:
        """파일 변경 여부 확인"""
        file_path = str(Path(file_path).resolve())
        
        if not Path(file_path).exists():
            return False
        
        current_signature = self.calculate_file_signature(file_path)
        stored_signature = self.tracking_data.get(file_path, {}).get('signature')
        
        return current_signature != stored_signature
    
    def get_changed_files(self, file_pattern: str) -> List[str]:
        """변경된 파일 목록 반환"""
        from glob import glob
        
        changed_files = []
        for file_path in glob(file_pattern):
            if self.has_changed(file_path):
                changed_files.append(file_path)
        
        return changed_files

class IncrementalFeaturePipeline:
    """증분 처리 지원 파이프라인"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.change_tracker = DataChangeTracker()
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def run_incremental(self, force_full_rebuild: bool = False) -> Dict[str, Any]:
        """증분 처리 실행"""
        
        if force_full_rebuild:
            return self._run_full_pipeline()
        
        # 변경된 입력 파일 감지
        input_pattern = self.config.get('input', {}).get('file_pattern', '*.json')
        changed_files = self.change_tracker.get_changed_files(input_pattern)
        
        if not changed_files:
            self.logger.info("변경된 파일 없음 - 스킵")
            return {'status': 'skipped', 'reason': 'no_changes'}
        
        self.logger.info(f"변경된 파일 {len(changed_files)}개 감지")
        
        # 변경된 파일만 처리
        result = self._process_changed_files(changed_files)
        
        # 변경 추적 업데이트
        for file_path in changed_files:
            self.change_tracker.mark_processed(file_path)
        
        return result
```

---

## 🔧 2.2.4 병렬 처리 및 성능 최적화

### 멀티프로세싱 구현

```python
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp

class ParallelFeatureProcessor:
    """병렬 피처 처리기"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.max_workers = config.get('max_workers', mp.cpu_count())
        self.chunk_size = config.get('chunk_size', 1000)
        
    def process_parallel(self, data: List[Dict], processor_func: callable) -> List[Dict]:
        """병렬 처리 실행"""
        
        if len(data) < self.chunk_size:
            # 작은 데이터는 순차 처리
            return processor_func(data)
        
        # 데이터를 청크로 분할
        chunks = [
            data[i:i + self.chunk_size] 
            for i in range(0, len(data), self.chunk_size)
        ]
        
        results = []
        
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            # 각 청크를 병렬로 처리
            future_to_chunk = {
                executor.submit(processor_func, chunk): chunk 
                for chunk in chunks
            }
            
            for future in as_completed(future_to_chunk):
                try:
                    chunk_result = future.result()
                    results.extend(chunk_result)
                except Exception as e:
                    self.logger.error(f"청크 처리 중 오류: {e}")
                    # 실패한 청크는 순차 처리로 재시도
                    chunk = future_to_chunk[future]
                    fallback_result = processor_func(chunk)
                    results.extend(fallback_result)
        
        return results
```

### 메모리 최적화

```python
class MemoryEfficientProcessor:
    """메모리 효율적 처리기"""
    
    def __init__(self, memory_limit: str = "4GB"):
        self.memory_limit = self._parse_memory_limit(memory_limit)
        
    def process_with_memory_control(self, data_iterator, processor_func):
        """메모리 사용량을 제어하며 처리"""
        
        import psutil
        import gc
        
        results = []
        batch = []
        batch_size = 100
        
        for item in data_iterator:
            batch.append(item)
            
            if len(batch) >= batch_size:
                # 메모리 사용량 확인
                memory_usage = psutil.virtual_memory().percent
                
                if memory_usage > 80:  # 80% 초과 시
                    # 가비지 컬렉션 실행
                    gc.collect()
                    
                    # 배치 크기 줄이기
                    batch_size = max(10, batch_size // 2)
                
                # 배치 처리
                batch_result = processor_func(batch)
                results.extend(batch_result)
                
                batch = []
        
        # 남은 데이터 처리
        if batch:
            batch_result = processor_func(batch)
            results.extend(batch_result)
        
        return results
```

---

## 🔧 2.2.5 모니터링 및 진행률 추적

### 실시간 진행률 모니터링

```python
from tqdm import tqdm
import time

class ProgressMonitor:
    """진행률 모니터링"""
    
    def __init__(self, total_items: int, description: str = "Processing"):
        self.total_items = total_items
        self.description = description
        self.progress_bar = tqdm(total=total_items, desc=description)
        self.start_time = time.time()
        
    def update(self, count: int = 1):
        """진행률 업데이트"""
        self.progress_bar.update(count)
        
    def set_postfix(self, **kwargs):
        """추가 정보 표시"""
        self.progress_bar.set_postfix(**kwargs)
        
    def close(self):
        """진행률 바 종료"""
        self.progress_bar.close()
        
        elapsed_time = time.time() - self.start_time
        print(f"\n✅ {self.description} 완료: {elapsed_time:.2f}초")

class MetricsCollector:
    """메트릭 수집기"""
    
    def __init__(self):
        self.stage_metrics = []
        self.pipeline_metrics = {}
        
    def add_stage_metrics(self, metrics: Dict[str, Any]):
        """스테이지 메트릭 추가"""
        metrics['timestamp'] = datetime.now().isoformat()
        self.stage_metrics.append(metrics)
        
    def set_pipeline_metrics(self, metrics: Dict[str, Any]):
        """파이프라인 메트릭 설정"""
        self.pipeline_metrics = metrics
        self.pipeline_metrics['timestamp'] = datetime.now().isoformat()
        
    def get_summary(self) -> Dict[str, Any]:
        """메트릭 요약 반환"""
        return {
            'pipeline': self.pipeline_metrics,
            'stages': self.stage_metrics,
            'total_stages': len(self.stage_metrics),
            'total_processing_time': sum(
                stage.get('processing_time', 0) 
                for stage in self.stage_metrics
            )
        }
```

### 성능 벤치마킹

```python
class PerformanceBenchmark:
    """성능 벤치마크"""
    
    def __init__(self):
        self.benchmarks = {}
        
    def benchmark_stage(self, stage_name: str, data_size: int, 
                       processing_time: float) -> Dict[str, float]:
        """스테이지 성능 벤치마크"""
        
        throughput = data_size / processing_time if processing_time > 0 else 0
        
        benchmark = {
            'data_size': data_size,
            'processing_time': processing_time,
            'throughput': throughput,  # 초당 처리량
            'avg_time_per_item': processing_time / data_size if data_size > 0 else 0
        }
        
        self.benchmarks[stage_name] = benchmark
        return benchmark
        
    def compare_with_baseline(self, baseline_file: str) -> Dict[str, Any]:
        """기준선과 비교"""
        
        if not os.path.exists(baseline_file):
            # 기준선 파일 생성
            with open(baseline_file, 'w') as f:
                json.dump(self.benchmarks, f, indent=2)
            return {'status': 'baseline_created'}
        
        # 기준선 로드
        with open(baseline_file, 'r') as f:
            baseline = json.load(f)
        
        comparison = {}
        for stage_name, current in self.benchmarks.items():
            if stage_name in baseline:
                baseline_throughput = baseline[stage_name]['throughput']
                current_throughput = current['throughput']
                
                improvement = (
                    (current_throughput - baseline_throughput) / baseline_throughput 
                    if baseline_throughput > 0 else 0
                )
                
                comparison[stage_name] = {
                    'current_throughput': current_throughput,
                    'baseline_throughput': baseline_throughput,
                    'improvement_ratio': improvement,
                    'status': 'improved' if improvement > 0.1 else 
                             'degraded' if improvement < -0.1 else 'stable'
                }
        
        return comparison
```

---

## ✅ 완료 기준

### 기능적 완료 기준
- [ ] 단계별 파이프라인 구조 구현 완료
- [ ] YAML 기반 설정 관리 시스템 구축
- [ ] 병렬 처리 지원 (4개 이상 워커)
- [ ] 증분 처리 시스템 구현
- [ ] 실시간 진행률 모니터링 구현

### 기술적 완료 기준
- [ ] 메모리 사용량 80% 이하 유지
- [ ] 처리 속도 순차 처리 대비 2배 이상 개선
- [ ] 에러 발생 시 자동 복구 메커니즘
- [ ] 설정 변경 시 재시작 없이 적용
- [ ] 의존성 기반 스마트 재계산

### 품질 완료 기준
- [ ] 모든 스테이지에 대한 단위 테스트 작성
- [ ] 성능 벤치마크 수립 및 기준선 설정
- [ ] 에러 핸들링 및 로깅 시스템 구현
- [ ] 파이프라인 문서화 완료
- [ ] 설정 스키마 검증 구현

---

## 🚀 다음 단계

완료 후 [2.3 피처 검증 및 테스트](./2.3-feature-validation-testing-guide.md)로 진행하여 생성된 피처들의 품질을 검증하고 테스트합니다.

---

## 📚 참고 자료

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Python Multiprocessing Guide](https://docs.python.org/3/library/multiprocessing.html)
- [YAML Best Practices](https://yaml.org/spec/1.2/spec.html)
- [Pipeline Design Patterns](https://martinfowler.com/articles/data-monolith-to-mesh.html)
