---
title: "2.1 피처 엔지니어링 로직 개발 가이드"
description: "TMDBPreProcessor 기반 확장 가능한 피처 생성 시스템 구축"
author: "MLOps Team"
created: "2025-06-05"
updated: "2025-06-05"
version: "1.0"
stage: "2.1"
category: "Feature Engineering"
tags: ["피처엔지니어링", "TMDBPreProcessor", "데이터증강", "시간기반피처", "통계적피처"]
prerequisites: ["1단계 데이터 처리 완료", "Python 기초", "pandas/numpy"]
difficulty: "intermediate"
estimated_time: "4-6시간"
---

# 2.1 피처 엔지니어링 로직 개발 가이드

## 📋 개요

**목표**: TMDBPreProcessor를 기반으로 확장 가능한 피처 생성 시스템 구축

**핵심 가치**: ML 모델의 성능을 좌우하는 고품질 피처를 체계적으로 생성

---

## 🎯 학습 목표

### 이론적 목표
- 피처 엔지니어링의 핵심 원리 이해
- 도메인 지식을 피처로 변환하는 방법 습득
- 시간적/통계적/상호작용 피처의 설계 원칙 학습

### 실무적 목표
- TMDBPreProcessor 클래스 확장 및 고도화
- 다양한 유형의 피처 생성 로직 구현
- 피처 품질 검증 시스템 구축

---

## 🔧 2.1.1 TMDBPreProcessor 클래스 확장

### 현재 기본 구조 분석

기존 TMDBPreProcessor의 핵심 기능:
```python
class TMDBPreProcessor:
    def __init__(self, movies: list, user_count=100, max_select_count=20):
        # 설정 초기화
    
    @staticmethod
    def augmentation(movie):
        # 영화 평점 기반 데이터 증강: pow(2, rating)
        
    def generate_watch_second(self, rating):
        # 평점 기반 시청 시간 생성 로직
        
    def selection(self, user_id, features):
        # 사용자별 영화 선택 시뮬레이션
        
    def run(self):
        # 전체 전처리 파이프라인 실행
```

### 확장된 구조 설계

```python
class AdvancedTMDBPreProcessor:
    def __init__(self, movies: list, config: dict):
        self.movies = movies
        self.config = config
        self.feature_registry = {}
        self.validators = []
        self.transformers = {}
        
    def register_feature(self, name: str, extractor_func: callable, 
                        dependencies: list = None):
        """피처 추출 함수를 등록"""
        self.feature_registry[name] = {
            'extractor': extractor_func,
            'dependencies': dependencies or [],
            'metadata': {}
        }
    
    def add_validator(self, validator: callable):
        """피처 검증 함수 추가"""
        self.validators.append(validator)
    
    def extract_all_features(self):
        """의존성 순서에 따라 모든 피처 추출"""
        # 의존성 그래프 기반 실행 순서 결정
        # 각 피처 추출 및 검증
        pass
```

### 핵심 피처 생성 로직 개선

#### **데이터 증강 고도화**
```python
def advanced_augmentation(self, movie: dict, strategy: str = "rating_based"):
    """다양한 전략의 데이터 증강"""
    
    strategies = {
        'rating_based': lambda x: int(pow(2, x['vote_average'])),
        'popularity_based': lambda x: int(x['popularity'] / 10),
        'hybrid': lambda x: int(pow(1.5, x['vote_average']) * (x['popularity'] / 50))
    }
    
    if strategy not in strategies:
        raise ValueError(f"지원하지 않는 증강 전략: {strategy}")
    
    count = strategies[strategy](movie)
    
    # 최소/최대 제한 적용
    min_count = self.config.get('min_augmentation', 1)
    max_count = self.config.get('max_augmentation', 100)
    
    return max(min_count, min(count, max_count))
```

#### **시청 시간 모델링 개선**
```python
def generate_sophisticated_watch_time(self, movie: dict, user_profile: dict):
    """사용자 프로필과 영화 특성을 고려한 시청 시간 생성"""
    
    base_duration = movie.get('runtime', 120) * 60  # 초 단위
    rating = movie['vote_average']
    popularity = movie['popularity']
    
    # 사용자 선호도 반영
    genre_preference = self._calculate_genre_preference(
        movie['genre_ids'], user_profile
    )
    
    # 시청 완료 확률 계산
    completion_prob = self._calculate_completion_probability(
        rating, popularity, genre_preference
    )
    
    # 실제 시청 시간 계산
    if completion_prob > 0.8:
        # 높은 확률로 완시청
        watch_time = base_duration * random.uniform(0.9, 1.0)
    elif completion_prob > 0.5:
        # 중간 지점까지 시청
        watch_time = base_duration * random.uniform(0.4, 0.8)
    else:
        # 초반에 이탈
        watch_time = base_duration * random.uniform(0.1, 0.3)
    
    return int(watch_time)

def _calculate_genre_preference(self, genre_ids: list, user_profile: dict):
    """사용자의 장르 선호도 계산"""
    preferences = user_profile.get('genre_preferences', {})
    
    if not genre_ids:
        return 0.5  # 기본값
    
    scores = [preferences.get(str(gid), 0.5) for gid in genre_ids]
    return sum(scores) / len(scores)

def _calculate_completion_probability(self, rating: float, popularity: float, 
                                   genre_pref: float):
    """영화 완시청 확률 계산"""
    # 가중 평균으로 확률 계산
    prob = (rating * 0.4 + (popularity / 100) * 0.3 + genre_pref * 0.3) / 10
    return max(0.1, min(0.95, prob))  # 0.1-0.95 범위로 제한
```

---

## 🔧 2.1.2 고급 피처 엔지니어링

### 시간 기반 피처

#### **출시연도별 트렌드 분석**
```python
def extract_temporal_features(self, movies: list):
    """시간 기반 피처 추출"""
    
    # 영화별 출시연도 추출
    for movie in movies:
        release_date = movie.get('release_date', '')
        if release_date:
            year = int(release_date[:4])
            movie['release_year'] = year
            movie['decade'] = (year // 10) * 10
            movie['era'] = self._classify_era(year)
    
    # 연도별 인기도 트렌드 계산
    year_popularity = {}
    for movie in movies:
        year = movie.get('release_year')
        if year:
            if year not in year_popularity:
                year_popularity[year] = []
            year_popularity[year].append(movie['popularity'])
    
    # 각 영화에 연도별 상대적 인기도 추가
    for movie in movies:
        year = movie.get('release_year')
        if year and year in year_popularity:
            year_avg = sum(year_popularity[year]) / len(year_popularity[year])
            movie['relative_popularity'] = movie['popularity'] / year_avg
    
    return movies

def _classify_era(self, year: int):
    """영화 시대 분류"""
    if year < 1970:
        return 'classic'
    elif year < 1990:
        return 'vintage'  
    elif year < 2010:
        return 'modern'
    else:
        return 'contemporary'
```

#### **계절성 패턴 모델링**
```python
def generate_seasonal_preferences(self, user_profile: dict):
    """사용자별 계절적 장르 선호도 생성"""
    
    seasonal_patterns = {
        'spring': {'romance': 1.2, 'drama': 1.1, 'comedy': 1.0},
        'summer': {'action': 1.3, 'adventure': 1.2, 'comedy': 1.1},
        'autumn': {'thriller': 1.2, 'drama': 1.2, 'horror': 1.1},
        'winter': {'drama': 1.3, 'romance': 1.1, 'family': 1.2}
    }
    
    # 사용자의 기본 선호도에 계절 가중치 적용
    current_season = self._get_current_season()
    pattern = seasonal_patterns.get(current_season, {})
    
    adjusted_preferences = user_profile.get('genre_preferences', {}).copy()
    for genre, weight in pattern.items():
        if genre in adjusted_preferences:
            adjusted_preferences[genre] *= weight
    
    return adjusted_preferences

def _get_current_season(self):
    """현재 계절 반환 (시뮬레이션용)"""
    import random
    return random.choice(['spring', 'summer', 'autumn', 'winter'])
```

### 통계적 피처

#### **영화별 평점 분포 분석**
```python
def calculate_rating_distribution_features(self, movies: list):
    """영화별 평점 분포 통계 피처 계산"""
    
    all_ratings = [movie['vote_average'] for movie in movies]
    
    # 전체 분포 통계
    mean_rating = np.mean(all_ratings)
    std_rating = np.std(all_ratings)
    
    for movie in movies:
        rating = movie['vote_average']
        
        # Z-score (정규화 점수)
        movie['rating_zscore'] = (rating - mean_rating) / std_rating
        
        # 백분위 순위
        movie['rating_percentile'] = (
            sum(1 for r in all_ratings if r <= rating) / len(all_ratings)
        )
        
        # 카테고리 분류
        if rating >= 8.0:
            movie['rating_category'] = 'excellent'
        elif rating >= 7.0:
            movie['rating_category'] = 'good'
        elif rating >= 6.0:
            movie['rating_category'] = 'average'
        else:
            movie['rating_category'] = 'poor'
    
    return movies
```

#### **장르별 통계 계산**
```python
def calculate_genre_statistics(self, movies: list):
    """장르별 통계적 피처 계산"""
    
    # 장르별 데이터 수집
    genre_stats = {}
    for movie in movies:
        for genre_id in movie.get('genre_ids', []):
            if genre_id not in genre_stats:
                genre_stats[genre_id] = {
                    'ratings': [],
                    'popularity': [],
                    'count': 0
                }
            
            genre_stats[genre_id]['ratings'].append(movie['vote_average'])
            genre_stats[genre_id]['popularity'].append(movie['popularity'])
            genre_stats[genre_id]['count'] += 1
    
    # 장르별 통계 계산
    for genre_id, data in genre_stats.items():
        data['avg_rating'] = np.mean(data['ratings'])
        data['avg_popularity'] = np.mean(data['popularity'])
        data['rating_std'] = np.std(data['ratings'])
        data['popularity_std'] = np.std(data['popularity'])
    
    # 각 영화에 장르 통계 피처 추가
    for movie in movies:
        genre_features = {
            'avg_genre_rating': 0,
            'avg_genre_popularity': 0,
            'genre_diversity': len(movie.get('genre_ids', []))
        }
        
        if movie.get('genre_ids'):
            ratings = [genre_stats[gid]['avg_rating'] 
                      for gid in movie['genre_ids'] 
                      if gid in genre_stats]
            popularities = [genre_stats[gid]['avg_popularity'] 
                           for gid in movie['genre_ids'] 
                           if gid in genre_stats]
            
            if ratings:
                genre_features['avg_genre_rating'] = np.mean(ratings)
            if popularities:
                genre_features['avg_genre_popularity'] = np.mean(popularities)
        
        movie.update(genre_features)
    
    return movies, genre_stats
```

### 상호작용 피처

#### **사용자-장르 친화도**
```python
def calculate_user_genre_affinity(self, interactions: list):
    """사용자별 장르 친화도 계산"""
    
    user_genre_interactions = {}
    
    # 사용자별 장르 상호작용 수집
    for interaction in interactions:
        user_id = interaction['user_id']
        movie_genres = interaction.get('movie_genres', [])
        watch_time = interaction['watch_seconds']
        rating = interaction['rating']
        
        if user_id not in user_genre_interactions:
            user_genre_interactions[user_id] = {}
        
        for genre in movie_genres:
            if genre not in user_genre_interactions[user_id]:
                user_genre_interactions[user_id][genre] = {
                    'total_watch_time': 0,
                    'total_ratings': 0,
                    'count': 0
                }
            
            user_genre_interactions[user_id][genre]['total_watch_time'] += watch_time
            user_genre_interactions[user_id][genre]['total_ratings'] += rating
            user_genre_interactions[user_id][genre]['count'] += 1
    
    # 친화도 점수 계산
    user_affinities = {}
    for user_id, genres in user_genre_interactions.items():
        user_affinities[user_id] = {}
        
        for genre, stats in genres.items():
            avg_watch_time = stats['total_watch_time'] / stats['count']
            avg_rating = stats['total_ratings'] / stats['count']
            
            # 정규화된 친화도 점수 (0-1 범위)
            affinity_score = (avg_rating / 10.0 * 0.6 + 
                            min(avg_watch_time / 7200, 1.0) * 0.4)
            
            user_affinities[user_id][genre] = affinity_score
    
    return user_affinities
```

#### **영화-영화 유사도**
```python
def calculate_movie_similarity(self, movies: list):
    """영화 간 유사도 계산"""
    
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.preprocessing import MultiLabelBinarizer
    
    # 장르 기반 유사도
    genres_list = [movie.get('genre_ids', []) for movie in movies]
    mlb = MultiLabelBinarizer()
    genre_matrix = mlb.fit_transform(genres_list)
    
    genre_similarity = cosine_similarity(genre_matrix)
    
    # 메타데이터 기반 유사도
    features = []
    for movie in movies:
        feature_vector = [
            movie['vote_average'] / 10.0,  # 정규화된 평점
            min(movie['popularity'] / 100, 1.0),  # 정규화된 인기도
            movie.get('release_year', 2000) / 2025.0  # 정규화된 출시연도
        ]
        features.append(feature_vector)
    
    metadata_similarity = cosine_similarity(features)
    
    # 가중 평균으로 최종 유사도 계산
    final_similarity = (genre_similarity * 0.7 + metadata_similarity * 0.3)
    
    # 각 영화에 유사 영화 정보 추가
    for i, movie in enumerate(movies):
        similarities = final_similarity[i]
        
        # 자기 자신 제외하고 상위 5개 유사 영화 인덱스
        similar_indices = np.argsort(similarities)[-6:-1][::-1]
        
        movie['similar_movies'] = [
            {
                'movie_id': movies[idx]['id'],
                'similarity': similarities[idx]
            }
            for idx in similar_indices
        ]
        
        movie['avg_similarity_score'] = np.mean([
            similarities[idx] for idx in similar_indices
        ])
    
    return movies, final_similarity
```

---

## 🔧 2.1.3 피처 검증 시스템

### 통계적 검증

#### **피처 분포 정상성 확인**
```python
def validate_feature_distribution(self, feature_data: pd.DataFrame):
    """피처 분포의 통계적 정상성 검증"""
    
    validation_results = {}
    
    for column in feature_data.select_dtypes(include=[np.number]).columns:
        series = feature_data[column].dropna()
        
        if len(series) < 10:
            continue
        
        results = {
            'column': column,
            'count': len(series),
            'missing_ratio': feature_data[column].isnull().sum() / len(feature_data),
            'mean': series.mean(),
            'std': series.std(),
            'skewness': series.skew(),
            'kurtosis': series.kurtosis()
        }
        
        # 정규성 검정 (Shapiro-Wilk test for small samples)
        if len(series) <= 5000:
            from scipy.stats import shapiro
            stat, p_value = shapiro(series)
            results['normality_test'] = {
                'statistic': stat,
                'p_value': p_value,
                'is_normal': p_value > 0.05
            }
        
        # 이상치 탐지 (IQR 방법)
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = series[(series < lower_bound) | (series > upper_bound)]
        results['outliers'] = {
            'count': len(outliers),
            'ratio': len(outliers) / len(series),
            'values': outliers.tolist()[:10]  # 최대 10개만 저장
        }
        
        validation_results[column] = results
    
    return validation_results
```

#### **상관관계 분석**
```python
def analyze_feature_correlations(self, feature_data: pd.DataFrame, 
                                threshold: float = 0.9):
    """피처 간 상관관계 분석 및 다중공선성 검사"""
    
    # 수치형 피처만 선택
    numeric_features = feature_data.select_dtypes(include=[np.number])
    
    # 상관계수 행렬 계산
    correlation_matrix = numeric_features.corr()
    
    # 높은 상관관계 피처 쌍 찾기
    high_correlations = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > threshold:
                high_correlations.append({
                    'feature1': correlation_matrix.columns[i],
                    'feature2': correlation_matrix.columns[j],
                    'correlation': corr_value
                })
    
    # VIF (Variance Inflation Factor) 계산
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    
    vif_data = pd.DataFrame()
    vif_data["Feature"] = numeric_features.columns
    vif_data["VIF"] = [
        variance_inflation_factor(numeric_features.values, i) 
        for i in range(len(numeric_features.columns))
    ]
    
    # 다중공선성 문제가 있는 피처 식별 (VIF > 10)
    multicollinear_features = vif_data[vif_data["VIF"] > 10]["Feature"].tolist()
    
    return {
        'correlation_matrix': correlation_matrix,
        'high_correlations': high_correlations,
        'vif_scores': vif_data,
        'multicollinear_features': multicollinear_features
    }
```

### 비즈니스 로직 검증

#### **도메인 지식 기반 규칙**
```python
def validate_business_logic(self, movies: list, interactions: list):
    """비즈니스 도메인 지식 기반 데이터 검증"""
    
    validation_errors = []
    
    # 영화 데이터 검증
    for movie in movies:
        movie_id = movie.get('id')
        
        # 평점 범위 검증 (0-10)
        rating = movie.get('vote_average', 0)
        if not 0 <= rating <= 10:
            validation_errors.append({
                'type': 'rating_range',
                'movie_id': movie_id,
                'message': f'평점이 유효 범위를 벗어남: {rating}'
            })
        
        # 인기도 음수 검증
        popularity = movie.get('popularity', 0)
        if popularity < 0:
            validation_errors.append({
                'type': 'negative_popularity',
                'movie_id': movie_id,
                'message': f'인기도가 음수: {popularity}'
            })
        
        # 출시일 검증
        release_date = movie.get('release_date', '')
        if release_date:
            try:
                from datetime import datetime
                release_year = int(release_date[:4])
                current_year = datetime.now().year
                
                if release_year < 1900 or release_year > current_year + 2:
                    validation_errors.append({
                        'type': 'invalid_release_year',
                        'movie_id': movie_id,
                        'message': f'비현실적인 출시연도: {release_year}'
                    })
            except (ValueError, IndexError):
                validation_errors.append({
                    'type': 'invalid_date_format',
                    'movie_id': movie_id,
                    'message': f'잘못된 날짜 형식: {release_date}'
                })
    
    # 상호작용 데이터 검증
    for interaction in interactions:
        user_id = interaction.get('user_id')
        movie_id = interaction.get('content_id')
        watch_time = interaction.get('watch_seconds', 0)
        rating = interaction.get('rating', 0)
        
        # 시청 시간 현실성 검증 (최대 8시간)
        if watch_time > 8 * 3600:
            validation_errors.append({
                'type': 'unrealistic_watch_time',
                'user_id': user_id,
                'movie_id': movie_id,
                'message': f'비현실적인 시청 시간: {watch_time}초'
            })
        
        # 시청 시간 음수 검증
        if watch_time < 0:
            validation_errors.append({
                'type': 'negative_watch_time',
                'user_id': user_id,
                'movie_id': movie_id,
                'message': f'음수 시청 시간: {watch_time}'
            })
        
        # 평점 범위 검증
        if not 0 <= rating <= 10:
            validation_errors.append({
                'type': 'invalid_rating',
                'user_id': user_id,
                'movie_id': movie_id,
                'message': f'유효하지 않은 평점: {rating}'
            })
    
    return validation_errors
```

#### **레이블 리키지 방지**
```python
def check_label_leakage(self, features: pd.DataFrame, target: pd.Series):
    """타겟 변수와의 레이블 리키지 검사"""
    
    leakage_warnings = []
    
    # 수치형 피처와 타겟의 상관관계 확인
    for column in features.select_dtypes(include=[np.number]).columns:
        correlation = features[column].corr(target)
        
        # 너무 높은 상관관계는 리키지 가능성
        if abs(correlation) > 0.95:
            leakage_warnings.append({
                'feature': column,
                'correlation': correlation,
                'severity': 'high',
                'message': f'타겟과 과도하게 높은 상관관계: {correlation:.3f}'
            })
        elif abs(correlation) > 0.8:
            leakage_warnings.append({
                'feature': column,
                'correlation': correlation,
                'severity': 'medium',
                'message': f'타겟과 높은 상관관계 주의: {correlation:.3f}'
            })
    
    # 미래 정보 사용 검사 (시간 기반)
    time_features = [col for col in features.columns 
                    if any(keyword in col.lower() 
                          for keyword in ['future', 'next', 'after', 'tomorrow'])]
    
    if time_features:
        leakage_warnings.append({
            'feature': time_features,
            'severity': 'high',
            'message': '미래 정보를 포함한 피처 발견'
        })
    
    return leakage_warnings
```

---

## ✅ 완료 기준

### 기능적 완료 기준
- [ ] TMDBPreProcessor 확장 클래스 구현 완료
- [ ] 시간 기반 피처 5개 이상 생성
- [ ] 통계적 피처 5개 이상 생성  
- [ ] 상호작용 피처 3개 이상 생성
- [ ] 피처 검증 시스템 구현

### 기술적 완료 기준
- [ ] 피처 등록 시스템 구현
- [ ] 의존성 기반 실행 순서 관리
- [ ] 병렬 처리 지원
- [ ] 메모리 효율적 처리
- [ ] 설정 파일 기반 관리

### 품질 완료 기준
- [ ] 모든 피처에 대한 통계적 검증 통과
- [ ] 비즈니스 로직 검증 100% 통과
- [ ] 레이블 리키지 검사 통과
- [ ] 성능 벤치마크 수립
- [ ] 문서화 완료

---

## 🚀 다음 단계

완료 후 [2.2 피처 생성 파이프라인 구축](./2.2-feature-pipeline-construction-guide.md)으로 진행하여 생성된 피처들을 자동화된 파이프라인으로 관리합니다.

---

## 📚 참고 자료

- [Feature Engineering for Machine Learning](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Scikit-learn Feature Engineering](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Domain Knowledge in Feature Engineering](https://towardsdatascience.com/)
