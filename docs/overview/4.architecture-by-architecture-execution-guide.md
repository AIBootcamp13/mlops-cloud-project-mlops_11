---
title: MLOps 아키텍처별 실행 가이드 - 집 짓기 비유와 함께
description: MLOps 9아키텍처의 단계별 실행 방법과 집 짓기 비유를 통한 직관적 이해 가이드
author: MLOps Project Team
created: 2025-06-08
modified: 2025-06-08
version: "1.0"
tags:
  - MLOps
  - Architecture
  - Execution Guide
  - Step by Step
  - House Building Analogy
  - Tutorial
category: Execution Guide
status: Active
language: Korean
stage_range: 1-9
difficulty: Beginner to Intermediate
estimated_reading_time: 45 minutes
guide_type: Step by Step Tutorial
target_audience: MLOps Engineers, Data Scientists, Developers
learning_objective: Understanding and executing each MLOps architecture stage
house_analogy: Complete house building process
---

# MLOps 아키텍처별 실행 가이드 - 집 짓기 비유와 함께 🏠

## 개요

이 가이드는 MLOps 9아키텍처를 집 짓기 과정에 비유하여 각 아키텍처의 개념을 이해하고, 
실제 실행 방법을 단계별로 안내합니다. 복잡한 MLOps 개념을 친숙한 건축 과정으로 설명하여 
누구나 쉽게 따라할 수 있도록 구성했습니다.

---

## 🚀 사전 준비사항

### 환경 설정
```bash
# 1. 프로젝트 클론
git clone <repository-url>
cd movie-mlops

# 2. 환경 변수 설정
cp .env.template .env
# .env 파일에서 TMDB_API_KEY 등 필수 값 설정

# 3. 실행 권한 부여
chmod +x run_movie_mlops.sh
chmod +x scripts/**/*.sh

# 4. 기본 환경 설정
./run_movie_mlops.sh
# 메뉴에서 1번 선택 (최초 1회)
```

---

## 💪 1아키텍처: 기초 공사 및 배관 작업 (Apache Airflow)

### 🏗️ 집 짓기 비유
**"집의 토대가 되는 기초 콘크리트를 붓고, 상하수도 배관을 설치"**

데이터 파이프라인은 집의 배관과 같습니다. 깨끗한 물(데이터)이 들어와서 
처리된 후 필요한 곳으로 흘러가야 하듯이, 원시 데이터가 수집되어 
처리된 후 ML 모델이 사용할 수 있는 형태로 변환되어야 합니다.

### 📚 개념 설명

**데이터 파이프라인이란?**
- 원시 데이터를 수집하여 분석 가능한 형태로 변환하고 저장하는 자동화된 프로세스
- ETL(Extract, Transform, Load) 과정을 자동화
- 데이터 품질 보장 및 일관성 유지

**Apache Airflow란?**
- Python으로 작성된 오픈소스 워크플로우 관리 플랫폼
- DAG(Directed Acyclic Graph)를 통해 복잡한 워크플로우를 시각적으로 관리
- 스케줄링, 모니터링, 실패 처리 등 강력한 기능 제공

### 🔧 실행 방법

#### 개별 실행
```bash
# PostgreSQL과 Airflow 서비스 시작
docker compose -f docker/docker-compose.postgres.yml up -d
docker compose -f docker/docker-compose.airflow.yml up -d
```

#### 통합 스크립트 사용
```bash
./run_movie_mlops.sh
# 메뉴에서 5번 선택 (API 스택)
```

### 🎯 Airflow 사용 방법

#### 1. Airflow UI 접속 및 기본 사용법
```bash
# Airflow 웹 UI 접속
open http://localhost:8080
# 로그인 정보: admin / admin
```

**주요 UI 구성 요소:**
- **DAGs**: 워크플로우 목록 및 상태 확인
- **Graph View**: DAG의 태스크 의존성 시각화
- **Tree View**: 시간순 실행 이력 확인
- **Logs**: 각 태스크의 실행 로그

#### 2. DAG 실행 및 모니터링
```bash
# DAG 수동 실행 (UI에서)
# 1. DAGs 페이지에서 movie_data_collection DAG 클릭
# 2. 우측 상단 "Trigger DAG" 버튼 클릭
# 3. Graph View에서 실행 상태 실시간 확인

# API를 통한 DAG 실행
curl -X POST "http://localhost:8080/api/v1/dags/movie_data_collection/dagRuns" \
     -H "Content-Type: application/json" \
     -u admin:admin \
     -d '{"conf": {}}'
```

#### 3. 데이터 수집 결과 확인
```bash
# 수집된 원시 데이터 확인
ls -la data/raw/tmdb/
cat data/raw/tmdb/popular.json | jq '.movies[0]'

# 처리된 데이터 확인
ls -la data/processed/
head data/processed/watch_log.csv
```

### ✅ 핵심 확인 포인트
- ✅ TMDB API에서 영화 데이터 수집 완료
- ✅ 데이터 전처리 및 watch_log.csv 생성
- ✅ Airflow UI에서 DAG 실행 상태 녹색으로 표시
- ✅ 실패 시 자동 재시도 메커니즘 동작

### 🚨 문제 해결
```bash
# Airflow 컨테이너 로그 확인
docker logs movie-mlops-airflow

# 태스크 실패 시 로그 확인 방법
# Airflow UI > Graph View > 실패한 태스크 클릭 > Logs 탭
```

---

## 📦 2아키텍처: 자재 창고 건설 (Feast)

### 🏗️ 집 짓기 비유
**"건축 자재들을 체계적으로 보관할 창고 건설"**

피처 스토어는 건축 자재 창고와 같습니다. 다양한 자재(피처)들을 종류별로 
정리해서 보관하고, 필요할 때 언제든 빠르게 꺼내 쓸 수 있도록 관리하는 
체계적인 저장소입니다.

### 📚 개념 설명

**피처 스토어란?**
- ML 모델이 사용하는 피처(Feature)들을 중앙에서 관리하는 시스템
- 일관된 피처 정의와 재사용성 보장
- 실시간 서빙과 배치 처리 모두 지원

**Feast란?**
- 오픈소스 피처 스토어 플랫폼
- 피처 정의, 저장, 서빙을 통합 관리
- 다양한 데이터 소스와 저장소 지원

### 🔧 실행 방법

#### 개별 실행
```bash
# Redis와 Feast 서비스 시작
docker compose -f docker/docker-compose.redis.yml up -d
docker compose -f docker/docker-compose.feast.yml up -d
```

#### ML 스택으로 실행
```bash
./run_movie_mlops.sh
# 메뉴에서 6번 선택 (ML 스택)
```

### 🎯 Feast 사용 방법

#### 1. 피처 스토어 초기화
```bash
# Feast 컨테이너 접속
docker exec -it movie-mlops-feast bash
cd /app/feast_repo

# 피처 정의 적용
feast apply
```

#### 2. 피처 정의 확인
```bash
# 피처 뷰 목록 확인
feast feature-views list

# 엔티티 목록 확인
feast entities list

# 피처 서비스 목록 확인
feast feature-services list
```

#### 3. 피처 서빙 테스트
```python
# Python을 통한 온라인 피처 조회
python3 -c """
from feast import FeatureStore
import pandas as pd

# 피처 스토어 연결
fs = FeatureStore(repo_path='.')

# 온라인 피처 조회
features = fs.get_online_features(
    features=[
        'movie_features:rating',
        'movie_features:popularity',
        'user_features:age',
        'user_features:genre_preference'
    ],
    entity_rows=[
        {'movie_id': 1, 'user_id': 1},
        {'movie_id': 2, 'user_id': 1}
    ]
)

# 결과 출력
result_df = features.to_df()
print('피처 조회 결과:')
print(result_df)
"""
```

#### 4. Feast UI 접속
```bash
# Feast 웹 UI 접속
open http://localhost:6566
```

### 🌐 API를 통한 피처 조회

#### 개별 피처 조회
```bash
# 특정 영화의 피처 조회
curl -X GET "http://localhost:8000/api/v1/features/movie/123" \
     -H "Content-Type: application/json"
```

#### 배치 피처 조회
```bash
# 여러 엔티티의 피처 일괄 조회
curl -X POST "http://localhost:8000/api/v1/features/batch" \
     -H "Content-Type: application/json" \
     -d '{
       "entity_ids": [1, 2, 3, 4, 5],
       "features": ["rating", "popularity", "genre"],
       "entity_type": "movie"
     }'
```

### ✅ 핵심 확인 포인트
- ✅ 피처 정의가 Feast에 정상 등록
- ✅ 온라인 피처 서빙 정상 동작
- ✅ 배치 피처 조회 가능
- ✅ Feast UI에서 피처 메타데이터 확인

---

## 📋 3아키텍처: 설계도면 관리소 (Git + GitHub)

### 🏗️ 집 짓기 비유
**"건축 설계도면을 버전별로 관리하고, 변경 사항을 추적"**

버전 관리 시스템은 건축 설계도면 관리소와 같습니다. 설계 변경 이력을 모두 
기록하고, 여러 사람이 협업할 때 충돌 없이 작업할 수 있도록 조정하며, 
문제 발생 시 이전 버전으로 되돌릴 수 있습니다.

### 📚 개념 설명

**버전 관리 시스템이란?**
- 파일의 변경 이력을 추적하고 관리하는 시스템
- 협업 시 코드 충돌 방지 및 병합 지원
- 브랜치를 통한 병렬 개발 가능

**Git이란?**
- 분산 버전 관리 시스템의 대표주자
- 로컬과 원격 저장소 분리로 오프라인 작업 가능
- 강력한 브랜치 및 병합 기능

### 🔧 실행 방법

#### Git 상태 확인 (이미 구성됨)
```bash
# 현재 Git 상태 확인
git status
git log --oneline -10

# 원격 저장소 확인
git remote -v

# 브랜치 확인
git branch -a
```

### 🎯 Git 사용 방법

#### 1. 기본 Git 워크플로우
```bash
# 1. 변경사항 확인
git status
git diff

# 2. 변경사항 스테이징
git add .
# 또는 특정 파일만
git add src/api/main.py

# 3. 커밋
git commit -m "feat: 영화 추천 API 성능 개선"

# 4. 원격 저장소에 푸시
git push origin main
```

#### 2. 브랜치 전략
```bash
# 새 기능 개발을 위한 브랜치 생성
git checkout -b feature/new-recommendation-algorithm

# 브랜치에서 작업 후 커밋
git add .
git commit -m "feat: 새로운 추천 알고리즘 구현"

# 메인 브랜치로 병합
git checkout main
git merge feature/new-recommendation-algorithm

# 브랜치 삭제
git branch -d feature/new-recommendation-algorithm
```

### 🔄 GitHub Actions (CI/CD)

#### 워크플로우 파일 확인
```bash
# 모든 워크플로우 확인
ls -la .github/workflows/

# CI 워크플로우 내용 확인
cat .github/workflows/ci.yml
```

#### 로컬 테스트 실행
```bash
# 전체 테스트 실행
./run_tests.sh

# 개별 테스트 카테고리
python -m pytest tests/unit/ -v
python -m pytest tests/integration/ -v
python -m pytest tests/e2e/ -v

# 코드 품질 검사
flake8 src/
black --check src/
mypy src/
```

### ✅ 핵심 확인 포인트
- ✅ Git 커밋 히스토리 정상 추적
- ✅ GitHub Actions 워크플로우 정상 실행
- ✅ 코드 품질 검사 통과
- ✅ 테스트 자동 실행 및 통과

---

## 🏗️ 4아키텍처: 자동화 건설 장비 도입 (GitHub Actions)

### 🏗️ 집 짓기 비유
**"크레인, 컨베이어벨트 등 자동화 건설 장비로 효율성 향상"**

CI/CD 파이프라인은 자동화 건설 장비와 같습니다. 사람이 일일이 하던 
반복적인 작업들을 기계가 자동으로 처리해서 실수를 줄이고 
속도를 크게 향상시킵니다.

### 📚 개념 설명

**CI/CD란?**
- **CI (Continuous Integration)**: 지속적 통합 - 코드 변경사항을 자주 메인 브랜치에 통합
- **CD (Continuous Deployment)**: 지속적 배포 - 통합된 코드를 자동으로 프로덕션에 배포
- 자동화된 테스트, 빌드, 배포 프로세스

**GitHub Actions란?**
- GitHub에 내장된 CI/CD 플랫폼
- YAML 파일로 워크플로우 정의
- 다양한 이벤트 트리거 지원 (push, pull_request 등)

### 🔧 실행 방법

#### 워크플로우 확인
```bash
# CI 워크플로우 (.github/workflows/ci.yml)
cat .github/workflows/ci.yml

# CD 워크플로우 (.github/workflows/cd.yml)  
cat .github/workflows/cd.yml

# ML 파이프라인 워크플로우
cat .github/workflows/ml-pipeline.yml
```

### 🎯 GitHub Actions 사용 방법

#### 1. 워크플로우 트리거
```bash
# 코드 변경 후 자동 트리거
echo "# 테스트 변경" >> README.md
git add README.md
git commit -m "docs: README 업데이트"
git push origin main

# GitHub 리포지토리의 Actions 탭에서 실행 상태 확인
```

#### 2. 로컬에서 동일한 검사 실행
```bash
# 코드 포맷팅 검사
black --check src/
isort --check-only src/

# 린팅 검사
flake8 src/
pylint src/

# 타입 검사
mypy src/

# 보안 검사
bandit -r src/
safety check
```

#### 3. Docker 이미지 빌드 테스트
```bash
# 모든 Dockerfile 빌드 테스트
docker build -f docker/dockerfiles/Dockerfile.api \
             -t movie-mlops-api .

docker build -f docker/dockerfiles/Dockerfile.mlflow \
             -t movie-mlops-mlflow .

docker build -f docker/dockerfiles/Dockerfile.feast \
             -t movie-mlops-feast .

docker build -f docker/dockerfiles/Dockerfile.pytorch \
             -t movie-mlops-pytorch .
```

### ✅ 핵심 확인 포인트
- ✅ 모든 테스트 통과
- ✅ 코드 품질 검사 통과
- ✅ Docker 이미지 빌드 성공
- ✅ 자동 배포 (설정된 경우) 성공

---

## 👷‍♂️ 5아키텍처: 공사 관리 시스템 구축 (Airflow 워크플로우)

### 🏗️ 집 짓기 비유
**"전체 공사 일정과 작업자들을 체계적으로 관리하는 시스템"**

워크플로우 오케스트레이션은 공사 관리 시스템과 같습니다. 어떤 작업을 
언제, 어떤 순서로, 누가 해야 하는지를 체계적으로 관리하고, 
전체 프로젝트가 계획대로 진행되도록 조정합니다.

### 📚 개념 설명

**워크플로우 오케스트레이션이란?**
- 복잡한 작업들을 정의된 순서와 조건에 따라 자동 실행
- 작업 간 의존성 관리 및 실행 순서 제어
- 실패 시 재시도, 알림 등 오류 처리

**DAG (Directed Acyclic Graph)란?**
- 방향이 있고 순환하지 않는 그래프
- 작업(Task)들 간의 의존성을 시각적으로 표현
- Airflow에서 워크플로우를 정의하는 기본 단위

### 🔧 실행 방법

#### ML 훈련 파이프라인 실행
```bash
# Airflow에서 훈련 DAG 실행
open http://localhost:8080
# movie_training_pipeline DAG 활성화 후 실행

# API를 통한 DAG 트리거
curl -X POST \
     "http://localhost:8080/api/v1/dags/movie_training_pipeline/dagRuns" \
     -H "Content-Type: application/json" \
     -u admin:admin \
     -d '{"conf": {}}'
```

### 🎯 Airflow 워크플로우 사용 방법

#### 1. DAG 구조 이해
```python
# movie_training_pipeline.py의 주요 구조
"""
prepare_training_data → train_movie_model → evaluate_trained_model → register_model_to_mlflow
"""

# 각 태스크의 역할:
# 1. prepare_training_data: 훈련용 데이터셋 준비
# 2. train_movie_model: 모델 훈련 실행
# 3. evaluate_trained_model: 모델 성능 평가
# 4. register_model_to_mlflow: MLflow에 모델 등록
```

#### 2. 훈련 진행 상황 모니터링
```bash
# Airflow 컨테이너 로그 실시간 확인
docker logs -f movie-mlops-airflow

# 특정 태스크 로그 확인 (Airflow UI에서)
# Graph View > 태스크 클릭 > Logs 탭
```

#### 3. 수동 훈련 테스트
```python
# 컨테이너 내부에서 직접 훈련 실행
docker exec -it movie-mlops-api python3 -c """
from src.dataset.watch_log import get_datasets
from src.models.legacy.movie_predictor import MoviePredictor
from src.training.train import train
from src.dataset.data_loader import SimpleDataLoader
from src.utils.utils import init_seed

# 시드 초기화
init_seed()

# 데이터 로드
train_dataset, val_dataset, test_dataset = get_datasets()
print(f'훈련 데이터: {len(train_dataset.features)}개')
print(f'검증 데이터: {len(val_dataset.features)}개')

# 모델 생성
model = MoviePredictor(
    input_dim=train_dataset.features_dim,
    num_classes=train_dataset.num_classes,
    hidden_dim=64
)

# 훈련 실행
train_loader = SimpleDataLoader(
    train_dataset.features, 
    train_dataset.labels, 
    batch_size=32
)

for epoch in range(5):
    loss = train(model, train_loader)
    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')

print('훈련 완료!')
"""
```

### ✅ 핵심 확인 포인트
- ✅ DAG의 모든 태스크 성공적으로 완료
- ✅ 훈련된 모델 파일 생성 (models/trained/ 디렉토리)
- ✅ 모델 성능 지표 로그 출력
- ✅ XCom을 통한 태스크 간 데이터 전달 정상

---

## 🏅 6아키텍처: 품질 검사 및 건축 인증소 (MLflow)

### 🏗️ 집 짓기 비유
**"완성된 부분들을 검사하고 건축 허가를 받는 인증 과정"**

모델 레지스트리는 건축 인증소와 같습니다. 완성된 모델들이 실제 서비스에서 
사용하기에 적합한지 품질을 검사하고, 승인 과정을 거쳐 프로덕션에 
배포할 수 있는 인증을 부여합니다.

### 📚 개념 설명

**모델 레지스트리란?**
- 학습된 ML 모델들을 중앙에서 저장, 버전 관리하는 시스템
- 모델의 메타데이터, 성능 지표, 하이퍼파라미터 추적
- 스테이지 관리 (Development → Staging → Production)

**MLflow란?**
- 오픈소스 ML 생명주기 관리 플랫폼
- 실험 추적, 모델 패키징, 모델 레지스트리, 모델 서빙 통합 제공
- 다양한 ML 프레임워크 지원

### 🔧 실행 방법

#### MLflow 서버 시작
```bash
# MLflow 단독 실행
docker compose -f docker/docker-compose.mlflow.yml up -d

# 또는 ML 스택으로 실행
./run_movie_mlops.sh
# 메뉴에서 6번 선택 (ML 스택)

# MLflow UI 접속
open http://localhost:5000
```

### 🎯 MLflow 사용 방법

#### 1. 실험 생성 및 관리
```bash
# API를 통한 실험 생성
curl -X POST "http://localhost:8000/mlflow/experiments" \
     -H "Content-Type: application/json" \
     -d '{
       "name": "movie_recommendation_experiment",
       "description": "영화 추천 모델 실험"
     }'

# 실험 목록 조회
curl -X GET "http://localhost:8000/mlflow/experiments"
```

#### 2. 모델 등록 및 관리
```bash
# 등록된 모델 조회
curl -X GET "http://localhost:8000/mlflow/models"

# 특정 모델 상세 정보 조회
curl -X GET "http://localhost:8000/mlflow/models/movie_predictor"

# 모델 스테이지 변경 (Staging → Production)
curl -X POST "http://localhost:8000/mlflow/models/stage-transition" \
     -H "Content-Type: application/json" \
     -d '{
       "model_name": "movie_predictor",
       "version": "1",
       "stage": "Production",
       "description": "첫 번째 프로덕션 모델"
     }'
```

#### 3. Python API를 통한 모델 관리
```python
# MLflow 모델 레지스트리 직접 사용
docker exec -it movie-mlops-mlflow python3 -c """
import mlflow
from src.mlflow.model_registry import get_model_registry

# 모델 레지스트리 연결
registry = get_model_registry()

# 등록된 모델 목록 조회
models = registry.list_models()
print(f'등록된 모델 수: {len(models)}')

for model in models:
    print(f'모델명: {model["name"]}')
    print(f'최신 버전들: {model["latest_versions"]}')
    print('---')

# 모델 성능 비교
if models:
    model_name = models[0]['name']
    comparison = registry.compare_model_versions(
        model_name=model_name,
        versions=['1', '2'] if len(models) > 1 else ['1'],
        metrics=['rmse', 'mae', 'accuracy']
    )
    print('모델 성능 비교:')
    print(comparison)
"""
```

#### 4. 모델 프로덕션 승격
```bash
# 모델을 프로덕션으로 승격
curl -X POST \
     "http://localhost:8000/mlflow/models/movie_predictor/promote-to-production" \
     -H "Content-Type: application/json" \
     -d '{
       "version": "1",
       "description": "성능 검증 완료 후 프로덕션 승격"
     }'
```

### ✅ 핵심 확인 포인트
- ✅ MLflow UI에서 실험 및 모델 확인 가능
- ✅ 모델 버전 관리 정상 동작
- ✅ 스테이지 전환 (Staging → Production) 성공
- ✅ 모델 메트릭 및 파라미터 추적 정상

---

## 🏡 7아키텍처: 입주 및 생활 인프라 구축 (PyTorch)

### 🏗️ 집 짓기 비유
**"실제 거주할 수 있도록 전기, 가스, 인터넷 등 생활 인프라 연결"**

ML 프레임워크는 집의 생활 인프라와 같습니다. 구조는 완성되었지만 
실제로 사람이 살려면 전기, 가스, 인터넷 등이 연결되어야 하듯이, 
모델도 실제 서비스에서 사용하려면 추론 인프라가 구축되어야 합니다.

### 📚 개념 설명

**ML 프레임워크란?**
- 머신러닝 모델을 개발하고 배포하기 위한 소프트웨어 라이브러리
- 모델 정의, 훈련, 추론을 위한 고수준 API 제공
- GPU 가속, 분산 처리 등 성능 최적화 기능

**PyTorch란?**
- Meta(Facebook)에서 개발한 딥러닝 프레임워크
- 동적 계산 그래프로 직관적인 모델 개발 가능
- 연구와 프로덕션 모두에서 널리 사용

### 🔧 실행 방법

#### PyTorch 모델 서버 실행
```bash
# PyTorch API 서버 시작
docker compose -f docker/docker-compose.pytorch.yml up -d

# 또는 개발 모드로 실행
docker exec -it movie-mlops-pytorch-api bash
cd /app
python src/models/pytorch/training.py
```

### 🎯 PyTorch 사용 방법

#### 1. PyTorch 모델 훈련
```python
# 고도화된 PyTorch 모델 훈련
docker exec -it movie-mlops-pytorch-api python3 -c """
import torch
import torch.nn as nn
import torch.optim as optim
from src.models.pytorch.movie_recommender import create_model, count_parameters
from src.models.pytorch.data_loader import get_data_loaders
import numpy as np

# 모델 설정
config = {
    'num_users': 100,
    'num_movies': 1000,
    'embedding_dim': 64,
    'hidden_dims': [128, 64, 32],
    'dropout_rate': 0.3
}

# 모델 생성
model = create_model('neural_cf', config)
print(f'모델 파라미터 수: {count_parameters(model):,}')

# 옵티마이저 및 손실 함수
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# 가상 데이터로 훈련 데모
print('훈련 시작...')
model.train()

for epoch in range(3):
    # 가상 배치 데이터
    user_ids = torch.randint(0, config['num_users'], (32,))
    movie_ids = torch.randint(0, config['num_movies'], (32,))
    ratings = torch.randn(32) * 2 + 3  # 1-5 범위 가상 평점
    
    # 순전파
    predictions = model(user_ids, movie_ids)
    loss = criterion(predictions, ratings)
    
    # 역전파
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')

print('훈련 완료!')
"""
```

#### 2. 모델 추론 API 테스트
```bash
# 개별 예측 요청
curl -X POST "http://localhost:8001/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "user_id": 1,
       "movie_ids": [1, 2, 3, 4, 5]
     }'

# 사용자별 영화 추천
curl -X POST "http://localhost:8001/recommend" \
     -H "Content-Type: application/json" \
     -d '{
       "user_id": 1,
       "k": 10,
       "exclude_seen": true
     }'

# 유사 영화 추천
curl -X POST "http://localhost:8001/similar" \
     -H "Content-Type: application/json" \
     -d '{
       "movie_id": 123,
       "k": 5
     }'
```

#### 3. Legacy vs PyTorch 모델 성능 비교
```bash
# Legacy NumPy 모델 추천
echo "=== Legacy NumPy 모델 ==="
time curl -X GET "http://localhost:8000/?k=10"

# 개선된 API 추천
echo "=== 개선된 API ==="
time curl -X GET "http://localhost:8000/api/v1/recommendations?k=10"

# PyTorch 모델 추천
echo "=== PyTorch 모델 ==="
time curl -X POST "http://localhost:8001/recommend" \
     -H "Content-Type: application/json" \
     -d '{"user_id": 1, "k": 10}'
```

### ✅ 핵심 확인 포인트
- ✅ PyTorch 모델 정상 로드 및 초기화
- ✅ 추론 API 정상 응답
- ✅ 배치 예측 처리 가능
- ✅ GPU 사용 (가능한 경우) 또는 CPU 최적화

---

## 🛡️ 8아키텍처: 관리사무소 및 보안 시스템 (Prometheus + Grafana)

### 🏗️ 집 짓기 비유
**"24시간 관리사무소와 CCTV, 화재감지기 등 모니터링 시스템 구축"**

모니터링 시스템은 아파트 관리사무소와 같습니다. 24시간 건물 상태를 
감시하고, 문제 발생 시 즉시 알림을 보내며, 정기적인 점검을 통해 
안전하고 쾌적한 환경을 유지합니다.

### 📚 개념 설명

**모니터링이란?**
- 시스템의 상태, 성능, 동작을 지속적으로 관찰하고 기록
- 이상 상황 감지 및 알림
- 성능 분석 및 최적화를 위한 데이터 수집

**Prometheus란?**
- 오픈소스 모니터링 및 알림 시스템
- 시계열 데이터베이스 기반 메트릭 수집
- PromQL을 통한 강력한 쿼리 기능

**Grafana란?**
- 오픈소스 데이터 시각화 플랫폼
- 다양한 데이터 소스 지원
- 대시보드를 통한 실시간 모니터링

### 🔧 실행 방법

#### 모니터링 스택 실행
```bash
# 모니터링 스택 개별 실행
docker compose -f docker/docker-compose.monitoring.yml up -d

# 통합 스크립트 사용
./run_movie_mlops.sh
# 메뉴에서 7번 선택 (모니터링 스택)
```

### 🎯 Prometheus & Grafana 사용 방법

#### 1. Prometheus 접속 및 메트릭 확인
```bash
# Prometheus 웹 UI 접속
open http://localhost:9090

# 타겟 상태 확인
# Status > Targets 메뉴에서 각 서비스의 메트릭 수집 상태 확인
```

#### 2. 주요 메트릭 쿼리
```promql
# CPU 사용률
system_cpu_usage_percent

# HTTP 요청 수 (1분간)
rate(http_requests_total[1m])

# 모델 예측 응답 시간 (95퍼센타일)
histogram_quantile(0.95, rate(model_prediction_duration_seconds_bucket[1m]))

# 에러율 (5분간)
rate(http_requests_total{status=~"5.."}[5m]) / 
rate(http_requests_total[5m])

# 활성 데이터베이스 연결 수
database_connections_active
```

#### 3. Grafana 대시보드 설정
```bash
# Grafana 웹 UI 접속
open http://localhost:3000
# 로그인: admin / admin123

# 사전 구성된 대시보드 임포트
# 1. + 아이콘 > Import 클릭
# 2. Upload JSON file 선택
# 3. docker/configs/grafana/dashboards/mlops-overview.json 업로드
```

#### 4. 메트릭 수집 테스트
```bash
# 인위적으로 사용자 활동 생성
for i in {1..20}; do
  curl -X GET "http://localhost:8000/?k=5"
  curl -X GET "http://localhost:8000/api/v1/recommendations?k=3"
  sleep 1
done

# 메트릭 엔드포인트 직접 확인
curl http://localhost:8000/metrics | grep -E "(http_requests|model_predictions)"

# Prometheus에서 메트릭 업데이트 확인
# Graph 탭에서 위의 쿼리들 실행
```

### 🔍 핵심 모니터링 영역

#### 시스템 메트릭
- CPU, 메모리, 디스크 사용률
- 네트워크 I/O
- 컨테이너 리소스 사용량

#### 애플리케이션 메트릭
- API 응답 시간 및 처리량
- 에러율 및 상태 코드 분포
- 데이터베이스 연결 및 쿼리 성능

#### ML 특화 메트릭
- 모델 예측 수 및 지연시간
- 모델 정확도 및 성능 지표
- 피처 서빙 응답시간

#### 비즈니스 메트릭
- 사용자 세션 수
- 추천 클릭률
- 사용자 만족도 지표

### ✅ 핵심 확인 포인트
- ✅ Prometheus에서 모든 타겟 정상 수집
- ✅ Grafana 대시보드 정상 표시
- ✅ 알림 규칙 정상 동작
- ✅ 메트릭 데이터 시계열 정상 기록

---

## 🤖 9아키텍처: 스마트홈 자동화 시스템 (Apache Kafka)

### 🏗️ 집 짓기 비유
**"IoT 센서와 AI로 모든 것이 자동으로 반응하는 완전 스마트홈 완성"**

이벤트 기반 시스템은 스마트홈과 같습니다. 센서가 변화를 감지하면 
자동으로 관련 시스템들이 반응하여 최적의 환경을 유지합니다. 
사람이 직접 조작하지 않아도 시스템이 스스로 판단하고 대응합니다.

### 📚 개념 설명

**이벤트 기반 아키텍처란?**
- 시스템 구성 요소들이 이벤트를 통해 통신하고 자동으로 반응
- 느슨한 결합으로 확장성과 유연성 확보
- 실시간 데이터 처리 및 반응형 시스템 구축

**Apache Kafka란?**
- 분산 이벤트 스트리밍 플랫폼
- 높은 처리량과 낮은 지연시간
- 내구성 있는 메시지 저장 및 재처리 가능

### 🔧 실행 방법

#### Kafka 스택 실행
```bash
# Kafka 클러스터 시작
docker compose -f docker/docker-compose.kafka.yml up -d

# Kafka UI 접속
open http://localhost:8082
```

### 🎯 Kafka 사용 방법

#### 1. 토픽 생성 및 관리
```bash
# Kafka 컨테이너 접속
docker exec -it movie-mlops-kafka bash

# 주요 토픽 생성
kafka-topics --create --topic movie-recommendations \
             --bootstrap-server localhost:9092 \
             --partitions 3 --replication-factor 1

kafka-topics --create --topic user-events \
             --bootstrap-server localhost:9092 \
             --partitions 3 --replication-factor 1

kafka-topics --create --topic model-drift-alerts \
             --bootstrap-server localhost:9092 \
             --partitions 1 --replication-factor 1

kafka-topics --create --topic system-health \
             --bootstrap-server localhost:9092 \
             --partitions 2 --replication-factor 1

# 토픽 목록 확인
kafka-topics --list --bootstrap-server localhost:9092
```

#### 2. 이벤트 프로듀서 테스트
```python
# Python을 통한 이벤트 발생
docker exec -it movie-mlops-api python3 -c """
import json
import time
from datetime import datetime
from src.events.kafka_producer import MovieEventProducer
from src.events.event_schemas import (
    UserInteractionEvent, 
    ModelDriftEvent, 
    SystemHealthEvent
)

producer = MovieEventProducer()

# 1. 사용자 상호작용 이벤트
print('사용자 상호작용 이벤트 발생...')
for i in range(5):
    event = UserInteractionEvent(
        user_id=f'user_{i+1:03d}',
        movie_id=f'movie_{(i*10+1):03d}',
        interaction_type='click',
        timestamp=datetime.now().isoformat(),
        rating=4.0 + (i % 3) * 0.5,
        session_id=f'session_{i+1}'
    )
    producer.send_user_interaction(event)
    time.sleep(0.5)

# 2. 모델 드리프트 이벤트
print('모델 드리프트 이벤트 발생...')
drift_event = ModelDriftEvent(
    model_name='movie_predictor',
    model_version='1.0.0',
    drift_score=0.75,
    threshold=0.7,
    timestamp=datetime.now().isoformat(),
    metrics={'accuracy_drop': 0.05, 'feature_drift': 0.3}
)
producer.send_model_drift(drift_event)

# 3. 시스템 헬스 이벤트
print('시스템 헬스 이벤트 발생...')
health_event = SystemHealthEvent(
    service_name='movie-recommendation-api',
    status='degraded',
    cpu_usage=85.5,
    memory_usage=78.2,
    response_time_ms=1200,
    timestamp=datetime.now().isoformat()
)
producer.send_system_health(health_event)

print('모든 이벤트 발송 완료!')
"""
```

#### 3. 이벤트 컨슈머 테스트
```python
# 이벤트 수신 및 처리
docker exec -it movie-mlops-api python3 -c """
import time
import threading
from src.events.kafka_consumer import MovieEventConsumer

# 컨슈머 생성
consumer = MovieEventConsumer()

def start_consumer():
    print('이벤트 컨슈머 시작...')
    consumer.start_consuming()

# 백그라운드에서 컨슈머 시작
consumer_thread = threading.Thread(target=start_consumer, daemon=True)
consumer_thread.start()

# 10초간 이벤트 처리
print('10초간 이벤트 처리 중...')
time.sleep(10)

print('이벤트 처리 완료!')
"""
```

#### 4. 커맨드라인 도구를 통한 확인
```bash
# 특정 토픽의 메시지 실시간 확인
kafka-console-consumer --topic user-events \
                       --bootstrap-server localhost:9092 \
                       --from-beginning

# 다른 터미널에서 다른 토픽 확인
kafka-console-consumer --topic model-drift-alerts \
                       --bootstrap-server localhost:9092 \
                       --from-beginning
```

### 🔄 이벤트 기반 자동화 시나리오

#### 1. 모델 드리프트 감지 → 자동 재훈련
```bash
# 모델 드리프트 이벤트 시뮬레이션
curl -X POST "http://localhost:8000/api/v1/trigger/model-drift" \
     -H "Content-Type: application/json" \
     -d '{
       "model_name": "movie_predictor",
       "drift_score": 0.85,
       "threshold": 0.7
     }'

# Airflow UI에서 자동 트리거된 재훈련 DAG 확인
open http://localhost:8080
```

#### 2. 시스템 부하 감지 → 자동 스케일링 알림
```bash
# 시스템 부하 이벤트 시뮬레이션
curl -X POST "http://localhost:8000/api/v1/trigger/system-overload" \
     -H "Content-Type: application/json" \
     -d '{
       "service_name": "movie-api",
       "cpu_usage": 95.0,
       "memory_usage": 88.5
     }'
```

#### 3. 사용자 행동 분석 → 실시간 개인화
```bash
# 대량 사용자 이벤트 생성
for i in {1..50}; do
  curl -X POST "http://localhost:8000/api/v1/events/user-interaction" \
       -H "Content-Type: application/json" \
       -d "{
         \"user_id\": \"user_$(($i % 10 + 1))\",
         \"movie_id\": \"movie_$((RANDOM % 100 + 1))\",
         \"interaction_type\": \"view\",
         \"rating\": $((RANDOM % 5 + 1))
       }"
  sleep 0.1
done
```

### ✅ 핵심 확인 포인트
- ✅ Kafka 클러스터 정상 실행
- ✅ 토픽 생성 및 메시지 송수신 정상
- ✅ 이벤트 기반 자동화 트리거 동작
- ✅ Kafka UI에서 메시지 플로우 시각화

---

## 🧪 통합 테스트 및 E2E 시나리오

### 전체 파이프라인 테스트
```bash
# 1. 전체 시스템 시작
./run_movie_mlops.sh
# 메뉴에서 2번 선택 (모든 스택 시작)

# 2. 서비스 상태 확인
./run_movie_mlops.sh
# 메뉴에서 11번 선택 (서비스 상태 확인)

# 3. E2E 테스트 실행
./run_movie_mlops.sh
# 메뉴에서 8번 선택 (전체 시스템 테스트)
```

### 실제 사용자 시나리오 테스트
```bash
# 1. 새 사용자 영화 추천 요청
echo "=== 1. 사용자 추천 요청 ==="
curl -X GET "http://localhost:8000/api/v1/recommendations?k=10&user_id=test_user_001"

# 2. 사용자 피드백 수집
echo "=== 2. 사용자 피드백 수집 ==="
curl -X POST "http://localhost:8000/api/v1/feedback" \
     -H "Content-Type: application/json" \
     -d '{
       "user_id": "test_user_001",
       "movie_id": "123",
       "rating": 4.5,
       "interaction_type": "like"
     }'

# 3. 시스템 메트릭 확인
echo "=== 3. 시스템 메트릭 확인 ==="
curl -s http://localhost:8000/metrics | grep -E "(recommendation|prediction|user)"

# 4. 모델 성능 대시보드 확인
echo "=== 4. 모니터링 대시보드 ==="
echo "Grafana: http://localhost:3000/d/mlops-overview"
echo "Prometheus: http://localhost:9090/graph"
```

---

## 🎯 각 아키텍처별 성공 기준

| 아키텍처 | 집 짓기 비유 | 성공 기준 | 확인 방법 |
|---------|-------------|-----------|----------|
| **1아키텍처** | 기초 & 배관 | TMDB 데이터 수집 완료 | `ls data/raw/tmdb/popular.json` |
| **2아키텍처** | 자재 창고 | 피처 서빙 정상 동작 | Feast UI에서 피처 조회 성공 |
| **3아키텍처** | 설계도면 관리소 | Git 워크플로우 정상 | GitHub Actions 성공 표시 |
| **4아키텍처** | 자동화 장비 | CI/CD 파이프라인 통과 | 모든 테스트 스위트 성공 |
| **5아키텍처** | 공사 관리 시스템 | 모델 훈련 파이프라인 완료 | Airflow DAG 모든 태스크 성공 |
| **6아키텍처** | 품질 검사소 | 모델 레지스트리 등록 | MLflow UI에서 모델 확인 |
| **7아키텍처** | 생활 인프라 | PyTorch 추론 성공 | 추천 API 정상 응답 |
| **8아키텍처** | 관리사무소 & 보안 | 모니터링 메트릭 수집 | Grafana 대시보드 데이터 표시 |
| **9아키텍처** | 스마트홈 자동화 | 이벤트 처리 정상 | Kafka UI에서 메시지 확인 |

---

## 🏠 완성된 MLOps 하우스 최종 점검

### 전체 아키텍처 연결 확인
```bash
# 모든 서비스 상태 한 번에 확인
echo "=== MLOps 하우스 최종 점검 ==="

echo "🏗️ 1. 기초 & 배관 (Airflow)"
curl -s http://localhost:8080/health || echo "❌ Airflow 연결 실패"

echo "📦 2. 자재 창고 (Feast)"
curl -s http://localhost:6566/health || echo "❌ Feast 연결 실패"

echo "📋 3. 설계도면 관리소 (Git)"
git status && echo "✅ Git 정상" || echo "❌ Git 상태 확인 실패"

echo "🏗️ 4. 자동화 장비 (GitHub Actions)"
echo "GitHub Actions 상태는 웹에서 확인: https://github.com/your-repo/actions"

echo "👷‍♂️ 5. 공사 관리 시스템 (Airflow 워크플로우)"
curl -s http://localhost:8080/api/v1/dags -u admin:admin | grep -q "movie_training_pipeline" && echo "✅ 훈련 파이프라인 등록" || echo "❌ 파이프라인 미등록"

echo "🏅 6. 품질 검사소 (MLflow)"
curl -s http://localhost:5000/health || echo "❌ MLflow 연결 실패"

echo "🏡 7. 생활 인프라 (PyTorch)"
curl -s http://localhost:8001/health || echo "❌ PyTorch API 연결 실패"

echo "🛡️ 8. 관리사무소 & 보안 (Monitoring)"
curl -s http://localhost:9090/-/healthy && curl -s http://localhost:3000/api/health && echo "✅ 모니터링 정상" || echo "❌ 모니터링 연결 실패"

echo "🤖 9. 스마트홈 자동화 (Kafka)"
docker exec movie-mlops-kafka kafka-topics --list --bootstrap-server localhost:9092 | grep -q "user-events" && echo "✅ Kafka 정상" || echo "❌ Kafka 연결 실패"

echo ""
echo "🎉 MLOps 하우스 건설 완료!"
echo "이제 완전 자동화된 스마트한 ML 시스템에서 생활할 수 있습니다!"
```

---

## 📚 결론 및 다음 단계

### 🎯 학습 성과
이 가이드를 통해 다음과 같은 MLOps 핵심 개념들을 실습했습니다:

1. **데이터 파이프라인** - 자동화된 데이터 수집과 처리
2. **피처 관리** - 재사용 가능한 피처 스토어 구축
3. **버전 관리** - 코드와 모델의 체계적 관리
4. **자동화** - CI/CD를 통한 개발 효율성 향상
5. **워크플로우 관리** - 복잡한 ML 파이프라인 오케스트레이션
6. **모델 거버넌스** - 모델 품질과 배포 관리
7. **ML 프레임워크** - 고성능 모델 개발과 서빙
8. **모니터링** - 시스템과 모델 성능 관찰
9. **이벤트 기반 자동화** - 완전 자율적인 시스템 구축

### 🚀 다음 단계 제안

#### 심화 학습
- A/B 테스트를 통한 모델 성능 비교
- 실시간 스트리밍 데이터 처리 확장
- 멀티 모델 서빙 및 앙상블 구축
- 보안 및 프라이버시 강화

#### 프로덕션 적용
- 클라우드 환경으로 마이그레이션
- 쿠버네티스 기반 스케일링
- 모니터링 알림 시스템 구축
- 재해 복구 계획 수립

### 💡 핵심 메시지

**"집을 짓듯이 MLOps도 차근차근 단계별로 쌓아 올리면, 견고하고 살기 좋은 ML 시스템이 완성됩니다!"**

각 아키텍처는 이전 아키텍처의 기반 위에 구축되며, 모든 9아키텍처가 완성되면 
완전 자동화된 지능형 ML 생태계가 탄생합니다. 🏠✨

---

*"좋은 집을 짓듯이, 좋은 MLOps를 만들어보세요!"* 🎬🚀
