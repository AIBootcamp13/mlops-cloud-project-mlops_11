# 5단계: 워크플로우 오케스트레이션 - 상세 구현 가이드

## 📋 단계 개요

**목표**: 복잡한 ML 워크플로우를 자동화하고 의존성을 관리하여 안정적 실행 보장

**핵심 가치**: 데이터 파이프라인부터 모델 배포까지 전체 ML 생명주기의 체계적 관리

---

## 🎯 5.1 Apache Airflow 설치 및 설정

### 목표
MLOps 파이프라인을 위한 견고한 Airflow 환경 구축

### 상세 구현 사항

#### **5.1.1 Airflow 설치 및 초기 설정**
- **Docker Compose 기반 설치**
  ```yaml
  # docker-compose.airflow.yml
  version: '3.8'
  
  x-airflow-common:
    &airflow-common
    image: apache/airflow:2.8.1-python3.11
    environment: &airflow-common-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    user: "${AIRFLOW_UID:-50000}:0"
    depends_on: &airflow-common-depends-on
      postgres:
        condition: service_healthy
  
  services:
    postgres:
      image: postgres:15
      environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow
      volumes:
        - postgres-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "airflow"]
        interval: 10s
        retries: 5
        start_period: 5s
    
    airflow-webserver:
      <<: *airflow-common
      command: webserver
      ports:
        - "8080:8080"
      healthcheck:
        test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
        interval: 30s
        timeout: 10s
        retries: 5
        start_period: 30s
    
    airflow-scheduler:
      <<: *airflow-common
      command: scheduler
      healthcheck:
        test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
        interval: 30s
        timeout: 10s
        retries: 5
        start_period: 30s
  
  volumes:
    postgres-db-volume:
  ```

#### **5.1.2 Airflow 설정 최적화**
- **airflow.cfg 주요 설정**
  ```ini
  # airflow.cfg
  [core]
  dags_folder = /opt/airflow/dags
  base_log_folder = /opt/airflow/logs
  logging_level = INFO
  executor = LocalExecutor
  parallelism = 32
  max_active_tasks_per_dag = 16
  max_active_runs_per_dag = 16
  
  [scheduler]
  dag_dir_list_interval = 300
  child_process_timeout = 600
  catchup_by_default = False
  max_tis_per_query = 512
  
  [webserver]
  web_server_port = 8080
  web_server_host = 0.0.0.0
  secret_key = your-secret-key-here
  authenticate = True
  auth_backend = airflow.contrib.auth.backends.password_auth
  
  [email]
  email_backend = airflow.providers.sendgrid.hooks.sendgrid.SendGridHook
  
  [logging]
  remote_logging = True
  remote_base_log_folder = s3://your-bucket/airflow-logs
  ```

이 5단계를 완료하면 복잡한 ML 워크플로우를 안정적으로 자동화하고 관리할 수 있는 견고한 오케스트레이션 시스템이 구축됩니다.
