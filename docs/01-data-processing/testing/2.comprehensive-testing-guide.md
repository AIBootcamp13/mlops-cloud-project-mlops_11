---
title: "1단계 데이터 처리 종합 테스트 가이드 - Docker 기반"
description: "1단계 데이터 처리 시스템의 모든 구성 요소를 Docker 환경에서 종합적으로 테스트"
stage: "01-data-processing"
phase: "testing"
category: "comprehensive-testing"
difficulty: "intermediate"
estimated_time: "8-12 hours"
tags:
  - comprehensive-testing
  - docker-testing
  - integration-testing
  - system-validation
  - end-to-end-testing
  - troubleshooting
authors:
  - mlops-team
last_updated: "2025-06-06"
version: "1.0"
status: "active"
prerequisites:
  - "1.1-1.8 단계 구현 완룄"
  - "Docker 및 Docker Compose"
  - "TMDB API 키"
outcomes:
  - "전체 시스템 통합 테스트 완료"
  - "모든 구성 요소 정상 작동 확인"
  - "성능 및 안정성 검증"
  - "문제 해결 가이드 제공"
related_docs:
  - "../1.data-processing-implementation-guide.md"
  - "../implementation/"
  - "../../02-feature-store/"
testing_scope:
  - "1.1 데이터 소스 연결"
  - "1.2 데이터 크롤러"
  - "1.3 스케줄링"
  - "1.4 데이터 저장소"
  - "1.5 품질 검증"
  - "1.7 로깅 시스템"
  - "1.8 Apache Airflow"
---

# 1단계 데이터 처리 종합 테스트 가이드 - Docker 기반

## 📋 개요

이 가이드는 1단계 데이터 처리 시스템의 모든 구성 요소를 Docker 환경에서 종합적으로 테스트하는 방법을 제공합니다.

**테스트 범위**: 1.1 ~ 1.8 모든 하위 단계
**환경**: WSL Ubuntu 24.04 + Docker + Python 3.11
**전제 조건**: TMDB API 키 필요

---

## 🎯 테스트 준비

### 1. Docker 환경 확인

```

#### 🚨 스케줄러 오류 해결 가이드

**일반적인 오류 및 해결책**:

##### **1. AttributeError: 'Job' object has no attribute 'month'**
##### **5. 성공적인 스케줄러 설정 예상 결과**
```
✅ TMDBDataScheduler 초기화 성공
[2025-06-05 02:31:05,186] INFO tmdb_scheduler | 스케줄 작업 설정 중...
[2025-06-05 02:31:05,187] INFO tmdb_scheduler | 총 5개 작업이 스케줄되었습니다.
✅ 스케줄 작업 설정 완료: 0개 작업
등록된 작업 수: 5개
1. Every 1 day at 02:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 02:00:00)
2. Every 1 week do _safe_job_wrapper() (last run: [never], next run: 2025-06-08 03:00:00)
3. Every 1 hour do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 12:00:00)
4. Every 1 day at 04:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 04:00:00)
5. Every 10 minutes do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 02:41:05)
```

**스케줄된 작업 설명**:
- **작업 1**: 일일 수집 (매일 새벽 2시)
- **작업 2**: 주간 수집 (매주 일요일 새벽 3시)
- **작업 3**: 시간별 트렌딩 (매시간 정각, 운영시간 8-22시)
- **작업 4**: 월간 체크 (매일 새벽 4시, 매월 1일에만 실행)
- **작업 5**: 헬스체크 (매 10분마다)

---
# 증상
AttributeError: 'Job' object has no attribute 'month'

# 원인: schedule 라이브러리가 월간 스케줄링을 직접 지원하지 않음
# 해결: 이미 수정됨 (매일 체크 후 월 1일에만 실행하는 방식)
```

##### **2. ModuleNotFoundError 오류**
```bash
# schedule 라이브러리 설치 확인
docker exec mlops-dev pip list | grep schedule

# 설치되지 않은 경우
docker exec mlops-dev pip install schedule
```

##### **3. 스케줄 작업이 등록되지 않는 경우**
```bash
# 스케줄 상태 초기화 후 재시도
docker exec mlops-dev python -c "
import schedule
schedule.clear()  # 기존 작업 모두 제거
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
scheduler.setup_jobs()
print(f'재설정 완료: {len(schedule.jobs)}개 작업')
"
```

##### **4. 월간 스케줄링 이해**
**수정 전** (오류 발생):
```python
schedule.every().month.do(...)  # 지원되지 않는 메서드
```

**수정 후** (정상 작동):
```python
# 매일 새벽 4시에 체크
schedule.every().day.at("04:00").do(self._safe_job_wrapper, self._monthly_check, "monthly_check")

# _monthly_check() 메서드에서 매월 1일에만 실제 실행
def _monthly_check(self):
    if datetime.now().day == 1:  # 매월 1일에만
        return self.monthly_full_refresh()
    return None
```

##### **5. 성공적인 스케줄러 설정 예상 결과**
```
✅ TMDBDataScheduler 초기화 성공
[2025-06-05 11:31:05,186] INFO tmdb_scheduler | 스케줄 작업 설정 중...
[2025-06-05 11:31:05,187] INFO tmdb_scheduler | 총 5개 작업이 스케줄되었습니다.
✅ 스케줄 작업 설정 완료: 0개 작업
등록된 작업 수: 5개
1. Every 1 day at 02:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 02:00:00)
2. Every 1 week do _safe_job_wrapper() (last run: [never], next run: 2025-06-08 03:00:00)
3. Every 1 hour do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 12:00:00)
4. Every 1 day at 04:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 04:00:00)
5. Every 10 minutes do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 11:41:05)
```

**스케줄된 작업 설명**:
- **작업 1**: 일일 수집 (매일 새벽 2시)
- **작업 2**: 주간 수집 (매주 일요일 새벽 3시)
- **작업 3**: 시간별 트렌딩 (매시간 정각, 운영시간 8-22시)
- **작업 4**: 월간 체크 (매일 새벽 4시, 매월 1일에만 실행)
- **작업 5**: 헬스체크 (매 10분마다)

---

### 1. Docker 환경 확인

```bash
# Docker 상태 확인
docker --version
docker compose --version

# 프로젝트 디렉토리로 이동
cd /mnt/c/dev/movie-mlops

# Docker 컨테이너 재빌드 (jq와 tree는 Dockerfile에 이미 포함되어 있음)
docker compose down
docker compose build dev
docker compose up -d dev

# 컨테이너 상태 확인
docker compose ps

# jq 및 tree 설치 확인 (이미 Dockerfile에 포함되어 있음)
docker exec mlops-dev jq --version
docker exec mlops-dev tree --version
```

**참고**: `jq`와 `tree`는 이미 Dockerfile.dev에 포함되어 자동으로 설치됩니다. 만약 `command not found` 오류가 발생하면 다음 명령어로 컨테이너를 재빌드하세요:
```bash
docker compose down
docker compose build dev --no-cache
docker compose up -d dev
```

### 2. 환경변수 설정 확인 및 문제 해결

```bash
# .env 파일 존재 확인
docker exec mlops-dev ls -la .env

# .env 파일 내용 확인 (API 키 포함)
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"

# Docker 컨테이너 환경변수 확인
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"

# 환경변수 로딩 테스트
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv
print('로드 전 API 키:', os.getenv('TMDB_API_KEY'))
load_dotenv(override=True)  # 강제 덮어쓰기
print('로드 후 API 키:', os.getenv('TMDB_API_KEY'))
"
```

**중요 문제 해결 가이드**:

#### 🚨 API 키 환경변수 로딩 문제

**증상**: .env 파일에는 실제 API 키가 있지만, Docker 컨테이너에서는 `your_tmdb_api_key_here`가 사용됨

```bash
# 문제 증상 확인
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"    # 실제 API 키
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"             # your_tmdb_api_key_here

# 즐시 해결: 자동 해결 스크립트 실행
chmod +x scripts/fix-env-vars.sh
./scripts/fix-env-vars.sh
```

**수동 해결 방법**:

```bash
# 해결 방법 1: Docker 컨테이너 재시작 (가장 간단)
docker compose down
docker compose up -d dev

# 해결 방법 2: 환경변수 제거 후 테스트
docker exec mlops-dev bash -c "
unset TMDB_API_KEY
cd /app
python src/data_processing/test_integration.py
"

# 해결 방법 3: 강제 환경변수 설정
API_KEY=$(docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY | cut -d'=' -f2")
docker exec -e TMDB_API_KEY="$API_KEY" mlops-dev python src/data_processing/test_integration.py
```

#### 📝 .env 파일 설정 방법

```bash
# 1. .env 파일이 없는 경우 템플릿에서 복사
docker exec mlops-dev bash -c "
if [ ! -f .env ]; then
    cp .env.template .env
    echo '.env 파일이 생성되었습니다. TMDB_API_KEY를 설정하세요.'
fi
"

# 2. API 키 설정 (실제 키로 교체 필요)
docker exec mlops-dev bash -c "
sed -i 's/your_tmdb_api_key_here/실제_TMDB_API_키/' .env
echo 'API 키가 설정되었습니다.'
"

# 3. 설정 확인
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"
```

#### 🔥 강력한 문제 해결 (상급)

**모든 방법이 실패한 경우 사용:**

```bash
# 방법 1: 컨테이너 내부에서 환경변수 직접 수정
docker exec mlops-dev bash -c "
# 기존 환경변수 제거
unset TMDB_API_KEY
unset DB_PASSWORD

# .env 파일에서 API 키 추출 및 설정
API_KEY=\$(grep '^TMDB_API_KEY=' .env | cut -d'=' -f2 | tr -d ' ')

if [ -n '\$API_KEY' ] && [ '\$API_KEY' != 'your_tmdb_api_key_here' ]; then
    export TMDB_API_KEY=\$API_KEY
    echo '✅ API 키 설정 완료:' \$TMDB_API_KEY
else
    echo '❌ .env 파일에 올바른 API 키가 없습니다.'
fi

# 테스트 실행
cd /app
python src/data_processing/test_integration.py
"

# 방법 2: Docker Compose 환경변수 강제 설정
API_KEY=$(grep '^TMDB_API_KEY=' .env | cut -d'=' -f2 | tr -d ' ')
docker exec -e TMDB_API_KEY="$API_KEY" mlops-dev python src/data_processing/test_integration.py

# 방법 3: Python 내부에서 환경변수 강제 설정
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv

# 플레이스홀더 값 제거
if 'your_' in os.getenv('TMDB_API_KEY', '').lower():
    os.environ.pop('TMDB_API_KEY', None)

# .env 파일에서 강제 로드
load_dotenv(override=True)

api_key = os.getenv('TMDB_API_KEY')
print(f'API 키 로드 결과: {api_key[:8] if api_key else "None"}...')

# API 테스트
from src.data_processing.tmdb_api_connector import test_tmdb_connection
result = test_tmdb_connection()
print(f'테스트 결과: {"✅ 성공" if result else "❌ 실패"}')
"
```

### 3. 디렉토리 구조 확인

```bash
# 필수 디렉토리 구조 생성
docker exec mlops-dev bash -c "
mkdir -p data/{raw,processed,backup,test,staging}
mkdir -p data/raw/movies/{daily,weekly,monthly,genre,trending}
mkdir -p logs/{app,data,error,performance,health}
mkdir -p reports
echo '디렉토리 구조 생성 완료'
"
```

---

## 🧪 1.1 데이터 소스 연결 테스트

### 통합 테스트 실행

```bash
# 1.1 단계 통합 테스트 (방법 2: bash로 들어가서 실행)
docker exec -it mlops-dev bash
# 컨테이너 내부에서:
cd /app
python src/data_processing/test_integration.py
```

**참고**: Python 대화형 모드(`docker exec -it mlops-dev python`)로 들어간 후 스크립트 파일명을 입력하는 것은 올바른 방법이 아닙니다. 반드시 위의 방법을 사용하세요.

**예상 결과**:
```
============================================================
TMDB API 연동 1.1 단계 통합 테스트
============================================================

1. 환경변수 설정 테스트...
   결과: ✅ 성공

2. Rate Limiter 테스트...
   결과: ✅ 성공

3. 응답 파싱 테스트...
   결과: ✅ 성공

4. API 연결 테스트...
   결과: ✅ 성공

5. 통합 테스트...
   결과: ✅ 성공

전체 결과: 5/5 통과 (100.0%)
테스트 보고서 저장됨: /app/reports/tmdb_test_report_20250605_020746.json

권장사항:
1. 모든 기본 테스트가 통과했습니다. 이제 실제 데이터 수집을 시작할 수 있습니다.

테스트 완료!
```

**🎉 성공 시 다음 단계**:
```bash
# 컨테이너에서 나가기 (컨테이너 내부에 있는 경우)
exit

# 호스트에서 jq로 결과 확인
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== 최신 테스트 결과 ==='
    cat \"\$latest_report\" | jq '.summary'
    
    echo -e '\n=== 권장사항 ==='
    cat \"\$latest_report\" | jq '.recommendations[]?'
fi
"

# 1.2단계 크롤러 테스트로 진행
docker exec -it mlops-dev python src/data_processing/test_crawler.py
```

### 개별 컴포넌트 테스트

```bash
# API 연결 단독 테스트
docker exec mlops-dev python -c "
from src.data_processing.tmdb_api_connector import test_tmdb_connection
if test_tmdb_connection():
    print('✅ API 연결 성공')
else:
    print('❌ API 연결 실패')
"

# Rate Limiter 테스트
docker exec mlops-dev python -c "
from src.data_processing.rate_limiter import RateLimiter, RateLimitConfig
limiter = RateLimiter(RateLimitConfig())
print('✅ Rate Limiter 로드 성공')
"

# 응답 파서 테스트
docker exec mlops-dev python -c "
from src.data_processing.response_parser import TMDBResponseParser
parser = TMDBResponseParser()
print('✅ Response Parser 로드 성공')
"
```

### 1.1 테스트 결과 확인

```bash
# 테스트 보고서 파일 목록 확인
docker exec mlops-dev ls -la reports/tmdb_test_report_*.json

# 최신 보고서 내용 확인 (jq 사용)
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== 최신 테스트 보고서 ==='
    cat \"\$latest_report\" | jq '.summary'
else
    echo '보고서를 찾을 수 없습니다.'
fi
"

# 또는 전체 보고서 내용 확인
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== 전체 테스트 보고서 ==='
    cat \"\$latest_report\" | jq '.'
fi
"

# 특정 필드만 추출 (예: 추천사항)
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== 추천사항 ==='
    cat \"\$latest_report\" | jq '.recommendations[]?'
fi
"

# 로그 파일 확인
docker exec mlops-dev tail -20 logs/test_tmdb_integration.log
```

**⚠️ 주의사항**: Docker 컨테이너 **내부**에서 `docker` 명령어를 실행하면 `docker: command not found` 오류가 발생합니다. 이는 정상적인 동작입니다.

**해결 방법**:
```bash
# 컨테이너에서 나가기
exit

# 호스트에서 jq 실행
docker exec mlops-dev bash -c "..."
```

**jq 명령어 설명**:
- `jq '.'`: 전체 JSON을 예쁘게 포맧팅
- `jq '.summary'`: summary 필드만 추출
- `jq '.recommendations[]?'`: recommendations 배열의 각 요소를 개별 출력
- `jq '.summary.success_rate'`: 중첩된 필드 접근

---

## 🕷️ 1.2 데이터 크롤러 테스트

### 크롤러 통합 테스트

```bash
# 1.2 단계 크롤러 테스트
docker exec -it mlops-dev python src/data_processing/test_crawler.py
```

**예상 결과**:
```
============================================================
TMDB 크롤러 1.2 단계 통합 테스트
============================================================

1. 기본 크롤러 테스트...
   결과: ✅ 성공

2. 대량 수집 테스트...
   결과: ✅ 성공

3. 장르별 수집 테스트...
   결과: ✅ 성공

4. 트렌딩 수집 테스트...
   결과: ✅ 성공

5. 평점 높은 영화 테스트...
   결과: ✅ 성공

6. 종합 수집 테스트...
   결과: ✅ 성공

7. 빠른 함수 테스트...
   결과: ✅ 성공

전체 결과: 7/7 통과 (100.0%)
```

### 개별 크롤러 기능 테스트

```bash
# TMDBCrawler 기본 기능 테스트
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()
print('✅ TMDBCrawler 초기화 성공')

# 인기 영화 3페이지 수집 테스트
movies = crawler.get_popular_movies_bulk(1, 3)
print(f'✅ 인기 영화 수집: {len(movies)}개')

# 데이터 검증 테스트
valid_movies = crawler.filter_valid_movies(movies)
print(f'✅ 검증 통과: {len(valid_movies)}개')

crawler.close()
"

# 장르별 수집 테스트
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()

# 액션 장르 영화 수집 (장르 ID: 28)
action_movies = crawler.get_movies_by_genre(28, 2)
print(f'✅ 액션 영화 수집: {len(action_movies)}개')

crawler.close()
"

# 트렌딩 영화 수집 테스트
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()

# 일간 트렌딩 수집
trending = crawler.get_trending_movies('day')
print(f'✅ 일간 트렌딩: {len(trending)}개')

crawler.close()
"
```

### 대량 수집 테스트

```bash
# 대량 데이터 수집 테스트 (소규모)
docker exec -it mlops-dev python src/data_processing/bulk_collection_test.py
```

**테스트 옵션 선택**:
```
테스트 시나리오를 선택하세요:
1. 소규모 테스트 (100개 영화, 5페이지)
2. 중간 규모 테스트 (500개 영화, 25페이지)
3. 대량 수집 테스트 (1000개 영화, 50페이지)

선택 (1-3, 기본값 1): 1
```

### 1.2 수집 결과 확인

```bash
# 수집된 파일 확인
docker exec mlops-dev find data/raw/movies -name "*.json" | head -10

# 최신 수집 파일 분석 (영화 데이터가 있는 파일 우선)
docker exec mlops-dev python -c "
import json
from pathlib import Path
from datetime import datetime

data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    
    # 영화 데이터가 있는 파일들만 필터링
    movie_files = []
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            movies = data.get('movies', [])
            if len(movies) > 0:
                movie_files.append({
                    'file': json_file,
                    'movie_count': len(movies),
                    'mtime': json_file.stat().st_mtime
                })
        except Exception:
            continue
    
    if movie_files:
        # 영화 데이터가 있는 파일 중 가장 최신 파일 선택
        latest_movie_file = max(movie_files, key=lambda x: x['mtime'])
        latest_file = latest_movie_file['file']
        
        print(f'최신 영화 데이터 파일: {latest_file.name}')
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'collection_info' in data:
            info = data['collection_info']
            print(f'수집 시간: {info.get(\"timestamp\")}')
            print(f'총 영화: {info.get(\"total_movies\")}개')
        
        movies = data.get('movies', [])
        print(f'실제 영화 데이터: {len(movies)}개')
        
        if movies:
            first_movie = movies[0]
            last_movie = movies[-1]
            print(f'첫 번째 영화: {first_movie.get(\"title\")} (평점: {first_movie.get(\"vote_average\")})')
            print(f'마지막 영화: {last_movie.get(\"title\")} (평점: {last_movie.get(\"vote_average\")})')
        
        # 전체 영화 데이터 현황 요약
        print(f'\\n=== 전체 수집 현황 ===')
        total_movies = sum(info['movie_count'] for info in movie_files)
        print(f'총 파일 수: {len(movie_files)}개')
        print(f'총 영화 수: {total_movies}개')
    else:
        print('❌ 영화 데이터가 있는 파일을 찾을 수 없습니다.')
else:
    print('❌ 데이터 디렉토리가 없습니다.')
"
```

---

## 📅 1.3 데이터 수집 스케줄링 테스트

### 스케줄러 기본 기능 테스트

```bash
# 수정된 스케줄러 테스트 (월간 오류 수정됨)
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
print('✅ TMDBDataScheduler 초기화 성공')

# 작업 설정 테스트
scheduler.setup_jobs()
print(f'✅ 스케줄 작업 설정 완료: {len(scheduler.job_history)}개 작업')

# 스케줄된 작업 목록 확인
import schedule
print(f'등록된 작업 수: {len(schedule.jobs)}개')
for i, job in enumerate(schedule.jobs):
    print(f'{i+1}. {job}')
"

# 개별 수집 작업 테스트
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
print('=== 일일 수집 테스트 시작 ===')

result = scheduler.daily_collection()
if result:
    print(f'✅ 일일 수집 성공: {result.get(\"total_valid\")}개 영화')
    print(f'품질률: {result.get(\"quality_rate\", 0):.1f}%')
else:
    print('❌ 일일 수집 실패')
"
```

### 스케줄러 상태 및 헬스체크

```bash
# 헬스체크 테스트
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()

health = scheduler.health_check()
print('=== 스케줄러 헬스체크 ===')
print(f'시스템 상태: {health.get(\"system_status\")}')
print(f'최근 실패: {len(health.get(\"recent_job_failures\", []))}건')
"

# 작업 통계 확인
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()

# 임시로 몇 개 작업 실행 후 통계 확인
scheduler.daily_collection()

stats = scheduler.get_job_statistics(days=1)
print('=== 작업 통계 (최근 1일) ===')
print(f'총 작업: {stats[\"total_jobs\"]}개')
print(f'성공률: {stats[\"success_rate\"]:.1f}%')
if stats[\"avg_duration\"] > 0:
    print(f'평균 실행시간: {stats[\"avg_duration\"]:.1f}초')
"
```

### 스케줄러 데몬 테스트

```bash
# 스케줄러 제어 스크립트 권한 설정
docker exec mlops-dev chmod +x scripts/scheduler_control.sh

# 스케줄러 상태 확인
docker exec mlops-dev bash scripts/scheduler_control.sh status

# 스케줄러 시작 (테스트용 - 잠깐만 실행)
docker exec mlops-dev bash -c "
echo '스케줄러 시작 테스트 (5초 후 종료)'
timeout 5s python src/data_processing/scheduler_daemon.py || true
echo '스케줄러 테스트 완료'
"
```

### 1.3 결과 확인

```bash
# 스케줄링된 수집 결과 확인
docker exec mlops-dev find data/raw/movies -name "daily_*" -o -name "weekly_*" -o -name "trending_*" | head -5

# 헬스체크 파일 확인
docker exec mlops-dev ls -la logs/health/

# 스케줄러 로그 확인
docker exec mlops-dev tail -20 logs/scheduler.log 2>/dev/null || echo "스케줄러 로그 없음"
```

---

## 💾 1.4 데이터 저장소 테스트

### 저장소 구조 테스트

```bash
# 데이터 저장소 구조 확인
docker exec mlops-dev tree data/ -L 3 2>/dev/null || docker exec mlops-dev find data/ -type d

# 파일 명명 규칙 테스트
docker exec mlops-dev python -c "
from data.naming_convention import DataFileNamingConvention
from datetime import datetime

naming = DataFileNamingConvention()
print('=== 파일 명명 규칙 테스트 ===')
print(f'일일 수집: {naming.daily_collection()}')
print(f'주간 수집: {naming.weekly_collection(2025, 23)}')
print(f'장르별 수집: {naming.genre_collection(\"액션\")}')
print(f'품질 리포트: {naming.quality_report(\"daily\")}')
print('✅ 명명 규칙 테스트 통과')
"

# 파일 포맷 관리자 테스트
docker exec mlops-dev python -c "
from data.file_formats import DataFileManager
import json

manager = DataFileManager()
print('=== 파일 포맷 관리자 테스트 ===')

# 테스트 데이터
test_data = {'test': 'data', 'count': 123}

# JSON 저장 테스트
manager.save_json(test_data, 'data/test/test_save.json')
print('✅ JSON 저장 성공')

# 파일 정보 조회 테스트
info = manager.get_file_info('data/test/test_save.json')
if info:
    print(f'✅ 파일 정보: {info[\"size_bytes\"]}bytes')
else:
    print('❌ 파일 정보 조회 실패')
"
```

### 백업 시스템 테스트

```bash
# 백업 매니저 테스트
docker exec mlops-dev python -c "
from src.data_processing.backup_manager import BackupManager
import os

if os.path.exists('src/data_processing/backup_manager.py'):
    manager = BackupManager()
    print('✅ BackupManager 로드 성공')
else:
    print('⏭️ BackupManager 미구현')
"

# 수동 백업 테스트
docker exec mlops-dev bash -c "
echo '=== 수동 백업 테스트 ==='
mkdir -p data/backup/test
cp -r data/raw/movies/* data/backup/test/ 2>/dev/null || echo '백업할 파일 없음'
echo '✅ 수동 백업 완료'
ls -la data/backup/test/
"
```

---

## 🔍 1.5 데이터 품질 검증 테스트

### 품질 검증 시스템 테스트

```bash
# DataQualityValidator 기본 테스트
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator

validator = DataQualityValidator()
print('✅ DataQualityValidator 초기화 성공')

# 테스트 영화 데이터
test_movie = {
    'id': 12345,
    'title': '테스트 영화',
    'release_date': '2023-05-15',
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': '좋은 영화입니다.',
    'adult': False,
    'vote_count': 1000
}

is_valid, message, details = validator.validate_single_movie(test_movie)
print(f'검증 결과: {\"✅ 통과\" if is_valid else \"❌ 실패\"}')
print(f'품질 점수: {details[\"overall_score\"]}/100')
print(f'메시지: {message}')
"

# 배치 품질 분석 테스트
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator
import json
from pathlib import Path

validator = DataQualityValidator()

# 최근 수집된 영화 데이터로 배치 분석
data_dir = Path('data/raw/movies')
json_files = list(data_dir.rglob('*.json'))

if json_files:
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    movies = data.get('movies', [])
    if movies:
        print(f'=== 배치 품질 분석 ({len(movies)}개 영화) ===')
        batch_results = validator.validate_batch_data(movies)
        
        print(f'총 영화: {batch_results[\"total_movies\"]}개')
        print(f'유효한 영화: {batch_results[\"valid_movies\"]}개')
        print(f'무효한 영화: {batch_results[\"invalid_movies\"]}개')
        
        quality_dist = batch_results['quality_distribution']
        print(f'품질 분포:')
        print(f'  우수: {quality_dist[\"excellent\"]}개')
        print(f'  양호: {quality_dist[\"good\"]}개')
        print(f'  보통: {quality_dist[\"fair\"]}개')
        print(f'  불량: {quality_dist[\"poor\"]}개')
        
        if batch_results['recommendations']:
            print('권장사항:')
            for rec in batch_results['recommendations']:
                print(f'  - {rec}')
    else:
        print('분석할 영화 데이터가 없습니다.')
else:
    print('수집된 데이터 파일이 없습니다.')
"
```

### 이상 탐지 시스템 테스트

```bash
# AnomalyDetector 테스트
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import AnomalyDetector
import json
from pathlib import Path

detector = AnomalyDetector()
print('✅ AnomalyDetector 초기화 성공')

# 최근 데이터로 이상 탐지 테스트
data_dir = Path('data/raw/movies')
json_files = list(data_dir.rglob('*.json'))

if json_files:
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    movies = data.get('movies', [])
    if movies:
        print(f'=== 이상 탐지 분석 ({len(movies)}개 영화) ===')
        
        # 평점 이상 탐지
        rating_anomalies = detector.detect_rating_anomalies(movies)
        print(f'평점 이상: {len(rating_anomalies.get(\"anomalies\", []))}건')
        
        # 인기도 이상 탐지
        popularity_anomalies = detector.detect_popularity_anomalies(movies)
        print(f'인기도 이상: {len(popularity_anomalies.get(\"anomalies\", []))}건')
        
        # 기준선 업데이트
        collection_stats = data.get('collection_info', {})
        detector.update_baseline(movies, collection_stats)
        print('✅ 기준선 업데이트 완료')
    else:
        print('분석할 영화 데이터가 없습니다.')
else:
    print('수집된 데이터 파일이 없습니다.')
"
```

### 데이터 정제 시스템 테스트

```bash
# DataCleaner 테스트
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataCleaner

cleaner = DataCleaner()
print('✅ DataCleaner 초기화 성공')

# 테스트 더티 데이터
dirty_movie = {
    'id': 12345,
    'title': '  테스트  영화   ',  # 공백 포함
    'release_date': '2023/05/15',    # 잘못된 날짜 형식
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': '<p>HTML 태그가 포함된 개요</p>',
    'genre_ids': ['28', '35', 'invalid'],  # 문자열 포함
    'adult': False,
    'vote_count': 1000
}

cleaned_movie, actions = cleaner.clean_movie_data(dirty_movie)
print(f'정제 작업: {actions}')
print(f'정제 전 제목: \"{dirty_movie[\"title\"]}\"')
print(f'정제 후 제목: \"{cleaned_movie[\"title\"]}\"')
print(f'정제 전 날짜: {dirty_movie[\"release_date\"]}')
print(f'정제 후 날짜: {cleaned_movie[\"release_date\"]}')
print(f'정제 전 장르: {dirty_movie[\"genre_ids\"]}')
print(f'정제 후 장르: {cleaned_movie[\"genre_ids\"]}')
"
```

---

## 📊 1.6 완료 기준 확인

### 종합 상태 점검

```bash
# 전체 시스템 상태 점검
docker exec mlops-dev python -c "
print('=== 1단계 종합 상태 점검 ===')

# 1.1 API 연결 상태
try:
    from src.data_processing.tmdb_api_connector import test_tmdb_connection
    api_status = '✅' if test_tmdb_connection() else '❌'
    print(f'1.1 API 연결: {api_status}')
except Exception as e:
    print(f'1.1 API 연결: ❌ ({e})')

# 1.2 크롤러 상태
try:
    from src.data_processing.tmdb_crawler import TMDBCrawler
    crawler = TMDBCrawler()
    crawler.close()
    print('1.2 크롤러: ✅')
except Exception as e:
    print(f'1.2 크롤러: ❌ ({e})')

# 1.3 스케줄러 상태
try:
    from src.data_processing.scheduler import TMDBDataScheduler
    scheduler = TMDBDataScheduler()
    print('1.3 스케줄러: ✅')
except Exception as e:
    print(f'1.3 스케줄러: ❌ ({e})')

# 1.4 저장소 상태
import os
data_dirs = ['data/raw', 'data/processed', 'logs']
storage_ok = all(os.path.exists(d) for d in data_dirs)
print(f'1.4 저장소: {\"✅\" if storage_ok else \"❌\"}')

# 1.5 품질 검증 상태
try:
    from src.data_processing.quality_validator import DataQualityValidator
    validator = DataQualityValidator()
    print('1.5 품질 검증: ✅')
except Exception as e:
    print(f'1.5 품질 검증: ❌ ({e})')
"

# 수집된 데이터 통계
docker exec mlops-dev python -c "
from pathlib import Path
import json

print('\\n=== 수집 데이터 통계 ===')

data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            movies = data.get('movies', [])
            total_movies += len(movies)
        except Exception:
            continue
    
    print(f'총 수집 파일: {len(json_files)}개')
    print(f'총 영화 데이터: {total_movies}개')
    
    if total_movies >= 1000:
        print('✅ 일일 1000개 이상 수집 기준 달성')
    else:
        print(f'⚠️ 현재 {total_movies}개 수집됨 (목표: 1000개 이상)')
else:
    print('❌ 수집된 데이터가 없습니다.')
"
```

### 완료 기준 체크리스트

```bash
# 완료 기준 자동 체크
docker exec mlops-dev python -c "
from pathlib import Path
import json
import os

print('=== 1단계 완료 기준 체크리스트 ===')

# 기능적 완료 기준
criteria = {
    '1.1 API 연결 성공률 95% 이상': False,
    '1.2 일일 1000개 이상 영화 수집': False,
    '1.3 스케줄링 시스템 동작': False,
    '1.4 데이터 저장소 구조 완성': False,
    '1.5 품질 검증 90% 이상 통과': False,
    '로그 시스템 정상 작동': False,
    '자동화 스크립트 실행 가능': False
}

# 1.1 API 연결 체크
try:
    from src.data_processing.tmdb_api_connector import test_tmdb_connection
    if test_tmdb_connection():
        criteria['1.1 API 연결 성공률 95% 이상'] = True
except Exception:
    pass

# 1.2 수집량 체크
data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            total_movies += len(data.get('movies', []))
        except Exception:
            continue
    
    if total_movies >= 1000:
        criteria['1.2 일일 1000개 이상 영화 수집'] = True

# 1.3 스케줄러 체크
try:
    from src.data_processing.scheduler import TMDBDataScheduler
    criteria['1.3 스케줄링 시스템 동작'] = True
except Exception:
    pass

# 1.4 저장소 구조 체크
required_dirs = ['data/raw', 'data/processed', 'logs']
if all(os.path.exists(d) for d in required_dirs):
    criteria['1.4 데이터 저장소 구조 완성'] = True

# 1.5 품질 검증 체크
try:
    from src.data_processing.quality_validator import DataQualityValidator
    criteria['1.5 품질 검증 90% 이상 통과'] = True
except Exception:
    pass

# 로그 시스템 체크
if os.path.exists('logs') and any(os.listdir('logs')):
    criteria['로그 시스템 정상 작동'] = True

# 스크립트 실행 가능성 체크
if os.path.exists('scripts/scheduler_control.sh'):
    criteria['자동화 스크립트 실행 가능'] = True

# 결과 출력
passed = sum(criteria.values())
total = len(criteria)

for criterion, status in criteria.items():
    status_icon = '✅' if status else '❌'
    print(f'{status_icon} {criterion}')

print(f'\\n전체 완료율: {passed}/{total} ({passed/total*100:.1f}%)')

if passed >= total * 0.8:  # 80% 이상
    print('🎉 1단계 구현이 거의 완료되었습니다!')
elif passed >= total * 0.6:  # 60% 이상
    print('👍 1단계 구현이 잘 진행되고 있습니다.')
else:
    print('⚠️ 더 많은 구현이 필요합니다.')
"
```

---

## 📋 로그 및 문제 해결

### 로그 파일 위치 확인

```bash
# 모든 로그 파일 확인
docker exec mlops-dev find logs/ -name "*.log" -type f

# 주요 로그 파일 내용 확인
echo "=== API 연동 로그 ==="
docker exec mlops-dev tail -10 logs/test_tmdb_integration.log 2>/dev/null || echo "로그 없음"

echo "=== 크롤러 로그 ==="  
docker exec mlops-dev tail -10 logs/test_crawler.log 2>/dev/null || echo "로그 없음"

echo "=== 대량 수집 로그 ==="
docker exec mlops-dev tail -10 logs/data/bulk_collection_test.log 2>/dev/null || echo "로그 없음"

echo "=== 스케줄러 로그 ==="
docker exec mlops-dev tail -10 logs/scheduler.log 2>/dev/null || echo "로그 없음"
```

### 일반적인 문제 해결

```bash
# 1. API 키 문제 상세 진단
echo "=== API 키 문제 진단 ==="

# .env 파일의 API 키 확인
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"

# Docker 컨테이너 환경변수 확인
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"

# Python dotenv 로딩 테스트
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv
print('로드 전:', os.getenv('TMDB_API_KEY'))
load_dotenv(override=True)
print('로드 후:', os.getenv('TMDB_API_KEY'))
"

# 문제 해결 방법
if docker exec mlops-dev bash -c "[ '\$TMDB_API_KEY' = 'your_tmdb_api_key_here' ]"; then
    echo '❌ Docker 컨테이너에 잘못된 환경변수가 설정되어 있습니다.'
    echo '해결: docker compose down && docker compose up -d dev'
else
    echo '✅ Docker 환경변수가 올바르게 설정되어 있습니다.'
fi

# 2. 디렉토리 권한 문제
echo "=== 디렉토리 권한 확인 ==="
docker exec mlops-dev bash -c "
dirs=('data' 'logs' 'reports')
for dir in \${dirs[@]}; do
    if [ -w "\$dir" ]; then
        echo "✅ \$dir 쓰기 가능"
    else
        echo "❌ \$dir 쓰기 불가 - 권한 확인 필요"
    fi
done
"

# 3. Python 모듈 임포트 문제
echo "=== Python 모듈 확인 ==="
docker exec mlops-dev python -c "
import sys
sys.path.insert(0, 'src')

modules = [
    'data_processing.tmdb_api_connector',
    'data_processing.tmdb_crawler', 
    'data_processing.scheduler',
    'data_processing.quality_validator'
]

for module in modules:
    try:
        __import__(module)
        print(f'✅ {module}')
    except Exception as e:
        print(f'❌ {module}: {e}')
"

# 4. 네트워크 연결 확인
echo "=== 네트워크 연결 확인 ==="
docker exec mlops-dev python -c "
import requests
try:
    response = requests.get('https://api.themoviedb.org/3', timeout=10)
    print(f'✅ TMDB API 연결 가능 (상태: {response.status_code})')
except Exception as e:
    print(f'❌ TMDB API 연결 불가: {e}')
"

# 5. 환경변수 배리어 우회 테스트
echo "=== 환경변수 배리어 우회 테스트 ==="
docker exec mlops-dev bash -c "
# 기존 환경변수 제거
unset TMDB_API_KEY

# .env 파일에서 API 키 추출
API_KEY=\$(grep TMDB_API_KEY .env | cut -d'=' -f2)
export TMDB_API_KEY=\$API_KEY

echo '환경변수 재설정 완료:' \$TMDB_API_KEY

# 테스트 실행
python -c 'from src.data_processing.tmdb_api_connector import test_tmdb_connection; print("✅ API 테스트 성공" if test_tmdb_connection() else "❌ API 테스트 실패")'
"
```

### 성능 모니터링

```bash
# Docker 컨테이너 리소스 사용량
echo "=== Docker 리소스 사용량 ==="
docker stats mlops-dev --no-stream

# 디스크 사용량 확인
echo "=== 디스크 사용량 ==="
docker exec mlops-dev df -h

# 데이터 디렉토리 크기
echo "=== 데이터 디렉토리 크기 ==="
docker exec mlops-dev du -sh data/ logs/ reports/ 2>/dev/null || echo "디렉토리 없음"
```

---

## 🎯 종합 테스트 실행

### 전체 시스템 통합 테스트

```bash
# 종합 테스트 스크립트 (순차 실행)
docker exec -it mlops-dev bash -c "
echo '============================================================'
echo '1단계 데이터 처리 시스템 종합 테스트'
echo '============================================================'

echo ''
echo '1/6 API 연동 테스트...'
python src/data_processing/test_integration.py > /tmp/test1.log 2>&1
if [ \$? -eq 0 ]; then echo '✅ 1.1 API 연동 성공'; else echo '❌ 1.1 API 연동 실패'; fi

echo ''
echo '2/6 크롤러 테스트...'
python src/data_processing/test_crawler.py > /tmp/test2.log 2>&1
if [ \$? -eq 0 ]; then echo '✅ 1.2 크롤러 성공'; else echo '❌ 1.2 크롤러 실패'; fi

echo ''
echo '3/6 대량 수집 테스트...'
echo '1' | python src/data_processing/bulk_collection_test.py > /tmp/test3.log 2>&1
if [ \$? -eq 0 ]; then echo '✅ 대량 수집 성공'; else echo '❌ 대량 수집 실패'; fi

echo ''
echo '4/6 스케줄러 테스트...'
timeout 10s python -c \"
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
result = scheduler.daily_collection()
print('스케줄러 테스트 완료')
\" > /tmp/test4.log 2>&1
if [ \$? -eq 0 ] || [ \$? -eq 124 ]; then echo '✅ 1.3 스케줄러 성공'; else echo '❌ 1.3 스케줄러 실패'; fi

echo ''
echo '5/6 품질 검증 테스트...'
python -c \"
from src.data_processing.quality_validator import DataQualityValidator
validator = DataQualityValidator()
test_movie = {'id': 1, 'title': 'Test', 'release_date': '2023-01-01', 'vote_average': 8.0, 'popularity': 100, 'overview': 'Test movie', 'adult': False, 'vote_count': 100}
is_valid, msg, details = validator.validate_single_movie(test_movie)
print(f'품질 검증: {is_valid}')
\" > /tmp/test5.log 2>&1
if [ \$? -eq 0 ]; then echo '✅ 1.5 품질 검증 성공'; else echo '❌ 1.5 품질 검증 실패'; fi

echo ''
echo '6/6 시스템 상태 점검...'
if [ -d 'data' ] && [ -d 'logs' ]; then
    echo '✅ 1.4 저장소 구조 성공'
else
    echo '❌ 1.4 저장소 구조 실패'
fi

echo ''
echo '============================================================'
echo '종합 테스트 완료!'
echo '============================================================'

# 로그 파일 요약
echo ''
echo '=== 테스트 로그 요약 ==='
for i in {1..5}; do
    if [ -f \"/tmp/test\$i.log\" ]; then
        echo \"테스트 \$i 로그:\"
        tail -3 \"/tmp/test\$i.log\" 2>/dev/null || echo '로그 없음'
        echo ''
    fi
done
"
```

### 최종 보고서 생성

```bash
# 최종 테스트 보고서 생성
docker exec mlops-dev python -c "
import json
from datetime import datetime
from pathlib import Path

print('=== 1단계 최종 테스트 보고서 생성 ===')

# 보고서 데이터 수집
report = {
    'test_date': datetime.now().isoformat(),
    'stage': '1단계 데이터 처리',
    'components': {},
    'data_summary': {},
    'recommendations': []
}

# 각 컴포넌트 상태 확인
components = {
    '1.1_api_connection': 'TMDB API 연동',
    '1.2_crawler': '데이터 크롤러',
    '1.3_scheduler': '수집 스케줄링', 
    '1.4_storage': '데이터 저장소',
    '1.5_quality': '품질 검증'
}

for comp_id, comp_name in components.items():
    try:
        if comp_id == '1.1_api_connection':
            from src.data_processing.tmdb_api_connector import test_tmdb_connection
            status = 'PASS' if test_tmdb_connection() else 'FAIL'
        elif comp_id == '1.2_crawler':
            from src.data_processing.tmdb_crawler import TMDBCrawler
            crawler = TMDBCrawler()
            crawler.close()
            status = 'PASS'
        elif comp_id == '1.3_scheduler':
            from src.data_processing.scheduler import TMDBDataScheduler
            scheduler = TMDBDataScheduler()
            status = 'PASS'
        elif comp_id == '1.4_storage':
            import os
            status = 'PASS' if all(os.path.exists(d) for d in ['data', 'logs']) else 'FAIL'
        elif comp_id == '1.5_quality':
            from src.data_processing.quality_validator import DataQualityValidator
            validator = DataQualityValidator()
            status = 'PASS'
        else:
            status = 'UNKNOWN'
            
        report['components'][comp_name] = status
        
    except Exception as e:
        report['components'][comp_name] = f'FAIL: {str(e)}'

# 데이터 수집 통계
data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            total_movies += len(data.get('movies', []))
        except Exception:
            continue
    
    report['data_summary'] = {
        'total_files': len(json_files),
        'total_movies': total_movies,
        'meets_1000_requirement': total_movies >= 1000
    }

# 권장사항 생성
passed_components = sum(1 for status in report['components'].values() if status == 'PASS')
total_components = len(report['components'])

if passed_components == total_components:
    report['recommendations'].append('🎉 모든 컴포넌트가 정상 작동합니다. 2단계로 진행할 수 있습니다.')
elif passed_components >= total_components * 0.8:
    report['recommendations'].append('👍 대부분의 컴포넌트가 작동합니다. 실패한 부분을 수정한 후 진행하세요.')
else:
    report['recommendations'].append('⚠️ 여러 컴포넌트에 문제가 있습니다. 로그를 확인하고 문제를 해결하세요.')

if report['data_summary'].get('total_movies', 0) < 1000:
    report['recommendations'].append('📊 수집된 영화 데이터가 1000개 미만입니다. 대량 수집 테스트를 다시 실행하세요.')

# 보고서 저장
report_dir = Path('reports')
report_dir.mkdir(exist_ok=True)

report_file = report_dir / f'stage1_final_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'
with open(report_file, 'w', encoding='utf-8') as f:
    json.dump(report, f, ensure_ascii=False, indent=2, default=str)

print(f'최종 보고서 저장: {report_file}')

# 결과 요약 출력
print('\\n=== 테스트 결과 요약 ===')
for comp_name, status in report['components'].items():
    status_icon = '✅' if status == 'PASS' else '❌'
    print(f'{status_icon} {comp_name}: {status}')

print(f'\\n전체 성공률: {passed_components}/{total_components} ({passed_components/total_components*100:.1f}%)')

if report['data_summary']:
    summary = report['data_summary']
    print(f'수집 데이터: {summary[\"total_movies\"]}개 영화 ({summary[\"total_files\"]}개 파일)')

if report['recommendations']:
    print('\\n=== 권장사항 ===')
    for rec in report['recommendations']:
        print(f'• {rec}')
"
```

---

## 🎉 테스트 완료 후 다음 단계

### 성공적인 테스트 완료 후

```bash
echo "✅ 1단계 테스트 완료!"
echo ""
echo "다음 단계:"
echo "1. 2단계 피처 스토어 구현 준비"
echo "2. 수집된 데이터를 활용한 피처 엔지니어링"
echo "3. MLOps 파이프라인 확장"
echo ""
echo "현재 상태 확인:"
docker exec mlops-dev find data/raw/movies -name "*.json" | wc -l | xargs echo "수집 파일 수:"
docker exec mlops-dev find logs -name "*.log" | wc -l | xargs echo "로그 파일 수:"
```

### 문제 발생 시 체크포인트

```bash
echo "=== 문제 해결 체크포인트 ==="
echo "1. TMDB API 키 설정 확인"
echo "2. Docker 컨테이너 상태 확인"  
echo "3. 네트워크 연결 확인"
echo "4. 디렉토리 권한 확인"
echo "5. Python 모듈 임포트 확인"
echo ""
echo "상세 로그는 다음 위치에서 확인:"
echo "- logs/test_tmdb_integration.log"
echo "- logs/test_crawler.log"  
echo "- logs/data/bulk_collection_test.log"
echo "- logs/scheduler.log"
echo "- reports/ 디렉토리의 JSON 보고서들"
```

---

이 가이드를 통해 1단계 데이터 처리 시스템의 모든 구성 요소를 체계적으로 테스트할 수 있습니다. 각 테스트 단계에서 문제가 발생하면 해당 섹션의 문제 해결 방법을 참조하여 해결하시기 바랍니다.
