# 1.5 데이터 품질 검증 - WSL Ubuntu 24.04 구현 가이드

## 📋 단계 개요

**목표**: 수집된 데이터의 품질을 보장하고 이상 데이터를 조기에 감지

**환경**: WSL Ubuntu 24.04 + Docker + Python 3.11

**핵심 가치**: 신뢰할 수 있는 데이터 품질을 통한 ML 모델의 성능 보장

---

## 🎯 1.5.1 실시간 품질 검증 시스템

### 목표
데이터 수집 시점에 즉시 품질을 검증하여 문제 데이터 유입 차단

### 필드별 검증 규칙 구현

```bash
# 품질 검증 모듈 생성
docker exec mlops-dev touch src/data_processing/quality_validator.py
```

**QualityValidator 클래스 구조**:
```python
import logging
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import json

class DataQualityValidator:
    """데이터 품질 검증 클래스"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.validation_rules = self._setup_validation_rules()
        self.quality_stats = {
            'total_validated': 0,
            'passed': 0,
            'failed': 0,
            'error_details': {}
        }
    
    def _setup_validation_rules(self):
        """검증 규칙 설정"""
        return {
            'required_fields': [
                'id', 'title', 'release_date', 
                'vote_average', 'popularity', 'overview'
            ],
            'field_types': {
                'id': int,
                'title': str,
                'vote_average': (int, float),
                'popularity': (int, float),
                'adult': bool
            },
            'field_ranges': {
                'vote_average': (0, 10),
                'popularity': (0, float('inf')),
                'vote_count': (0, float('inf'))
            },
            'field_patterns': {
                'release_date': r'^\d{4}-\d{2}-\d{2}$',
                'imdb_id': r'^tt\d+$'
            }
        }
    
    def validate_single_movie(self, movie: Dict) -> Tuple[bool, str, Dict]:
        """단일 영화 데이터 검증"""
        self.quality_stats['total_validated'] += 1
        validation_result = {
            'movie_id': movie.get('id', 'unknown'),
            'checks': {},
            'overall_score': 0,
            'issues': []
        }
        
        try:
            # 필수 필드 존재 확인
            required_check = self._check_required_fields(movie)
            validation_result['checks']['required_fields'] = required_check
            
            # 데이터 타입 검증
            type_check = self._check_field_types(movie)
            validation_result['checks']['field_types'] = type_check
            
            # 값 범위 검증
            range_check = self._check_field_ranges(movie)
            validation_result['checks']['field_ranges'] = range_check
            
            # 패턴 검증
            pattern_check = self._check_field_patterns(movie)
            validation_result['checks']['field_patterns'] = pattern_check
            
            # 비즈니스 로직 검증
            business_check = self._check_business_logic(movie)
            validation_result['checks']['business_logic'] = business_check
            
            # 전체 점수 계산
            validation_result['overall_score'] = self._calculate_quality_score(validation_result['checks'])
            
            # 통과/실패 판정 (70점 이상 통과)
            is_valid = validation_result['overall_score'] >= 70
            
            if is_valid:
                self.quality_stats['passed'] += 1
                return True, "Valid", validation_result
            else:
                self.quality_stats['failed'] += 1
                return False, f"Quality score too low: {validation_result['overall_score']}", validation_result
                
        except Exception as e:
            self.quality_stats['failed'] += 1
            self.logger.error(f"Validation error for movie {movie.get('id', 'unknown')}: {e}")
            return False, f"Validation error: {str(e)}", validation_result
    
    def _check_required_fields(self, movie: Dict) -> Dict:
        """필수 필드 존재 확인"""
        missing_fields = []
        for field in self.validation_rules['required_fields']:
            if field not in movie or movie[field] is None or movie[field] == '':
                missing_fields.append(field)
        
        return {
            'passed': len(missing_fields) == 0,
            'score': max(0, 100 - len(missing_fields) * 20),
            'missing_fields': missing_fields
        }
    
    def _check_field_types(self, movie: Dict) -> Dict:
        """데이터 타입 검증"""
        type_errors = []
        for field, expected_type in self.validation_rules['field_types'].items():
            if field in movie and movie[field] is not None:
                if not isinstance(movie[field], expected_type):
                    type_errors.append(f"{field}: expected {expected_type}, got {type(movie[field])}")
        
        return {
            'passed': len(type_errors) == 0,
            'score': max(0, 100 - len(type_errors) * 25),
            'type_errors': type_errors
        }
    
    def _check_field_ranges(self, movie: Dict) -> Dict:
        """값 범위 검증"""
        range_errors = []
        for field, (min_val, max_val) in self.validation_rules['field_ranges'].items():
            if field in movie and movie[field] is not None:
                value = movie[field]
                if not (min_val <= value <= max_val):
                    range_errors.append(f"{field}: {value} not in range [{min_val}, {max_val}]")
        
        return {
            'passed': len(range_errors) == 0,
            'score': max(0, 100 - len(range_errors) * 20),
            'range_errors': range_errors
        }
    
    def _check_field_patterns(self, movie: Dict) -> Dict:
        """패턴 검증"""
        import re
        pattern_errors = []
        for field, pattern in self.validation_rules['field_patterns'].items():
            if field in movie and movie[field] is not None:
                if not re.match(pattern, str(movie[field])):
                    pattern_errors.append(f"{field}: {movie[field]} doesn't match pattern {pattern}")
        
        return {
            'passed': len(pattern_errors) == 0,
            'score': max(0, 100 - len(pattern_errors) * 15),
            'pattern_errors': pattern_errors
        }
    
    def _check_business_logic(self, movie: Dict) -> Dict:
        """비즈니스 로직 검증"""
        business_errors = []
        
        # 성인 영화 필터링
        if movie.get('adult', False):
            business_errors.append("Adult content not allowed")
        
        # 개봉 전 영화 제외
        release_date = movie.get('release_date')
        if release_date:
            try:
                release_dt = datetime.strptime(release_date, '%Y-%m-%d')
                if release_dt > datetime.now():
                    business_errors.append("Unreleased movie")
            except ValueError:
                business_errors.append("Invalid release date format")
        
        # 평점 0인 영화 제외
        if movie.get('vote_average', 0) == 0:
            business_errors.append("Zero rating")
        
        # 투표 수 너무 적은 영화 제외
        if movie.get('vote_count', 0) < 10:
            business_errors.append("Insufficient votes")
        
        return {
            'passed': len(business_errors) == 0,
            'score': max(0, 100 - len(business_errors) * 25),
            'business_errors': business_errors
        }
    
    def _calculate_quality_score(self, checks: Dict) -> float:
        """전체 품질 점수 계산"""
        total_score = 0
        weights = {
            'required_fields': 0.3,
            'field_types': 0.25,
            'field_ranges': 0.2,
            'field_patterns': 0.1,
            'business_logic': 0.15
        }
        
        for check_name, weight in weights.items():
            if check_name in checks:
                total_score += checks[check_name]['score'] * weight
        
        return round(total_score, 2)
```

### 배치 품질 분석 시스템

```python
def validate_batch_data(self, movies: List[Dict]) -> Dict:
    """배치 데이터 품질 분석"""
    batch_results = {
        'total_movies': len(movies),
        'valid_movies': 0,
        'invalid_movies': 0,
        'quality_distribution': {},
        'common_issues': {},
        'recommendations': []
    }
    
    valid_movies = []
    invalid_movies = []
    quality_scores = []
    all_issues = []
    
    for movie in movies:
        is_valid, message, details = self.validate_single_movie(movie)
        quality_scores.append(details['overall_score'])
        
        if is_valid:
            valid_movies.append(movie)
            batch_results['valid_movies'] += 1
        else:
            invalid_movies.append(movie)
            batch_results['invalid_movies'] += 1
            all_issues.extend(details['issues'])
    
    # 품질 분포 분석
    batch_results['quality_distribution'] = {
        'excellent': len([s for s in quality_scores if s >= 90]),
        'good': len([s for s in quality_scores if 80 <= s < 90]),
        'fair': len([s for s in quality_scores if 70 <= s < 80]),
        'poor': len([s for s in quality_scores if s < 70])
    }
    
    # 공통 이슈 분석
    from collections import Counter
    issue_counts = Counter(all_issues)
    batch_results['common_issues'] = dict(issue_counts.most_common(10))
    
    # 개선 권장사항
    batch_results['recommendations'] = self._generate_recommendations(batch_results)
    
    return batch_results

def _generate_recommendations(self, batch_results: Dict) -> List[str]:
    """개선 권장사항 생성"""
    recommendations = []
    
    total = batch_results['total_movies']
    invalid_rate = batch_results['invalid_movies'] / total * 100
    
    if invalid_rate > 10:
        recommendations.append(f"데이터 품질 불량률이 {invalid_rate:.1f}%로 높습니다. 수집 로직 점검 필요")
    
    common_issues = batch_results['common_issues']
    if 'Zero rating' in common_issues:
        recommendations.append("평점 0인 영화가 많습니다. 필터링 강화 필요")
    
    if 'Insufficient votes' in common_issues:
        recommendations.append("투표 수 부족 영화가 많습니다. 최소 투표 수 기준 상향 검토")
    
    return recommendations
```

---

## 🎯 1.5.2 통계적 이상 탐지

### 목표
통계적 방법을 통한 이상 패턴 자동 감지

### 이상 탐지 구현

```python
class AnomalyDetector:
    """통계적 이상 탐지"""
    
    def __init__(self):
        self.baseline_stats = {}
        self.alert_thresholds = {
            'rating_mean_change': 0.5,
            'popularity_variance_change': 2.0,
            'collection_volume_change': 0.3
        }
    
    def detect_rating_anomalies(self, movies: List[Dict]) -> Dict:
        """평점 분포 이상 탐지"""
        ratings = [m.get('vote_average', 0) for m in movies if m.get('vote_average')]
        
        if not ratings:
            return {'status': 'no_data', 'anomalies': []}
        
        current_stats = {
            'mean': np.mean(ratings),
            'std': np.std(ratings),
            'median': np.median(ratings),
            'q1': np.percentile(ratings, 25),
            'q3': np.percentile(ratings, 75)
        }
        
        anomalies = []
        
        # 기준 통계와 비교
        if 'ratings' in self.baseline_stats:
            baseline = self.baseline_stats['ratings']
            
            # 평균 변화 확인
            mean_change = abs(current_stats['mean'] - baseline['mean'])
            if mean_change > self.alert_thresholds['rating_mean_change']:
                anomalies.append({
                    'type': 'rating_mean_shift',
                    'current': current_stats['mean'],
                    'baseline': baseline['mean'],
                    'change': mean_change
                })
        
        # 극값 탐지
        iqr = current_stats['q3'] - current_stats['q1']
        lower_bound = current_stats['q1'] - 1.5 * iqr
        upper_bound = current_stats['q3'] + 1.5 * iqr
        
        outliers = [r for r in ratings if r < lower_bound or r > upper_bound]
        if len(outliers) > len(ratings) * 0.1:  # 10% 이상이 극값
            anomalies.append({
                'type': 'excessive_outliers',
                'outlier_count': len(outliers),
                'outlier_rate': len(outliers) / len(ratings)
            })
        
        return {
            'status': 'analyzed',
            'current_stats': current_stats,
            'anomalies': anomalies
        }
    
    def detect_collection_anomalies(self, collection_stats: Dict) -> Dict:
        """수집량 이상 탐지"""
        anomalies = []
        
        current_count = collection_stats.get('total_collected', 0)
        
        if 'collection' in self.baseline_stats:
            baseline_count = self.baseline_stats['collection']['average_count']
            change_rate = abs(current_count - baseline_count) / baseline_count
            
            if change_rate > self.alert_thresholds['collection_volume_change']:
                anomalies.append({
                    'type': 'collection_volume_change',
                    'current': current_count,
                    'baseline': baseline_count,
                    'change_rate': change_rate
                })
        
        return {
            'status': 'analyzed',
            'anomalies': anomalies
        }
    
    def update_baseline(self, movies: List[Dict], collection_stats: Dict):
        """기준선 업데이트"""
        # 평점 통계 업데이트
        ratings = [m.get('vote_average', 0) for m in movies if m.get('vote_average')]
        if ratings:
            self.baseline_stats['ratings'] = {
                'mean': np.mean(ratings),
                'std': np.std(ratings),
                'median': np.median(ratings)
            }
        
        # 수집량 통계 업데이트
        if 'collection' not in self.baseline_stats:
            self.baseline_stats['collection'] = {'average_count': collection_stats.get('total_collected', 0)}
        else:
            # 지수 이동 평균 적용
            alpha = 0.1
            current_avg = self.baseline_stats['collection']['average_count']
            new_count = collection_stats.get('total_collected', 0)
            self.baseline_stats['collection']['average_count'] = alpha * new_count + (1 - alpha) * current_avg
```

---

## 🎯 1.5.3 일간 품질 리포트 생성

### 목표
자동화된 품질 리포트를 통한 데이터 상태 가시화

### 품질 리포트 시스템

```bash
# 품질 리포트 생성기 구현
docker exec mlops-dev touch src/data_processing/quality_reporter.py
```

```python
class QualityReporter:
    """데이터 품질 리포트 생성"""
    
    def __init__(self):
        self.validator = DataQualityValidator()
        self.anomaly_detector = AnomalyDetector()
    
    def generate_daily_report(self, date_str: str = None) -> Dict:
        """일간 품질 리포트 생성"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        
        # 해당 날짜 데이터 로드
        daily_files = self._find_daily_files(date_str)
        if not daily_files:
            return {'status': 'no_data', 'date': date_str}
        
        all_movies = []
        collection_stats = {}
        
        for file_path in daily_files:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'movies' in data:
                    all_movies.extend(data['movies'])
                if 'collection_info' in data:
                    collection_stats.update(data['collection_info'])
        
        # 품질 분석 실행
        batch_results = self.validator.validate_batch_data(all_movies)
        anomaly_results = self.anomaly_detector.detect_rating_anomalies(all_movies)
        collection_anomalies = self.anomaly_detector.detect_collection_anomalies(collection_stats)
        
        # 리포트 생성
        report = {
            'report_date': date_str,
            'generation_time': datetime.now().isoformat(),
            'data_summary': {
                'total_files_processed': len(daily_files),
                'total_movies_analyzed': len(all_movies),
                'unique_movies': len(set(m.get('id') for m in all_movies if m.get('id')))
            },
            'quality_summary': {
                'overall_quality_score': self._calculate_overall_quality(batch_results),
                'valid_rate': batch_results['valid_movies'] / batch_results['total_movies'] * 100,
                'quality_distribution': batch_results['quality_distribution'],
                'common_issues': batch_results['common_issues'],
                'recommendations': batch_results['recommendations']
            },
            'anomaly_analysis': {
                'rating_anomalies': anomaly_results['anomalies'],
                'collection_anomalies': collection_anomalies['anomalies'],
                'anomaly_count': len(anomaly_results['anomalies']) + len(collection_anomalies['anomalies'])
            },
            'data_health': self._assess_data_health(batch_results, anomaly_results, collection_anomalies)
        }
        
        # 리포트 저장
        self._save_report(report, date_str)
        
        return report
    
    def _calculate_overall_quality(self, batch_results: Dict) -> float:
        """전체 품질 점수 계산"""
        quality_dist = batch_results['quality_distribution']
        total = batch_results['total_movies']
        
        if total == 0:
            return 0
        
        weighted_score = (
            quality_dist['excellent'] * 95 +
            quality_dist['good'] * 85 +
            quality_dist['fair'] * 75 +
            quality_dist['poor'] * 50
        ) / total
        
        return round(weighted_score, 2)
    
    def _assess_data_health(self, batch_results: Dict, anomaly_results: Dict, collection_anomalies: Dict) -> Dict:
        """데이터 건강도 평가"""
        health_score = 100
        issues = []
        
        # 품질 불량률 체크
        if batch_results['total_movies'] > 0:
            invalid_rate = batch_results['invalid_movies'] / batch_results['total_movies']
            if invalid_rate > 0.2:  # 20% 이상
                health_score -= 30
                issues.append("high_invalid_rate")
            elif invalid_rate > 0.1:  # 10% 이상
                health_score -= 15
                issues.append("moderate_invalid_rate")
        
        # 이상 탐지 결과 체크
        anomaly_count = len(anomaly_results.get('anomalies', [])) + len(collection_anomalies.get('anomalies', []))
        if anomaly_count > 2:
            health_score -= 25
            issues.append("multiple_anomalies")
        elif anomaly_count > 0:
            health_score -= 10
            issues.append("minor_anomalies")
        
        # 건강도 등급 결정
        if health_score >= 90:
            grade = "🟢 Excellent"
        elif health_score >= 80:
            grade = "🟡 Good"
        elif health_score >= 70:
            grade = "🟠 Fair"
        else:
            grade = "🔴 Poor"
        
        return {
            'health_score': max(0, health_score),
            'grade': grade,
            'issues': issues
        }
    
    def _save_report(self, report: Dict, date_str: str):
        """리포트 저장"""
        report_dir = Path('data/raw/metadata/quality_reports')
        report_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = report_dir / f"daily_quality_report_{date_str}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        # 최신 리포트 링크 생성
        latest_link = report_dir / "latest_quality_report.json"
        if latest_link.exists():
            latest_link.unlink()
        latest_link.symlink_to(report_file.name)
    
    def _find_daily_files(self, date_str: str) -> List[Path]:
        """해당 날짜 데이터 파일 찾기"""
        data_dir = Path('data/raw/movies')
        pattern = f"*{date_str}*.json"
        
        files = []
        for subdir in ['daily', 'trending']:
            subdir_path = data_dir / subdir
            if subdir_path.exists():
                files.extend(subdir_path.glob(pattern))
        
        return files
```

### 품질 리포트 자동 생성 스크립트

```bash
# 일간 품질 리포트 생성 스크립트
docker exec mlops-dev bash -c "
cat > scripts/generate_daily_quality_report.py << 'EOF'
#!/usr/bin/env python3
\"\"\"일간 데이터 품질 리포트 자동 생성 스크립트\"\"\"

import sys
from pathlib import Path
from datetime import datetime, timedelta

# 프로젝트 루트 설정
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from data_processing.quality_reporter import QualityReporter

def main():
    reporter = QualityReporter()
    
    # 어제 날짜 리포트 생성 (보통 새벽에 실행)
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
    
    print(f\"일간 품질 리포트 생성 중... (날짜: {yesterday})\")
    
    try:
        report = reporter.generate_daily_report(yesterday)
        
        if report.get('status') == 'no_data':
            print(f\"경고: {yesterday} 날짜의 데이터를 찾을 수 없습니다.\")
            return
        
        # 리포트 요약 출력
        print(\"\\n=== 일간 품질 리포트 요약 ===\")
        print(f\"분석된 영화 수: {report['data_summary']['total_movies_analyzed']}\")
        print(f\"전체 품질 점수: {report['quality_summary']['overall_quality_score']}/100\")
        print(f\"유효 데이터 비율: {report['quality_summary']['valid_rate']:.1f}%\")
        print(f\"데이터 건강도: {report['data_health']['grade']}\")
        print(f\"감지된 이상: {report['anomaly_analysis']['anomaly_count']}개\")
        
        if report['quality_summary']['recommendations']:
            print(\"\\n=== 개선 권장사항 ===\")
            for i, rec in enumerate(report['quality_summary']['recommendations'], 1):
                print(f\"{i}. {rec}\")
        
        print(f\"\\n✅ 리포트가 저장되었습니다: data/raw/metadata/quality_reports/daily_quality_report_{yesterday}.json\")
        
    except Exception as e:
        print(f\"❌ 리포트 생성 실패: {e}\")
        sys.exit(1)

if __name__ == \"__main__\":
    main()
EOF

chmod +x scripts/generate_daily_quality_report.py
"
```

---

## 🎯 1.5.4 품질 개선 액션 시스템

### 자동 데이터 정제

```python
class DataCleaner:
    """자동 데이터 정제"""
    
    def __init__(self):
        self.cleaning_stats = {
            'processed': 0,
            'cleaned': 0,
            'removed': 0,
            'actions': []
        }
    
    def clean_movie_data(self, movie: Dict) -> Tuple[Dict, str]:
        """개별 영화 데이터 정제"""
        self.cleaning_stats['processed'] += 1
        original_movie = movie.copy()
        actions = []
        
        # 1. 빈 문자열을 None으로 변환
        for key, value in movie.items():
            if value == "":
                movie[key] = None
                actions.append(f"empty_to_none_{key}")
        
        # 2. 제목 정제
        if movie.get('title'):
            cleaned_title = self._clean_title(movie['title'])
            if cleaned_title != movie['title']:
                movie['title'] = cleaned_title
                actions.append("title_cleaned")
        
        # 3. 개요 정제
        if movie.get('overview'):
            cleaned_overview = self._clean_overview(movie['overview'])
            if cleaned_overview != movie['overview']:
                movie['overview'] = cleaned_overview
                actions.append("overview_cleaned")
        
        # 4. 장르 정규화
        if movie.get('genre_ids'):
            movie['genre_ids'] = self._normalize_genres(movie['genre_ids'])
            actions.append("genres_normalized")
        
        # 5. 날짜 형식 표준화
        if movie.get('release_date'):
            standardized_date = self._standardize_date(movie['release_date'])
            if standardized_date != movie['release_date']:
                movie['release_date'] = standardized_date
                actions.append("date_standardized")
        
        if actions:
            self.cleaning_stats['cleaned'] += 1
            self.cleaning_stats['actions'].extend(actions)
        
        return movie, '; '.join(actions) if actions else 'no_cleaning_needed'
    
    def _clean_title(self, title: str) -> str:
        """제목 정제"""
        import re
        # 불필요한 공백 제거
        title = re.sub(r'\s+', ' ', title.strip())
        # 특수 문자 정제
        title = re.sub(r'[^\w\s\-\.\,\!\?\:\(\)]', '', title)
        return title
    
    def _clean_overview(self, overview: str) -> str:
        """개요 정제"""
        import re
        # HTML 태그 제거
        overview = re.sub(r'<[^>]+>', '', overview)
        # 불필요한 공백 제거
        overview = re.sub(r'\s+', ' ', overview.strip())
        return overview
    
    def _normalize_genres(self, genre_ids: List) -> List:
        """장르 정규화"""
        if not isinstance(genre_ids, list):
            return []
        return [int(g) for g in genre_ids if isinstance(g, (int, str)) and str(g).isdigit()]
    
    def _standardize_date(self, date_str: str) -> str:
        """날짜 형식 표준화"""
        import re
        from datetime import datetime
        
        # 이미 YYYY-MM-DD 형식인지 확인
        if re.match(r'^\d{4}-\d{2}-\d{2}$', date_str):
            return date_str
        
        # 다양한 날짜 형식 처리
        date_patterns = [
            '%Y/%m/%d', '%Y.%m.%d', '%Y%m%d',
            '%m/%d/%Y', '%m-%d-%Y', '%d/%m/%Y'
        ]
        
        for pattern in date_patterns:
            try:
                dt = datetime.strptime(date_str, pattern)
                return dt.strftime('%Y-%m-%d')
            except ValueError:
                continue
        
        return date_str  # 변환 실패 시 원본 반환

def apply_batch_cleaning(self, movies: List[Dict]) -> Tuple[List[Dict], Dict]:
    """배치 데이터 정제"""
    cleaned_movies = []
    cleaning_report = {
        'total_processed': len(movies),
        'successfully_cleaned': 0,
        'removed_count': 0,
        'cleaning_actions': {},
        'removed_reasons': {}
    }
    
    for movie in movies:
        try:
            cleaned_movie, actions = self.clean_movie_data(movie)
            
            # 정제 후 재검증
            validator = DataQualityValidator()
            is_valid, reason, details = validator.validate_single_movie(cleaned_movie)
            
            if is_valid:
                cleaned_movies.append(cleaned_movie)
                cleaning_report['successfully_cleaned'] += 1
                
                # 정제 액션 통계
                if actions != 'no_cleaning_needed':
                    for action in actions.split('; '):
                        cleaning_report['cleaning_actions'][action] = cleaning_report['cleaning_actions'].get(action, 0) + 1
            else:
                # 정제 후에도 유효하지 않으면 제거
                cleaning_report['removed_count'] += 1
                cleaning_report['removed_reasons'][reason] = cleaning_report['removed_reasons'].get(reason, 0) + 1
                
        except Exception as e:
            cleaning_report['removed_count'] += 1
            cleaning_report['removed_reasons'][f'cleaning_error: {str(e)}'] = cleaning_report['removed_reasons'].get(f'cleaning_error: {str(e)}', 0) + 1
    
    return cleaned_movies, cleaning_report
```

---

## 🎯 1.5.5 실제 구현된 품질 검증 시스템 🆕

### 목표
실제 구현된 DataQualityValidator, AnomalyDetector, DataCleaner 클래스를 기반으로 한 종합적 데이터 품질 검증 시스템 검증

### 실제 구현된 DataQualityValidator 주요 기능

#### **포괄적 품질 검증 시스템**
```python
# 실제 구현된 품질 검증 로직
class DataQualityValidator:
    def validate_single_movie(self, movie: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
        """실제 구현된 단일 영화 데이터 검증"""
        
        validation_result = {
            'movie_id': movie.get('id', 'unknown'),
            'checks': {},
            'overall_score': 0,
            'issues': []
        }
        
        # 1. 필수 필드 존재 확인 (30% 가중치)
        required_check = self._check_required_fields(movie)
        validation_result['checks']['required_fields'] = required_check
        
        # 2. 데이터 타입 검증 (25% 가중치)
        type_check = self._check_field_types(movie)
        validation_result['checks']['field_types'] = type_check
        
        # 3. 값 범위 검증 (20% 가중치)
        range_check = self._check_field_ranges(movie)
        validation_result['checks']['field_ranges'] = range_check
        
        # 4. 패턴 검증 (10% 가중치)
        pattern_check = self._check_field_patterns(movie)
        validation_result['checks']['field_patterns'] = pattern_check
        
        # 5. 비즈니스 로직 검증 (15% 가중치)
        business_check = self._check_business_logic(movie)
        validation_result['checks']['business_logic'] = business_check
        
        # 6. 전체 점수 계산 (70점 이상 통과)
        validation_result['overall_score'] = self._calculate_quality_score(validation_result['checks'])
        
        # 7. 통과/실패 판정
        is_valid = validation_result['overall_score'] >= 70
        
        return is_valid, "Valid" if is_valid else f"Quality score too low: {validation_result['overall_score']}", validation_result
```

### 실제 구현된 테스트 시스템 🆕

#### **단일 영화 검증 테스트**
```bash
# 실제 구현된 품질 검증 테스트
docker exec -it mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator

# 테스트 데이터 준비
test_movie_good = {
    'id': 12345,
    'title': '테스트 영화',
    'release_date': '2023-05-15',
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': '좋은 영화입니다.',
    'adult': False,
    'vote_count': 1000
}

validator = DataQualityValidator()
is_valid, message, details = validator.validate_single_movie(test_movie_good)
print(f'결과: {"\u2705 통과" if is_valid else "\u274c 실패"}')
print(f'점수: {details["overall_score"]}/100')
"
```

---

## ✅ 완료 기준

### 1.5.1 기능적 완료 기준
- [ ] 실시간 품질 검증 시스템 구현 완료
- [ ] 필드별 검증 규칙 정상 작동
- [ ] 배치 품질 분석 자동 실행
- [ ] 통계적 이상 탐지 시스템 동작
- [ ] 일간 품질 리포트 자동 생성

### 1.5.2 기술적 완료 기준
- [ ] 품질 점수 계산 알고리즘 검증
- [ ] 이상 탐지 알고리즘 정확도 확인
- [ ] 자동 데이터 정제 기능 작동
- [ ] 품질 개선 액션 시스템 구현
- [ ] 메타데이터 관리 시스템 통합

### 1.5.3 운영적 완료 기준
- [ ] 품질 임계값 기반 알림 시스템
- [ ] 품질 추세 분석 및 시각화
- [ ] 품질 리포트 자동 배포
- [ ] 데이터 품질 SLA 모니터링
- [ ] 품질 개선 권장사항 자동 생성

---

## 🚀 다음 단계 준비

### 1.7 로깅 시스템과 통합
- 품질 검증 결과를 로깅 시스템에 통합
- 품질 이벤트 기반 알림 시스템 구축
- 품질 지표 실시간 모니터링

### 2단계 피처 스토어 연계
- 검증된 고품질 데이터만 피처 스토어로 전달
- 품질 메타데이터를 피처와 함께 저장
- 품질 기반 피처 선택 전략 수립

**🎯 목표 달성**: 신뢰할 수 있는 데이터 품질 보장 시스템 구축 완료!

**다음 단계**: 1.7 로깅 시스템 구축으로 종합적인 운영 가시성 확보
