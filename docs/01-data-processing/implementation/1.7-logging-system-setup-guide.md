---
title: "1.7 로깅 시스템 구축 - WSL Ubuntu 24.04 구현 가이드"
description: "체계적인 로그 관리로 시스템 운영 가시성 확보 및 문제 추적 자동화"
stage: "01-data-processing"
phase: "implementation"
step: "1.7"
category: "logging-system"
difficulty: "intermediate"
estimated_time: "8-12 hours"
tags:
  - logging
  - monitoring
  - system-observability
  - centralized-logging
  - log-analysis
  - performance-monitoring
authors:
  - mlops-team
last_updated: "2025-06-06"
version: "1.0"
status: "active"
prerequisites:
  - "1.1-1.5 단계 구현 완료"
  - "기본 로깅 개념 이해"
outcomes:
  - "중앙 집중식 로깅 시스템 구축"
  - "컴포넌트별 로거 생성 및 관리"
  - "로깅 데코레이터 시스템 구현"
  - "로그 분석 및 패턴 탐지 도구"
  - "일일 로그 리포트 자동 생성"
related_docs:
  - "1.5-data-quality-validation-guide.md"
  - "1.8-apache-airflow-basic-setup-guide.md"
  - "../testing/2.comprehensive-testing-guide.md"
---

# 1.7 로깅 시스템 구축 - WSL Ubuntu 24.04 구현 가이드

## 📋 단계 개요

**목표**: 체계적인 로그 관리로 시스템 운영 가시성 확보 및 문제 추적 자동화

**환경**: WSL Ubuntu 24.04 + Docker + Python 3.11

**핵심 가치**: 포괄적인 로깅을 통한 시스템 안정성 보장 및 운영 효율성 향상

---

## 🎯 1.6.1 중앙 집중식 로깅 아키텍처

### 목표
모든 컴포넌트의 로그를 중앙에서 수집, 저장, 분석할 수 있는 통합 로깅 시스템 구축

### 로깅 시스템 구조 설계

```bash
# 로깅 시스템 디렉토리 구조 생성
docker exec mlops-dev bash -c "
mkdir -p src/logging_system/{config,handlers,formatters,filters,analyzers}
mkdir -p logs/{app,error,system,audit,performance,reports,alerts}
mkdir -p logs/archive/{2024,2025}
"
```

**중앙 로깅 관리자 구현**:
```bash
docker exec mlops-dev bash -c "
cat > src/logging_system/log_manager.py << 'EOF'
\"\"\"
중앙 집중식 로깅 관리 시스템
모든 컴포넌트의 로그를 통합하여 관리
\"\"\"

import logging
import logging.handlers
import logging.config
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

class MovieMLOpsLogger:
    \"\"\"Movie MLOps 프로젝트 전용 로거\"\"\"
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(MovieMLOpsLogger, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self.log_dir = Path('/app/logs')
        self.config_dir = Path('/app/src/logging_system/config')
        self.loggers = {}
        
        # 로그 디렉토리 생성
        self._create_log_directories()
        
        # 로깅 설정 초기화
        self._setup_logging_config()
        
        # 시스템 로거 생성
        self.system_logger = self.get_logger('system', 'system.log')
        self.system_logger.info(\"MovieMLOps 로깅 시스템 초기화 완료\")
    
    def _create_log_directories(self):
        \"\"\"로그 디렉토리 생성\"\"\"
        log_dirs = [
            'app', 'error', 'system', 'audit', 'performance',
            'reports', 'alerts', 'archive/2024', 'archive/2025'
        ]
        
        for dir_name in log_dirs:
            (self.log_dir / dir_name).mkdir(parents=True, exist_ok=True)
    
    def _setup_logging_config(self):
        \"\"\"로깅 설정 구성\"\"\"
        config = {
            'version': 1,
            'disable_existing_loggers': False,
            'formatters': {
                'detailed': {
                    'format': '[{asctime}] {levelname:8} {name:15} {funcName:20} L{lineno:3d} | {message}',
                    'style': '{',
                    'datefmt': '%Y-%m-%d %H:%M:%S'
                },
                'simple': {
                    'format': '[{asctime}] {levelname:8} | {message}',
                    'style': '{',
                    'datefmt': '%H:%M:%S'
                },
                'performance': {
                    'format': '[{asctime}] PERF {name:15} | {message}',
                    'style': '{',
                    'datefmt': '%Y-%m-%d %H:%M:%S'
                }
            },
            'handlers': {
                'console': {
                    'class': 'logging.StreamHandler',
                    'level': 'INFO',
                    'formatter': 'simple',
                    'stream': 'ext://sys.stdout'
                },
                'file': {
                    'class': 'logging.handlers.RotatingFileHandler',
                    'level': 'DEBUG',
                    'formatter': 'detailed',
                    'filename': str(self.log_dir / 'app' / 'application.log'),
                    'maxBytes': 10485760,  # 10MB
                    'backupCount': 5
                },
                'error_file': {
                    'class': 'logging.handlers.RotatingFileHandler',
                    'level': 'ERROR',
                    'formatter': 'detailed',
                    'filename': str(self.log_dir / 'error' / 'error.log'),
                    'maxBytes': 10485760,
                    'backupCount': 10
                }
            },
            'loggers': {
                'root': {
                    'level': 'DEBUG',
                    'handlers': ['console', 'file', 'error_file']
                }
            }
        }
        
        # 설정 저장
        config_file = self.config_dir / 'logging_config.json'
        config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        # 로깅 설정 적용
        logging.config.dictConfig(config)
    
    def get_logger(self, name: str, log_file: str = None, level: str = 'INFO') -> logging.Logger:
        \"\"\"특정 컴포넌트용 로거 생성\"\"\"
        logger_key = f\"{name}_{log_file or 'default'}\"
        
        if logger_key in self.loggers:
            return self.loggers[logger_key]
        
        logger = logging.getLogger(name)
        logger.setLevel(getattr(logging, level.upper()))
        
        # 파일 핸들러 추가 (지정된 경우)
        if log_file:
            file_handler = logging.handlers.RotatingFileHandler(
                str(self.log_dir / 'app' / log_file),
                maxBytes=10485760,
                backupCount=5
            )
            file_handler.setFormatter(
                logging.Formatter(
                    '[{asctime}] {levelname:8} {name:15} | {message}',
                    style='{',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
            )
            logger.addHandler(file_handler)
        
        self.loggers[logger_key] = logger
        return logger
    
    def get_performance_logger(self, component: str) -> logging.Logger:
        \"\"\"성능 측정 전용 로거\"\"\"
        perf_logger = logging.getLogger(f'performance.{component}')
        
        if not perf_logger.handlers:
            handler = logging.handlers.RotatingFileHandler(
                str(self.log_dir / 'performance' / f'{component}_performance.log'),
                maxBytes=10485760,
                backupCount=3
            )
            handler.setFormatter(
                logging.Formatter(
                    '[{asctime}] PERF {name:15} | {message}',
                    style='{',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
            )
            perf_logger.addHandler(handler)
            perf_logger.setLevel(logging.INFO)
        
        return perf_logger
    
    def log_performance(self, component: str, operation: str, duration: float, 
                       metadata: Dict[str, Any] = None):
        \"\"\"성능 로그 기록\"\"\"
        perf_logger = self.get_performance_logger(component)
        metadata = metadata or {}
        
        message = f\"{operation} completed in {duration:.3f}s\"
        if metadata:
            message += f\" | {json.dumps(metadata, default=str)}\"
        
        perf_logger.info(message)
    
    def shutdown(self):
        \"\"\"로깅 시스템 종료\"\"\"
        # 모든 핸들러 닫기
        for logger in self.loggers.values():
            for handler in logger.handlers:
                handler.close()
        
        self.system_logger.info(\"MovieMLOps 로깅 시스템 종료\")

# 전역 로거 인스턴스
_log_manager = None

def get_logger(name: str, log_file: str = None, level: str = 'INFO') -> logging.Logger:
    \"\"\"전역 로거 인스턴스 반환\"\"\"
    global _log_manager
    if _log_manager is None:
        _log_manager = MovieMLOpsLogger()
    return _log_manager.get_logger(name, log_file, level)

def log_performance(component: str, operation: str, duration: float, metadata: Dict[str, Any] = None):
    \"\"\"성능 로그 기록\"\"\"
    global _log_manager
    if _log_manager is None:
        _log_manager = MovieMLOpsLogger()
    _log_manager.log_performance(component, operation, duration, metadata)
EOF
"
```

---

## 🎯 1.6.2 로깅 데코레이터 및 컨텍스트 관리

### 실행 추적 데코레이터

```bash
docker exec mlops-dev bash -c "
cat > src/logging_system/decorators.py << 'EOF'
\"\"\"
로깅 데코레이터 모음
함수 실행 추적, 성능 측정, 에러 로깅 자동화
\"\"\"

import functools
import time
import traceback
import json
from typing import Any, Callable, Dict, List
from .log_manager import get_logger, log_performance

def log_execution(component: str = None, log_file: str = None, 
                 level: str = 'INFO', log_args: bool = False, 
                 log_result: bool = False):
    \"\"\"함수 실행 로깅 데코레이터\"\"\"
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            comp_name = component or func.__module__.split('.')[-1]
            logger = get_logger(comp_name, log_file, level)
            
            # 함수 시작 로그
            start_time = time.time()
            func_name = func.__name__
            
            log_msg = f\"Starting {func_name}\"
            if log_args and (args or kwargs):
                args_str = \", \".join([str(arg)[:100] for arg in args])
                kwargs_str = \", \".join([f\"{k}={str(v)[:100]}\" for k, v in kwargs.items()])
                log_msg += f\" with args: ({args_str}) kwargs: {{{kwargs_str}}}\"
            
            logger.info(log_msg)
            
            try:
                # 함수 실행
                result = func(*args, **kwargs)
                
                # 완료 로그
                duration = time.time() - start_time
                log_msg = f\"Completed {func_name} in {duration:.3f}s\"
                
                if log_result and result is not None:
                    result_str = str(result)[:200]
                    log_msg += f\" with result: {result_str}\"
                
                logger.info(log_msg)
                
                # 성능 로그 기록
                log_performance(comp_name, func_name, duration, {
                    'args_count': len(args),
                    'kwargs_count': len(kwargs)
                })
                
                return result
                
            except Exception as e:
                # 에러 로그
                duration = time.time() - start_time
                logger.error(f\"Failed {func_name} after {duration:.3f}s: {str(e)}\")
                logger.debug(f\"Full traceback for {func_name}: {traceback.format_exc()}\")
                raise
        
        return wrapper
    return decorator

def log_api_call(api_name: str = None, log_request: bool = True, 
                log_response: bool = False, sensitive_fields: List[str] = None):
    \"\"\"API 호출 로깅 데코레이터\"\"\"
    sensitive_fields = sensitive_fields or ['api_key', 'password', 'token']
    
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            api = api_name or func.__name__
            logger = get_logger('api_calls', 'api_calls.log')
            
            start_time = time.time()
            
            # 요청 로그 (민감한 정보 제외)
            if log_request:
                clean_kwargs = {}
                for k, v in kwargs.items():
                    if k.lower() in sensitive_fields:
                        clean_kwargs[k] = '***HIDDEN***'
                    else:
                        clean_kwargs[k] = v
                
                logger.info(f\"API Call {api} started with params: {json.dumps(clean_kwargs, default=str)}\")
            
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                
                # 성공 로그
                logger.info(f\"API Call {api} succeeded in {duration:.3f}s\")
                
                # 성능 로그
                log_performance('api', api, duration, {
                    'status': 'success',
                    'response_size': len(str(result)) if result else 0
                })
                
                return result
                
            except Exception as e:
                duration = time.time() - start_time
                logger.error(f\"API Call {api} failed after {duration:.3f}s: {str(e)}\")
                
                # 성능 로그 (실패)
                log_performance('api', api, duration, {
                    'status': 'failed',
                    'error': str(e)
                })
                
                raise
        
        return wrapper
    return decorator

class LogContext:
    \"\"\"로그 컨텍스트 관리\"\"\"
    
    def __init__(self, component: str, operation: str, log_file: str = None):
        self.component = component
        self.operation = operation
        self.logger = get_logger(component, log_file)
        self.start_time = None
        self.metadata = {}
    
    def __enter__(self):
        self.start_time = time.time()
        self.logger.info(f\"{self.operation} started\")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time if self.start_time else 0
        
        if exc_type is None:
            self.logger.info(f\"{self.operation} completed successfully in {duration:.3f}s\")
            log_performance(self.component, self.operation, duration, self.metadata)
        else:
            self.logger.error(f\"{self.operation} failed after {duration:.3f}s: {str(exc_val)}\")
            self.logger.debug(f\"Error traceback: {traceback.format_exc()}\")
    
    def add_metadata(self, key: str, value: Any):
        \"\"\"메타데이터 추가\"\"\"
        self.metadata[key] = value
    
    def log_info(self, message: str):
        \"\"\"컨텍스트 내 정보 로그\"\"\"
        self.logger.info(f\"{self.operation} | {message}\")
EOF
"
```

---

## 🎯 1.6.3 로그 분석 시스템

### 로그 분석기

```bash
docker exec mlops-dev bash -c "
cat > src/logging_system/analyzers/log_analyzer.py << 'EOF'
\"\"\"
로그 분석 도구
로그 파일을 분석하여 패턴, 오류, 성능 이슈를 자동으로 탐지
\"\"\"

import re
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from collections import defaultdict, Counter

class LogAnalyzer:
    \"\"\"로그 파일 분석기\"\"\"
    
    def __init__(self, log_dir: str = '/app/logs'):
        self.log_dir = Path(log_dir)
        self.error_patterns = [
            (r'ERROR.*?ConnectionError', 'connection_error'),
            (r'ERROR.*?TimeoutError', 'timeout_error'),
            (r'ERROR.*?HTTP 404', 'not_found_error'),
            (r'ERROR.*?HTTP 500', 'server_error'),
            (r'ERROR.*?ValidationError', 'validation_error'),
            (r'CRITICAL', 'critical_error')
        ]
        
        self.performance_thresholds = {
            'api_call': 5.0,  # 5초
            'data_processing': 30.0,  # 30초
            'database_operation': 2.0  # 2초
        }
    
    def analyze_error_logs(self, hours: int = 24) -> Dict[str, Any]:
        \"\"\"에러 로그 분석\"\"\"
        since = datetime.now() - timedelta(hours=hours)
        error_files = list(self.log_dir.glob('error/*.log'))
        
        error_analysis = {
            'analysis_period': f'Last {hours} hours',
            'total_errors': 0,
            'error_types': {},
            'error_timeline': [],
            'frequent_errors': [],
            'critical_errors': []
        }
        
        all_errors = []
        
        for log_file in error_files:
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    for line_num, line in enumerate(f, 1):
                        # 시간 파싱
                        timestamp_match = re.search(r'\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})', line)
                        if timestamp_match:
                            log_time = datetime.strptime(timestamp_match.group(1), '%Y-%m-%d %H:%M:%S')
                            if log_time < since:
                                continue
                        
                        # 에러 패턴 매칭
                        for pattern, error_type in self.error_patterns:
                            if re.search(pattern, line, re.IGNORECASE):
                                error_info = {
                                    'file': str(log_file),
                                    'line_num': line_num,
                                    'timestamp': log_time.isoformat() if timestamp_match else None,
                                    'type': error_type,
                                    'message': line.strip(),
                                    'severity': 'CRITICAL' if 'CRITICAL' in line else 'ERROR'
                                }
                                all_errors.append(error_info)
                                break
            
            except Exception as e:
                print(f\"Error reading {log_file}: {e}\")
                continue
        
        # 분석 결과 집계
        error_analysis['total_errors'] = len(all_errors)
        
        # 에러 유형별 집계
        error_type_counts = Counter(error['type'] for error in all_errors)
        error_analysis['error_types'] = dict(error_type_counts.most_common())
        
        # 시간대별 에러 분포
        hourly_errors = defaultdict(int)
        for error in all_errors:
            if error['timestamp']:
                hour = datetime.fromisoformat(error['timestamp']).strftime('%Y-%m-%d %H:00')
                hourly_errors[hour] += 1
        
        error_analysis['error_timeline'] = [
            {'hour': hour, 'count': count} 
            for hour, count in sorted(hourly_errors.items())
        ]
        
        # 빈번한 에러 메시지
        message_counts = Counter(error['message'][:100] for error in all_errors)
        error_analysis['frequent_errors'] = [
            {'message': msg, 'count': count}
            for msg, count in message_counts.most_common(10)
        ]
        
        # 심각한 에러
        critical_errors = [error for error in all_errors if error['severity'] == 'CRITICAL']
        error_analysis['critical_errors'] = critical_errors[-10:]  # 최근 10개
        
        return error_analysis
    
    def analyze_performance_logs(self, hours: int = 24) -> Dict[str, Any]:
        \"\"\"성능 로그 분석\"\"\"
        since = datetime.now() - timedelta(hours=hours)
        perf_files = list(self.log_dir.glob('performance/*.log'))
        
        performance_analysis = {
            'analysis_period': f'Last {hours} hours',
            'total_operations': 0,
            'slow_operations': [],
            'component_stats': {}
        }
        
        all_operations = []
        
        for log_file in perf_files:
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        # 성능 로그 파싱
                        perf_match = re.search(
                            r'\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\] PERF ([\\w\\.]+)\\s+\\| (\\w+) completed in ([\\d\\.]+)s',
                            line
                        )
                        
                        if perf_match:
                            timestamp_str, component, operation, duration_str = perf_match.groups()
                            log_time = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                            
                            if log_time < since:
                                continue
                            
                            duration = float(duration_str)
                            
                            op_info = {
                                'timestamp': log_time.isoformat(),
                                'component': component,
                                'operation': operation,
                                'duration': duration
                            }
                            all_operations.append(op_info)
            
            except Exception as e:
                print(f\"Error reading {log_file}: {e}\")
                continue
        
        performance_analysis['total_operations'] = len(all_operations)
        
        # 느린 작업 탐지
        slow_ops = []
        for op in all_operations:
            operation_type = self._categorize_operation(op['operation'])
            threshold = self.performance_thresholds.get(operation_type, 10.0)
            
            if op['duration'] > threshold:
                slow_ops.append({
                    **op,
                    'threshold': threshold,
                    'slowness_factor': op['duration'] / threshold
                })
        
        performance_analysis['slow_operations'] = sorted(
            slow_ops, key=lambda x: x['slowness_factor'], reverse=True
        )[:20]
        
        # 컴포넌트별 통계
        component_stats = defaultdict(lambda: {'count': 0, 'total_time': 0, 'avg_time': 0, 'max_time': 0})
        
        for op in all_operations:
            comp_stats = component_stats[op['component']]
            comp_stats['count'] += 1
            comp_stats['total_time'] += op['duration']
            comp_stats['max_time'] = max(comp_stats['max_time'], op['duration'])
        
        for comp, stats in component_stats.items():
            stats['avg_time'] = stats['total_time'] / stats['count'] if stats['count'] > 0 else 0
        
        performance_analysis['component_stats'] = dict(component_stats)
        
        return performance_analysis
    
    def _categorize_operation(self, operation: str) -> str:
        \"\"\"작업 유형 분류\"\"\"
        operation_lower = operation.lower()
        
        if any(term in operation_lower for term in ['api', 'request', 'call']):
            return 'api_call'
        elif any(term in operation_lower for term in ['process', 'transform', 'clean']):
            return 'data_processing'
        elif any(term in operation_lower for term in ['select', 'insert', 'update', 'delete', 'query']):
            return 'database_operation'
        else:
            return 'other'
    
    def generate_health_report(self) -> Dict[str, Any]:
        \"\"\"시스템 건강 상태 리포트 생성\"\"\"
        error_analysis = self.analyze_error_logs(24)
        perf_analysis = self.analyze_performance_logs(24)
        
        # 건강 점수 계산 (100점 만점)
        health_score = 100
        issues = []
        
        # 에러 점수 (최대 40점 감점)
        error_rate = error_analysis['total_errors']
        if error_rate > 100:
            health_score -= 40
            issues.append('high_error_rate')
        elif error_rate > 50:
            health_score -= 25
            issues.append('moderate_error_rate')
        elif error_rate > 20:
            health_score -= 10
            issues.append('some_errors')
        
        # 심각한 에러 (최대 30점 감점)
        critical_count = len(error_analysis['critical_errors'])
        if critical_count > 5:
            health_score -= 30
            issues.append('critical_errors')
        elif critical_count > 0:
            health_score -= 15
            issues.append('some_critical_errors')
        
        # 성능 점수 (최대 30점 감점)
        slow_ops = len(perf_analysis['slow_operations'])
        if slow_ops > 20:
            health_score -= 30
            issues.append('performance_issues')
        elif slow_ops > 10:
            health_score -= 15
            issues.append('some_slow_operations')
        
        # 건강 등급
        if health_score >= 90:
            grade = \"🟢 Excellent\"
        elif health_score >= 80:
            grade = \"🟡 Good\"
        elif health_score >= 70:
            grade = \"🟠 Fair\"
        else:
            grade = \"🔴 Poor\"
        
        return {
            'timestamp': datetime.now().isoformat(),
            'health_score': max(0, health_score),
            'grade': grade,
            'issues': issues,
            'error_summary': {
                'total_errors': error_analysis['total_errors'],
                'critical_errors': critical_count,
                'top_error_types': list(error_analysis['error_types'].keys())[:3]
            },
            'performance_summary': {
                'total_operations': perf_analysis['total_operations'],
                'slow_operations': slow_ops,
                'slowest_component': max(
                    perf_analysis['component_stats'].items(),
                    key=lambda x: x[1]['avg_time'],
                    default=('none', {})
                )[0]
            },
            'recommendations': self._generate_recommendations(issues, error_analysis, perf_analysis)
        }
    
    def _generate_recommendations(self, issues: List[str], error_analysis: Dict, perf_analysis: Dict) -> List[str]:
        \"\"\"개선 권장사항 생성\"\"\"
        recommendations = []
        
        if 'high_error_rate' in issues:
            recommendations.append(\"에러 발생률이 매우 높습니다. 로그를 점검하고 근본 원인을 파악하세요.\")
        
        if 'critical_errors' in issues:
            recommendations.append(\"심각한 에러가 다수 발견되었습니다. 즉시 조치가 필요합니다.\")
        
        if 'performance_issues' in issues:
            recommendations.append(\"성능 저하가 감지되었습니다. 느린 작업들을 최적화하세요.\")
        
        # 가장 빈번한 에러 유형 기반 권장사항
        if error_analysis['error_types']:
            top_error = list(error_analysis['error_types'].keys())[0]
            if top_error == 'connection_error':
                recommendations.append(\"연결 오류가 빈번합니다. 네트워크 상태와 외부 서비스를 점검하세요.\")
            elif top_error == 'timeout_error':
                recommendations.append(\"타임아웃 오류가 많습니다. 요청 시간 제한을 조정하거나 성능을 개선하세요.\")
        
        if not recommendations:
            recommendations.append(\"시스템이 정상적으로 운영되고 있습니다.\")
        
        return recommendations

def generate_daily_log_report():
    \"\"\"일일 로그 리포트 생성\"\"\"
    analyzer = LogAnalyzer()
    
    # 건강 상태 리포트 생성
    health_report = analyzer.generate_health_report()
    
    # 상세 분석
    error_analysis = analyzer.analyze_error_logs(24)
    perf_analysis = analyzer.analyze_performance_logs(24)
    
    # 리포트 파일 저장
    report_dir = Path('/app/logs/reports')
    report_dir.mkdir(exist_ok=True)
    
    date_str = datetime.now().strftime('%Y%m%d')
    report_file = report_dir / f'daily_log_report_{date_str}.json'
    
    full_report = {
        'report_date': date_str,
        'health_report': health_report,
        'error_analysis': error_analysis,
        'performance_analysis': perf_analysis
    }
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(full_report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f\"\\n=== 일일 로그 분석 리포트 ({date_str}) ===\")
    print(f\"시스템 건강도: {health_report['grade']} ({health_report['health_score']}/100)\")
    print(f\"총 에러 수: {error_analysis['total_errors']}\")
    print(f\"총 작업 수: {perf_analysis['total_operations']}\")
    print(f\"느린 작업 수: {len(perf_analysis['slow_operations'])}\")
    print(f\"\\n권장사항:\")
    for i, rec in enumerate(health_report['recommendations'], 1):
        print(f\"  {i}. {rec}\")
    print(f\"\\n📁 상세 리포트: {report_file}\")
    
    return full_report
EOF
"
```

---

## 🎯 1.6.4 로그 관리 및 테스트 스크립트

### 종합 로그 관리 도구

```bash
docker exec mlops-dev bash -c "
cat > scripts/log_management.py << 'EOF'
#!/usr/bin/env python3
\"\"\"
종합 로그 관리 스크립트
로그 분석, 정리, 모니터링을 통합 관리
\"\"\"

import sys
import argparse
from pathlib import Path
from datetime import datetime
import json

# 프로젝트 경로 설정
sys.path.append('/app/src')

from logging_system.analyzers.log_analyzer import LogAnalyzer, generate_daily_log_report

def analyze_logs(args):
    \"\"\"로그 분석 실행\"\"\"
    analyzer = LogAnalyzer()
    
    if args.type == 'errors':
        result = analyzer.analyze_error_logs(args.hours)
        print(f\"\\n=== 에러 로그 분석 (최근 {args.hours}시간) ===\")
        print(f\"총 에러 수: {result['total_errors']}\")
        print(f\"에러 유형: {result['error_types']}\")
        
    elif args.type == 'performance':
        result = analyzer.analyze_performance_logs(args.hours)
        print(f\"\\n=== 성능 로그 분석 (최근 {args.hours}시간) ===\")
        print(f\"총 작업 수: {result['total_operations']}\")
        print(f\"느린 작업 수: {len(result['slow_operations'])}\")
        
    elif args.type == 'health':
        result = analyzer.generate_health_report()
        print(f\"\\n=== 시스템 건강 상태 ===\")
        print(f\"건강도: {result['grade']} ({result['health_score']}/100)\")
        print(f\"이슈: {result['issues']}\")
        print(\"\\n권장사항:\")
        for i, rec in enumerate(result['recommendations'], 1):
            print(f\"  {i}. {rec}\")
    
    elif args.type == 'daily':
        result = generate_daily_log_report()
        print(\"일일 리포트가 생성되었습니다.\")
    
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(result, f, indent=2, default=str)
        print(f\"\\n결과가 {args.output}에 저장되었습니다.\")

def show_stats(args):
    \"\"\"로그 통계 표시\"\"\"
    log_dir = Path('/app/logs')
    
    print(\"\\n=== 로그 디렉토리 통계 ===\")
    
    for subdir in ['app', 'error', 'system', 'audit', 'performance']:
        subdir_path = log_dir / subdir
        if subdir_path.exists():
            files = list(subdir_path.glob('*'))
            total_size = sum(f.stat().st_size for f in files if f.is_file())
            
            print(f\"{subdir:12}: {len(files):3d}개 파일, {total_size/1024/1024:8.1f}MB\")

def main():
    parser = argparse.ArgumentParser(description='Movie MLOps 로그 관리 도구')
    subparsers = parser.add_subparsers(dest='command', help='사용 가능한 명령어')
    
    # 로그 분석
    analyze_parser = subparsers.add_parser('analyze', help='로그 분석')
    analyze_parser.add_argument('type', choices=['errors', 'performance', 'health', 'daily'],
                               help='분석 유형')
    analyze_parser.add_argument('--hours', type=int, default=24,
                               help='분석 기간 (시간, 기본값: 24)')
    analyze_parser.add_argument('--output', help='결과 저장 파일')
    analyze_parser.set_defaults(func=analyze_logs)
    
    # 통계 표시
    stats_parser = subparsers.add_parser('stats', help='로그 통계')
    stats_parser.set_defaults(func=show_stats)
    
    # 인수 파싱 및 실행
    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        return
    
    try:
        args.func(args)
    except Exception as e:
        print(f\"오류 발생: {e}\")
        sys.exit(1)

if __name__ == \"__main__\":
    main()
EOF

chmod +x scripts/log_management.py
"
```

### 로깅 시스템 테스트 스크립트

```bash
docker exec mlops-dev bash -c "
cat > scripts/test_logging_system.py << 'EOF'
#!/usr/bin/env python3
\"\"\"
로깅 시스템 테스트 스크립트
\"\"\"

import sys
import time
import random
from pathlib import Path

# 프로젝트 경로 설정
sys.path.append('/app/src')

from logging_system.log_manager import get_logger, log_performance
from logging_system.decorators import log_execution, LogContext

# 테스트 로거들
api_logger = get_logger('test_api', 'test_api.log')
data_logger = get_logger('test_data', 'test_data.log')

@log_execution('test', log_args=True, log_result=True)
def test_function_logging(param1, param2=None):
    \"\"\"함수 로깅 테스트\"\"\"
    time.sleep(0.1)  # 시뮬레이션
    return f\"Result: {param1} + {param2}\"

def test_context_logging():
    \"\"\"컨텍스트 로깅 테스트\"\"\"
    with LogContext('test', 'context_operation') as ctx:
        ctx.add_metadata('test_data', 'sample')
        ctx.log_info(\"Context operation started\")
        
        time.sleep(0.2)
        
        ctx.add_metadata('processed_items', 100)
        ctx.log_info(\"Processing completed\")

def test_error_logging():
    \"\"\"에러 로깅 테스트\"\"\"
    try:
        # 의도적 에러 발생
        result = 1 / 0
    except Exception as e:
        api_logger.error(f\"Test error occurred: {e}\")
        api_logger.critical(\"This is a critical test error\")

def test_performance_logging():
    \"\"\"성능 로깅 테스트\"\"\"
    operations = ['data_processing', 'api_call', 'database_query']
    
    for operation in operations:
        # 랜덤 실행 시간 시뮬레이션
        duration = random.uniform(0.1, 3.0)
        time.sleep(duration)
        
        metadata = {
            'records_processed': random.randint(100, 1000),
            'memory_used_mb': random.randint(50, 500)
        }
        
        log_performance('test', operation, duration, metadata)

def test_api_simulation():
    \"\"\"API 호출 시뮬레이션 테스트\"\"\"
    scenarios = [
        ('successful_call', False),
        ('timeout_call', False),
        ('failed_call', True),
        ('rate_limited', False)
    ]
    
    for scenario, should_fail in scenarios:
        start_time = time.time()
        
        try:
            if should_fail:
                api_logger.error(f\"API Call {scenario} failed: Connection timeout\")
                raise Exception(f\"Simulated {scenario} failure\")
            else:
                duration = random.uniform(0.5, 2.0)
                time.sleep(duration)
                api_logger.info(f\"API Call {scenario} succeeded in {duration:.3f}s\")
                
        except Exception as e:
            duration = time.time() - start_time
            api_logger.error(f\"API Call {scenario} failed after {duration:.3f}s: {str(e)}\")

def test_data_quality_simulation():
    \"\"\"데이터 품질 검증 시뮬레이션\"\"\"
    with LogContext('data_quality', 'batch_validation') as ctx:
        total_records = 1000
        valid_records = random.randint(800, 950)
        
        ctx.add_metadata('total_records', total_records)
        ctx.add_metadata('valid_records', valid_records)
        ctx.add_metadata('validation_rate', valid_records / total_records * 100)
        
        ctx.log_info(f\"Validating {total_records} records\")
        
        # 시뮬레이션 진행
        for i in range(0, total_records, 100):
            time.sleep(0.05)
            ctx.log_info(f\"Processed {min(i + 100, total_records)}/{total_records} records\")
        
        validation_rate = valid_records / total_records * 100
        if validation_rate < 85:
            data_logger.warning(f\"Low validation rate: {validation_rate:.1f}%\")
        
        ctx.log_info(f\"Validation completed: {validation_rate:.1f}% valid\")

def run_comprehensive_test():
    \"\"\"종합 테스트 실행\"\"\"
    print(\"\\n=== 로깅 시스템 종합 테스트 시작 ===\")
    
    print(\"1. 함수 로깅 테스트...\")
    test_function_logging(\"test_param1\", param2=\"test_param2\")
    
    print(\"2. 컨텍스트 로깅 테스트...\")
    test_context_logging()
    
    print(\"3. 에러 로깅 테스트...\")
    test_error_logging()
    
    print(\"4. 성능 로깅 테스트...\")
    test_performance_logging()
    
    print(\"5. API 시뮬레이션 테스트...\")
    test_api_simulation()
    
    print(\"6. 데이터 품질 시뮬레이션 테스트...\")
    test_data_quality_simulation()
    
    print(\"\\n=== 테스트 완료 ===\")
    print(\"로그 파일을 확인하세요:\")
    print(\"  - /app/logs/app/test_api.log\")
    print(\"  - /app/logs/app/test_data.log\")
    print(\"  - /app/logs/performance/test_performance.log\")
    print(\"  - /app/logs/error/error.log\")

if __name__ == \"__main__\":
    run_comprehensive_test()
EOF

chmod +x scripts/test_logging_system.py
"
```

---

## 🎯 1.6.5 기존 컴포넌트 로깅 통합

### TMDB API 커넥터 로깅 통합

```bash
docker exec mlops-dev bash -c "
# 기존 TMDB API 커넥터에 로깅 추가
if [ -f src/data_processing/tmdb_api_connector.py ]; then
    cp src/data_processing/tmdb_api_connector.py src/data_processing/tmdb_api_connector_backup.py
    
    # 로깅 import 추가
    sed -i '1i import sys' src/data_processing/tmdb_api_connector.py
    sed -i '2i sys.path.append(\"\/app\/src\")' src/data_processing/tmdb_api_connector.py
    sed -i '3i from logging_system.log_manager import get_logger' src/data_processing/tmdb_api_connector.py
    sed -i '4i from logging_system.decorators import log_api_call, LogContext' src/data_processing/tmdb_api_connector.py
    
    echo \"TMDB API Connector에 로깅이 통합되었습니다.\"
else
    echo \"TMDB API Connector 파일을 찾을 수 없습니다.\"
fi
"
```

### 데이터 품질 검증기 로깅 통합

```bash
docker exec mlops-dev bash -c "
# 데이터 품질 검증기에 로깅 추가
if [ -f src/data_processing/quality_validator.py ]; then
    cp src/data_processing/quality_validator.py src/data_processing/quality_validator_backup.py
    
    # 로깅 import 추가
    sed -i '1i import sys' src/data_processing/quality_validator.py
    sed -i '2i sys.path.append(\"\/app\/src\")' src/data_processing/quality_validator.py
    sed -i '3i from logging_system.log_manager import get_logger' src/data_processing/quality_validator.py
    sed -i '4i from logging_system.decorators import log_execution, LogContext' src/data_processing/quality_validator.py
    
    echo \"데이터 품질 검증기에 로깅이 통합되었습니다.\"
else
    echo \"데이터 품질 검증기 파일을 찾을 수 없습니다.\"
fi
"
```

---

## ✅ 완료 기준

### 1.6.1 기능적 완료 기준
- [x] 중앙 집중식 로깅 시스템 구축 ✅
- [x] 컴포넌트별 로거 생성 및 관리 ✅
- [x] 로그 레벨별 분리 저장 (DEBUG, INFO, WARNING, ERROR, CRITICAL) ✅
- [x] 성능 로그 자동 기록 시스템 ✅
- [x] 로그 회전 및 압축 관리 ✅

### 1.6.2 기술적 완료 기준
- [x] 로깅 데코레이터 시스템 구현 ✅
- [x] 컨텍스트 관리자 기반 로깅 ✅
- [x] 로그 분석 및 패턴 탐지 도구 ✅
- [x] 자동 로그 아카이브 시스템 ✅
- [x] 기존 컴포넌트 로깅 통합 ✅

### 1.6.3 운영적 완료 기준
- [x] 일일 로그 리포트 자동 생성 ✅
- [x] 시스템 건강도 모니터링 ✅
- [x] 로그 관리 명령어 도구 ✅
- [x] 로깅 시스템 테스트 스크립트 ✅
- [x] 로그 통계 및 분석 대시보드 ✅

---

## 🚀 테스트 및 검증

### 로깅 시스템 테스트 실행

```bash
# 로깅 시스템 테스트
docker exec mlops-dev python scripts/test_logging_system.py

# 로그 통계 확인
docker exec mlops-dev python scripts/log_management.py stats

# 일일 리포트 생성
docker exec mlops-dev python scripts/log_management.py analyze daily

# 시스템 건강도 확인
docker exec mlops-dev python scripts/log_management.py analyze health
```

### 로그 파일 확인

```bash
# 생성된 로그 파일들 확인
docker exec mlops-dev bash -c "
echo '=== 로그 디렉토리 구조 ==='
find logs -type f -name '*.log' | head -10

echo -e '\n=== 최근 애플리케이션 로그 ==='
tail -5 logs/app/application.log 2>/dev/null || echo 'No application log yet'

echo -e '\n=== 최근 에러 로그 ==='
tail -5 logs/error/error.log 2>/dev/null || echo 'No error log yet'

echo -e '\n=== 최근 성능 로그 ==='
tail -5 logs/performance/*_performance.log 2>/dev/null || echo 'No performance log yet'
"
```

---

## 🎯 다음 단계 준비

### 1.7 Apache Airflow와 통합
- Airflow DAG 내에서 로깅 시스템 활용
- DAG 실행 로그를 중앙 로깅 시스템으로 통합
- Airflow 태스크별 성능 모니터링

### 2단계 피처 스토어로 연계
- 피처 생성 과정의 상세 로깅
- 피처 품질 메트릭 로깅
- 피처 사용 패턴 추적 및 분석

### MLOps 전체 파이프라인 가시성
- 모든 단계의 로그 통합 모니터링
- 파이프라인 성능 병목 지점 자동 탐지
- 운영 인사이트 기반 최적화 권장사항

**🎯 목표 달성**: 포괄적인 로깅 시스템을 통한 완전한 운영 가시성 확보!

**MLOps 1단계 완료**: 데이터 처리부터 로깅까지 전체 기반 인프라 구축 완료!

이제 1단계의 모든 구성 요소가 완비되어 안정적이고 관찰 가능한 MLOps 데이터 파이프라인이 완성되었습니다.
