# 📊 MLOps 구현 단계별 상세 분석 및 통합 계획

`mlops-cloud-project-mlops_11` 구현을 위한 **1, 2, 3, 7단계** 상세 분석입니다.

---

## 🎯 **1단계: 데이터 처리 및 분석 도구들**

### 📋 **이론적 프레임워크 요구사항**
- **Apache Airflow**: 워크플로우 관리 플랫폼
- **Apache Kafka**: 실시간 데이터 스트리밍
- **Python**: 데이터 과학 및 ML 스크립트
- **Apache Spark**: 분산 데이터 처리
- **목표**: 안정적인 데이터 파이프라인 구축

### ✅ **my-mlops에서 구현된 부분**

#### **TMDBCrawler 클래스** (`C:\dev\my-mlops\data-prepare\crawler.py`)
```python
class TMDBCrawler:
    def __init__(self, region="KR", language="ko-KR", image_language="ko", 
                 request_interval_seconds=0.4):
        self._base_url = os.environ.get("TMDB_BASE_URL")
        self._api_key = os.environ.get("TMDB_API_KEY")
        # ... 설정
    
    def get_popular_movies(self, page):
        # TMDB API 호출
    
    def get_bulk_popular_movies(self, start_page, end_page):
        # 페이지별 데이터 수집
    
    @staticmethod
    def save_movies_to_json_file(movies, dst="./result", filename="popular"):
        # JSON 형태로 저장
```

#### **핵심 기능들**
- ✅ **API 연동**: TMDB API 호출 및 데이터 수집
- ✅ **페이지네이션**: start_page ~ end_page 범위 처리
- ✅ **요청 제어**: 0.4초 간격으로 API 제한 준수
- ✅ **지역화**: 한국 지역(KR), 한국어(ko-KR) 설정
- ✅ **데이터 저장**: JSON 형태로 결과 저장
- ✅ **환경 변수**: .env 파일로 API 키 관리

### 🔄 **통합 계획**

#### **1-1. 파일 구조**
```
mlops-cloud-project-mlops_11/
├── src/
│   ├── data/
│   │   ├── crawlers/
│   │   │   ├── tmdb_crawler.py          # TMDBCrawler 이식
│   │   │   └── base_crawler.py          # 확장 가능한 베이스 클래스
│   │   ├── processors/
│   │   │   └── tmdb_processor.py        # TMDBPreProcessor 이식
│   │   ├── validators/
│   │   │   └── data_validator.py        # 데이터 검증
│   │   └── __init__.py
│   ├── config.py                        # 전역 설정
│   └── utils/
│       └── helpers.py                   # 유틸리티 함수
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── CardGrid.jsx             # 영화 포스터 그리드
│   │   │   └── MovieCard.jsx            # 개별 영화 카드
│   │   ├── services/
│   │   │   └── api.js                   # API 통신
│   │   └── App.jsx                      # 메인 애플리케이션
│   └── public/
│       └── poster/                      # 58개 영화 포스터
├── airflow/
│   ├── dags/
│   │   └── data_pipeline_dag.py         # 데이터 파이프라인 DAG
│   └── scripts/
│       └── init.sh                      # 초기화 스크립트
├── mlflow/
│   ├── models/                          # 저장된 모델
│   └── runs/                            # 실험 기록
├── docker/
│   ├── Dockerfile.api                   # API 서버용
│   └── Dockerfile.airflow               # Airflow용
├── k8s/
│   ├── dev-cluster-config.yaml          # 개발 환경
│   ├── staging-cluster-config.yaml      # 스테이징 환경
│   └── prod-cluster-config.yaml         # 프로덕션 환경
├── configs/
│   ├── development.yaml                 # 개발 설정
│   └── production.yaml                  # 프로덕션 설정
├── tests/
│   ├── unit/                            # 단위 테스트
│   └── integration/                     # 통합 테스트
├── notebooks/
│   └── data_exploration.ipynb           # 데이터 분석
├── scripts/
│   ├── setup.sh                         # 환경 설정
│   └── data_pipeline.py                 # 파이프라인 실행
├── data/
│   ├── raw/                             # 원본 데이터
│   └── processed/                       # 처리된 데이터
├── logs/                                # 로그 파일
├── models/                              # 모델 저장소
├── requirements.txt                     # Python 의존성
├── docker-compose.yml                   # Docker 환경
└── README.md                            # 프로젝트 가이드
```

#### **1-2. 확장 구현 사항**
- **로깅 시스템**: Python logging 모듈 추가
- **데이터 검증**: 수집된 데이터 품질 체크
- **에러 처리**: API 실패 시 재시도 로직
- **모니터링**: 수집 진행률 및 상태 추적

---

## 🎯 **2단계: 피처 스토어 및 ML 플랫폼**

### 📋 **이론적 프레임워크 요구사항**
- **Feast**: 오픈소스 피처 스토어
- **Hopsworks**: 엔터프라이즈급 ML 플랫폼
- **목표**: 재사용 가능한 피처 관리 체계 구축

### ✅ **my-mlops에서 구현된 부분**

#### **TMDBPreProcessor 클래스** (`C:\dev\my-mlops\data-prepare\preprocessing.py`)
```python
class TMDBPreProcessor:
    def __init__(self, movies: list, user_count=100, max_select_count=20):
        # 설정 초기화
    
    @staticmethod
    def augmentation(movie):
        # 영화 평점 기반 데이터 증강: pow(2, rating)
        
    def generate_watch_second(self, rating):
        # 평점 기반 시청 시간 생성 로직
        
    def selection(self, user_id, features):
        # 사용자별 영화 선택 시뮬레이션
        
    def run(self):
        # 전체 전처리 파이프라인 실행
        
    def plot(self):
        # rating vs watch_seconds 시각화
        
    def save(self, filename):
        # CSV 형태로 결과 저장
```

#### **핵심 피처 생성 로직**
- ✅ **데이터 증강**: `count = int(pow(2, rating))` - 평점 기반 가중치
- ✅ **시청 시간 생성**: 평점과 상관관계가 있는 시청 시간 알고리즘
- ✅ **사용자 시뮬레이션**: 100명 사용자, 최대 20개 영화 선택
- ✅ **피처 조합**: user_id, content_id, watch_seconds, rating, popularity
- ✅ **시각화**: rating과 watch_seconds 관계 그래프

### 🔄 **통합 계획**

#### **2-1. 파일 구조**
```
mlops-cloud-project-mlops_11/
├── src/
│   ├── features/
│   │   ├── engineering/
│   │   │   ├── movie_features.py        # 영화 관련 피처
│   │   │   ├── user_features.py         # 사용자 관련 피처  
│   │   │   └── interaction_features.py  # 상호작용 피처
│   │   ├── store/
│   │   │   ├── feature_store.py         # 간단한 피처 저장소
│   │   │   └── feature_registry.py      # 피처 메타데이터 관리
│   │   └── processors/
│   │       ├── tmdb_processor.py        # TMDBPreProcessor 이식
│   │       └── feature_pipeline.py     # 피처 파이프라인
├── configs/
│   └── feature_config.yaml              # 피처 설정
├── notebooks/
│   └── feature_analysis.ipynb           # 피처 분석
├── mlflow/
│   ├── experiments/                     # 실험 추적
│   └── artifacts/                       # 아티팩트 저장
└── tests/
    └── test_features/                   # 피처 테스트
```

#### **2-2. 확장 구현 사항**
- **피처 버전 관리**: 피처별 버전 추적
- **피처 유효성 검사**: 데이터 타입 및 범위 체크
- **피처 메타데이터**: 생성 시간, 설명, 데이터 타입 등
- **간단한 피처 스토어**: CSV/Parquet 기반 로컬 저장소

---

## 🎯 **3단계: 버전 관리 시스템**

### 📋 **이론적 프레임워크 요구사항**
- **Git**: 분산 버전 관리 시스템
- **GitHub**: 클라우드 기반 협업 플랫폼
- **목표**: 코드, 데이터, 모델의 체계적 버전 관리

### ✅ **my-mlops에서 구현된 부분**

#### **현재 Git 사용 현황**
- ✅ **Git 저장소**: `.git` 폴더 존재
- ✅ **커밋 히스토리**: 개발 과정 추적 가능
- ✅ **파일 관리**: `.gitignore`, `.gitattributes` 설정
- ✅ **브랜치**: main 브랜치 사용

#### **Git 구조 분석**
```
my-mlops/.git/
├── objects/          # Git 객체 저장소 (커밋, 파일 등)
├── refs/            # 브랜치 및 태그 참조
├── logs/            # 커밋 로그 히스토리
├── hooks/           # Git 훅 스크립트
└── config          # Git 설정 파일
```

### 🔄 **통합 계획**

#### **3-1. Git 워크플로우 설계**
```
mlops-cloud-project-mlops_11/
├── .git/                                # Git 저장소
├── .gitignore                           # 제외 파일 설정
├── .gitattributes                       # Git 속성 설정
├── docs/
│   ├── workflows/
│   │   └── git-workflow.md              # Git 사용 가이드
│   └── development/
│       └── code-review-guidelines.md    # 코드 리뷰 가이드
├── scripts/
│   ├── setup-git.sh                    # Git 초기 설정
│   └── hooks/
│       ├── pre-commit                   # 커밋 전 훅
│       └── pre-push                     # 푸시 전 훅
├── .github/
│   ├── workflows/
│   │   ├── ci.yml                       # CI 파이프라인
│   │   └── cd.yml                       # CD 파이프라인
│   └── PULL_REQUEST_TEMPLATE.md         # PR 템플릿
└── tests/
    ├── unit/                            # 단위 테스트
    └── integration/                     # 통합 테스트
```

#### **3-2. 버전 관리 전략**
- **브랜치 전략**: GitFlow 또는 GitHub Flow 적용
- **커밋 컨벤션**: Conventional Commits 형식
- **태그 관리**: 버전별 릴리스 태그
- **데이터 버전 관리**: DVC(Data Version Control) 고려

#### **3-3. 확장 구현 사항**
```python
# scripts/data_versioning.py
class DataVersionManager:
    def __init__(self, base_path):
        self.base_path = base_path
        
    def create_data_snapshot(self, version_tag):
        # 데이터 스냅샷 생성
        
    def restore_data_version(self, version_tag):
        # 특정 버전으로 데이터 복원
```

---

## 🎯 **7단계: 고도화된 ML 프레임워크와 모델 서빙**

### 📋 **이론적 프레임워크 요구사항**
- **PyTorch/TensorFlow**: ML 프레임워크
- **KServe/BentoML**: 모델 서빙 플랫폼
- **목표**: 다양한 ML 프레임워크와 모델 서빙 플랫폼 통합

### ✅ **my-mlops 및 my-mlops-web에서 구현된 부분**

#### **백엔드 (my-mlops): 모델 추론 시스템**
```python
# 추정되는 FastAPI 구조 (AWS EC2에 배포됨)
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class PredictionRequest(BaseModel):
    user_id: int
    # ... 기타 필드

@app.post("/batch-predict")
async def predict(request: PredictionRequest):
    # numpy 기반 MoviePredictor 모델 추론
    # 영화 추천 결과 반환
```

#### **프론트엔드 (my-mlops-web): React 애플리케이션**
```javascript
// src/api.js
const API_ENDPOINT = process.env.REACT_APP_API_ENDPOINT;
// http://ec2-3-37-127-189.ap-northeast-2.compute.amazonaws.com:8000/batch-predict

export async function getRecommendContents(k) {
  const response = await axios.get(`${API_ENDPOINT}`, {
    params: { k: k }
  });
  return response.data.recommended_content_id;
}

// src/App.jsx
function App() {
  const [contentIds, setContentIds] = useState([]);
  
  useEffect(() => {
    (async () => {
      const ids = await getRecommendContents(10);
      setContentIds(ids.length > 0 ? ids : getRandomContentsIds(10));
    })();
  }, []);
  
  return (
    <div className="App">
      <h2>000 님이 좋아할 만한 콘텐츠</h2>
      <CardGrid contentIds={contentIds} />      
    </div>
  );
}
```

#### **핵심 구현 요소**
- ✅ **모델 추론**: numpy 기반 MoviePredictor
- ✅ **API 서버**: FastAPI 기반 RESTful API
- ✅ **웹 인터페이스**: React 19.1.0 기반 SPA
- ✅ **클라우드 배포**: AWS EC2에 실제 배포
- ✅ **영화 포스터**: 58개 영화 이미지 자산
- ✅ **반응형 UI**: CSS Grid 기반 카드 레이아웃

### 🔄 **통합 계획**

#### **7-1. 백엔드 구조**
```
mlops-cloud-project-mlops_11/
├── src/
│   ├── api/
│   │   ├── main.py                      # FastAPI 애플리케이션
│   │   ├── routers/
│   │   │   ├── predictions.py           # 예측 엔드포인트
│   │   │   ├── health.py                # 헬스체크
│   │   │   └── models.py                # 모델 관리 API
│   │   ├── schemas/
│   │   │   ├── prediction.py            # Pydantic 모델
│   │   │   └── response.py              # 응답 스키마
│   │   └── middleware/
│   │       ├── logging.py               # 로깅 설정
│   │       └── monitoring.py            # 모니터링
│   ├── models/
│   │   ├── serving/
│   │   │   ├── movie_predictor.py       # numpy 기반 모델
│   │   │   └── model_loader.py          # 모델 로딩 유틸
│   │   └── registry/
│   │       └── model_registry.py        # 모델 버전 관리
│   └── core/
│       ├── config.py                    # 설정 관리
│       └── security.py                  # 보안 설정
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── CardGrid.jsx             # 영화 포스터 그리드
│   │   │   └── MovieCard.jsx            # 개별 영화 카드
│   │   ├── services/
│   │   │   └── api.js                   # API 통신
│   │   ├── utils/
│   │   │   └── fallback.js              # 랜덤 추천 fallback
│   │   └── App.jsx                      # 메인 애플리케이션
│   ├── public/
│   │   └── poster/                      # 58개 영화 포스터
│   └── Dockerfile                       # 프론트엔드 Docker
├── docker/
│   ├── Dockerfile.api                   # API 서버용
│   └── docker-compose.yml               # 개발 환경
├── k8s/
│   ├── backend-deployment.yaml          # 백엔드 배포
│   ├── frontend-deployment.yaml         # 프론트엔드 배포
│   └── service.yaml                     # 서비스 설정
├── deployment/
│   ├── aws/
│   │   ├── ec2-setup.sh                 # EC2 배포 스크립트
│   │   └── nginx.conf                   # Nginx 설정
│   └── monitoring/
│       ├── prometheus.yml               # 메트릭 수집
│       └── grafana-dashboard.json       # 대시보드
└── requirements.txt                     # Python 의존성
```

#### **7-2. 확장 구현 사항**

##### **모델 서빙 개선**
```python
# src/models/model_registry.py
class SimpleModelRegistry:
    def __init__(self, base_path):
        self.base_path = base_path
        
    def register_model(self, model, version, metadata):
        # 모델 등록 및 버전 관리
        
    def load_model(self, model_name, version="latest"):
        # 특정 버전 모델 로드
        
    def get_model_metadata(self, model_name, version):
        # 모델 메타데이터 조회
```

##### **A/B 테스트 지원**
```python
# src/api/ab_testing.py
class ABTestManager:
    def route_request(self, user_id, models):
        # 사용자 ID 기반 모델 라우팅
        
    def log_prediction(self, model_version, request, response):
        # 예측 결과 로깅
```

##### **모니터링 기능**
```python
# src/core/metrics.py
from prometheus_client import Counter, Histogram

prediction_counter = Counter('ml_predictions_total', 'Total predictions')
prediction_latency = Histogram('ml_prediction_duration_seconds', 'Prediction latency')

def track_prediction(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        prediction_counter.inc()
        prediction_latency.observe(time.time() - start_time)
        return result
    return wrapper
```

---

## 📋 **단계별 우선순위 및 구현 순서**

### **Phase 1: 핵심 구현**
1. **1단계**: 데이터 처리 파이프라인 이식
2. **2단계**: 피처 생성 로직 모듈화
3. **3단계**: Git 워크플로우 설정

### **Phase 2: 서빙 시스템**
4. **7단계**: FastAPI + React 통합 및 개선

### **Phase 3: 통합 및 문서화**
5. 전체 시스템 통합 테스트
6. 상세 문서 작성 및 README 업데이트

## 🎯 **기대 효과**

### **완성된 MLOps 학습 프로젝트**
- 📊 **실제 데이터 파이프라인**: TMDB API → 피처 생성 → 모델 서빙
- 🤖 **완전한 추천 시스템**: 영화 데이터 기반 실제 작동하는 서비스
- 🌐 **실무급 아키텍처**: API 서버 + 웹 프론트엔드 + 클라우드 배포
- 📚 **점진적 확장**: 기본 구현 → 엔터프라이즈급 MLOps 도구 도입