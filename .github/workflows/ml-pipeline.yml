name: ü§ñ ML Pipeline - Model Training & Deployment

on:
  schedule:
    # Îß§Ïùº UTC 2Ïãú (ÌïúÍµ≠ÏãúÍ∞Ñ 11Ïãú)Ïóê Ïã§Ìñâ
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model type to train'
        required: true
        default: 'collaborative_filtering'
        type: choice
        options:
        - collaborative_filtering
        - content_based
        - hybrid
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: 'movie-recommendation'
      force_retrain:
        description: 'Force retrain even if model exists'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://localhost:5000"
  
jobs:
  # ==============================================================================
  # 1. Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è Ï†ÑÏ≤òÎ¶¨
  # ==============================================================================
  data-pipeline:
    name: üìä Data Collection & Processing
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres123
          POSTGRES_DB: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    outputs:
      data-version: ${{ steps.data-check.outputs.version }}
      data-changed: ${{ steps.data-check.outputs.changed }}
      
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üêç Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/airflow.txt
        pip install -r requirements/postgres.txt
        pip install -r requirements/redis.txt
        
    - name: üîß Setup environment
      run: |
        cp .env.template .env
        echo "POSTGRES_HOST=localhost" >> .env
        echo "REDIS_HOST=localhost" >> .env
        echo "TMDB_API_KEY=${{ secrets.TMDB_API_KEY }}" >> .env
        
    - name: üìä Check data freshness
      id: data-check
      run: |
        # ÌòÑÏû¨ ÎÇ†ÏßúÎ°ú Îç∞Ïù¥ÌÑ∞ Î≤ÑÏ†Ñ ÏÉùÏÑ±
        DATA_VERSION=$(date +%Y%m%d)
        echo "version=$DATA_VERSION" >> $GITHUB_OUTPUT
        
        # Îç∞Ïù¥ÌÑ∞ Î≥ÄÍ≤Ω Ïó¨Î∂Ä ÌôïÏù∏ (ÏûÑÏãúÎ°ú Ìï≠ÏÉÅ true)
        echo "changed=true" >> $GITHUB_OUTPUT
        
        echo "üìä Data version: $DATA_VERSION" >> $GITHUB_STEP_SUMMARY
        
    - name: üé¨ Collect movie data
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      run: |
        # TODO: TMDB API Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
        echo "üé¨ Starting movie data collection..."
        
        # ÏûÑÏãúÎ°ú ÎçîÎØ∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
        mkdir -p data/raw/tmdb
        echo '{"movies": [], "version": "${{ steps.data-check.outputs.version }}"}' > data/raw/tmdb/movies.json
        
        echo "‚úÖ Movie data collection completed" >> $GITHUB_STEP_SUMMARY
        
    - name: üîÑ Process and validate data
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      run: |
        # TODO: Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ Î∞è Í≤ÄÏ¶ù Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
        echo "üîÑ Processing collected data..."
        
        # ÏûÑÏãúÎ°ú Ï≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
        mkdir -p data/processed
        echo '{"processed_movies": [], "features": [], "version": "${{ steps.data-check.outputs.version }}"}' > data/processed/movies_processed.json
        
        echo "‚úÖ Data processing completed" >> $GITHUB_STEP_SUMMARY
        
    - name: üì§ Upload processed data
      uses: actions/upload-artifact@v3
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      with:
        name: processed-data-${{ steps.data-check.outputs.version }}
        path: |
          data/processed/
          data/raw/tmdb/
        retention-days: 30

  # ==============================================================================
  # 2. Î™®Îç∏ ÌõàÎ†®
  # ==============================================================================
  model-training:
    name: ü§ñ Model Training
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: needs.data-pipeline.outputs.data-changed == 'true' || github.event.inputs.force_retrain == 'true'
    
    strategy:
      matrix:
        model_type: [collaborative_filtering, content_based]
        
    services:
      mlflow:
        image: python:3.11-slim
        env:
          MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow.db
        ports:
          - 5000:5000
        options: >-
          --health-cmd "pip install mlflow && mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlartifacts"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
    
    outputs:
      model-version: ${{ steps.model-train.outputs.version }}
      model-uri: ${{ steps.model-train.outputs.uri }}
      model-metrics: ${{ steps.model-train.outputs.metrics }}
      
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üì• Download processed data
      uses: actions/download-artifact@v3
      with:
        name: processed-data-${{ needs.data-pipeline.outputs.data-version }}
        path: ./data/
        
    - name: üêç Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: üì¶ Install ML dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/pytorch.txt
        pip install -r requirements/mlflow.txt
        
    - name: üîß Setup MLflow environment
      run: |
        export MLFLOW_TRACKING_URI=http://localhost:5000
        echo "MLFLOW_TRACKING_URI=http://localhost:5000" >> $GITHUB_ENV
        
        # MLflow ÏÑúÎ≤Ñ ÎåÄÍ∏∞
        sleep 30
        
    - name: ü§ñ Train model
      id: model-train
      run: |
        # TODO: Ïã§Ï†ú Î™®Îç∏ ÌõàÎ†® Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
        echo "ü§ñ Training ${{ matrix.model_type }} model..."
        
        # ÏûÑÏãúÎ°ú ÎçîÎØ∏ Î™®Îç∏ ÏÉùÏÑ±
        MODEL_VERSION="v$(date +%Y%m%d_%H%M%S)"
        MODEL_URI="models:/${{ matrix.model_type }}/$MODEL_VERSION"
        
        echo "version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        echo "uri=$MODEL_URI" >> $GITHUB_OUTPUT
        echo "metrics={\"rmse\": 0.85, \"mae\": 0.72}" >> $GITHUB_OUTPUT
        
        echo "‚úÖ Model training completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Model**: ${{ matrix.model_type }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Version**: $MODEL_VERSION" >> $GITHUB_STEP_SUMMARY
        echo "- **URI**: $MODEL_URI" >> $GITHUB_STEP_SUMMARY
        
    - name: üìä Model evaluation
      run: |
        # TODO: Î™®Îç∏ ÌèâÍ∞Ä Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
        echo "üìä Evaluating model performance..."
        
        # ÏûÑÏãú ÌèâÍ∞Ä Í≤∞Í≥º
        echo "‚úÖ Model evaluation completed" >> $GITHUB_STEP_SUMMARY
        echo "- **RMSE**: 0.85" >> $GITHUB_STEP_SUMMARY
        echo "- **MAE**: 0.72" >> $GITHUB_STEP_SUMMARY
        
    - name: üì§ Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: model-${{ matrix.model_type }}-${{ steps.model-train.outputs.version }}
        path: |
          models/
          mlartifacts/
        retention-days: 90

  # ==============================================================================
  # 3. Î™®Îç∏ Í≤ÄÏ¶ù Î∞è ÏäπÍ∏â
  # ==============================================================================
  model-validation:
    name: ‚úÖ Model Validation
    runs-on: ubuntu-latest
    needs: model-training
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üì• Download model artifacts
      uses: actions/download-artifact@v3
      with:
        pattern: model-*
        merge-multiple: true
        
    - name: üêç Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/pytorch.txt
        pip install -r requirements/mlflow.txt
        
    - name: ‚úÖ Validate models
      run: |
        # TODO: Î™®Îç∏ Í≤ÄÏ¶ù Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
        echo "‚úÖ Validating trained models..."
        
        # ÏûÑÏãú Í≤ÄÏ¶ù Í≤∞Í≥º
        echo "‚úÖ Model validation completed" >> $GITHUB_STEP_SUMMARY
        echo "- **All models passed validation**" >> $GITHUB_STEP_SUMMARY
        
    - name: üèÜ Promote best model
      run: |
        # TODO: ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ÏùÑ ÌîÑÎ°úÎçïÏÖòÏúºÎ°ú ÏäπÍ∏â
        echo "üèÜ Promoting best performing model..."
        
        echo "‚úÖ Model promotion completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Production model**: collaborative_filtering" >> $GITHUB_STEP_SUMMARY

  # ==============================================================================
  # 4. Î™®Îç∏ Î∞∞Ìè¨
  # ==============================================================================
  model-deployment:
    name: üöÄ Model Deployment
    runs-on: ubuntu-latest
    needs: [model-training, model-validation]
    
    environment: production
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üì• Download model artifacts
      uses: actions/download-artifact@v3
      with:
        pattern: model-*
        merge-multiple: true
        
    - name: üöÄ Deploy to model serving
      run: |
        # TODO: Î™®Îç∏ ÏÑúÎπô ÏãúÏä§ÌÖúÏóê Î∞∞Ìè¨
        echo "üöÄ Deploying model to serving system..."
        
        # ÏûÑÏãúÎ°ú Î∞∞Ìè¨ ÏÑ±Í≥µ ÏãúÎÆ¨Î†àÏù¥ÏÖò
        echo "‚úÖ Model deployment completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Endpoint**: https://api.movie-mlops.com/predict" >> $GITHUB_STEP_SUMMARY
        
    - name: üß™ Smoke test
      run: |
        # TODO: Î∞∞Ìè¨Îêú Î™®Îç∏ smoke test
        echo "üß™ Running smoke tests..."
        
        # ÏûÑÏãúÎ°ú ÌÖåÏä§Ìä∏ ÏÑ±Í≥µ
        echo "‚úÖ Smoke tests passed" >> $GITHUB_STEP_SUMMARY

  # ==============================================================================
  # 5. ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ ÏÑ§Ï†ï
  # ==============================================================================
  setup-monitoring:
    name: üìä Setup Model Monitoring
    runs-on: ubuntu-latest
    needs: model-deployment
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üìä Configure monitoring
      run: |
        # TODO: Î™®Îç∏ ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ ÏÑ§Ï†ï
        echo "üìä Setting up model performance monitoring..."
        
        echo "‚úÖ Monitoring setup completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Grafana Dashboard**: http://localhost:3000/d/model-performance" >> $GITHUB_STEP_SUMMARY
        
  # ==============================================================================
  # 6. ÏïåÎ¶º Î∞è Î≥¥Í≥†ÏÑú
  # ==============================================================================
  ml-report:
    name: üìã ML Pipeline Report
    runs-on: ubuntu-latest
    needs: [data-pipeline, model-training, model-validation, model-deployment, setup-monitoring]
    if: always()
    
    steps:
    - name: üìã Generate ML pipeline report
      run: |
        echo "## ü§ñ ML Pipeline Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìä Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.data-pipeline.result }}" == "success" ]; then
          echo "‚úÖ **Data Pipeline**: Success" >> $GITHUB_STEP_SUMMARY
          echo "  - Data Version: ${{ needs.data-pipeline.outputs.data-version }}" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Data Pipeline**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-training.result }}" == "success" ]; then
          echo "‚úÖ **Model Training**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Model Training**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-validation.result }}" == "success" ]; then
          echo "‚úÖ **Model Validation**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Model Validation**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-deployment.result }}" == "success" ]; then
          echo "‚úÖ **Model Deployment**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Model Deployment**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.setup-monitoring.result }}" == "success" ]; then
          echo "‚úÖ **Monitoring Setup**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Monitoring Setup**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìà Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- Monitor model performance in Grafana dashboard" >> $GITHUB_STEP_SUMMARY
        echo "- Check model endpoints for availability" >> $GITHUB_STEP_SUMMARY
        echo "- Review training metrics in MLflow" >> $GITHUB_STEP_SUMMARY
