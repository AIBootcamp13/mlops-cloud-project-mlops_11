name: ðŸ¤– ML Pipeline - Model Training & Deployment

on:
  schedule:
    # ë§¤ì¼ UTC 2ì‹œ (í•œêµ­ì‹œê°„ 11ì‹œ)ì— ì‹¤í–‰
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model type to train'
        required: true
        default: 'collaborative_filtering'
        type: choice
        options:
        - collaborative_filtering
        - content_based
        - hybrid
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: 'movie-recommendation'
      force_retrain:
        description: 'Force retrain even if model exists'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://localhost:5000"
  
jobs:
  # ==============================================================================
  # 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
  # ==============================================================================
  data-pipeline:
    name: ðŸ“Š Data Collection & Processing
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres123
          POSTGRES_DB: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    outputs:
      data-version: ${{ steps.data-check.outputs.version }}
      data-changed: ${{ steps.data-check.outputs.changed }}
      
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/airflow.txt
        pip install -r requirements/postgres.txt
        pip install -r requirements/redis.txt
        
    - name: ðŸ”§ Setup environment
      run: |
        cp .env.template .env
        echo "POSTGRES_HOST=localhost" >> .env
        echo "REDIS_HOST=localhost" >> .env
        echo "TMDB_API_KEY=${{ secrets.TMDB_API_KEY }}" >> .env
        
    - name: ðŸ“Š Check data freshness
      id: data-check
      run: |
        # í˜„ìž¬ ë‚ ì§œë¡œ ë°ì´í„° ë²„ì „ ìƒì„±
        DATA_VERSION=$(date +%Y%m%d)
        echo "version=$DATA_VERSION" >> $GITHUB_OUTPUT
        
        # ë°ì´í„° ë³€ê²½ ì—¬ë¶€ í™•ì¸ (ìž„ì‹œë¡œ í•­ìƒ true)
        echo "changed=true" >> $GITHUB_OUTPUT
        
        echo "ðŸ“Š Data version: $DATA_VERSION" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸŽ¬ Collect movie data
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      run: |
        # TODO: TMDB API ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        echo "ðŸŽ¬ Starting movie data collection..."
        
        # ìž„ì‹œë¡œ ë”ë¯¸ ë°ì´í„° ìƒì„±
        mkdir -p data/raw/tmdb
        echo '{"movies": [], "version": "${{ steps.data-check.outputs.version }}"}' > data/raw/tmdb/movies.json
        
        echo "âœ… Movie data collection completed" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ”„ Process and validate data
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      run: |
        # TODO: ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        echo "ðŸ”„ Processing collected data..."
        
        # ìž„ì‹œë¡œ ì²˜ë¦¬ëœ ë°ì´í„° ìƒì„±
        mkdir -p data/processed
        echo '{"processed_movies": [], "features": [], "version": "${{ steps.data-check.outputs.version }}"}' > data/processed/movies_processed.json
        
        echo "âœ… Data processing completed" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ“¤ Upload processed data
      uses: actions/upload-artifact@v3
      if: steps.data-check.outputs.changed == 'true' || github.event.inputs.force_retrain == 'true'
      with:
        name: processed-data-${{ steps.data-check.outputs.version }}
        path: |
          data/processed/
          data/raw/tmdb/
        retention-days: 30

  # ==============================================================================
  # 2. ëª¨ë¸ í›ˆë ¨
  # ==============================================================================
  model-training:
    name: ðŸ¤– Model Training
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: needs.data-pipeline.outputs.data-changed == 'true' || github.event.inputs.force_retrain == 'true'
    
    strategy:
      matrix:
        model_type: [collaborative_filtering, content_based]
        
    services:
      mlflow:
        image: python:3.11-slim
        env:
          MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow.db
        ports:
          - 5000:5000
        options: >-
          --health-cmd "pip install mlflow && mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlartifacts"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
    
    outputs:
      model-version: ${{ steps.model-train.outputs.version }}
      model-uri: ${{ steps.model-train.outputs.uri }}
      model-metrics: ${{ steps.model-train.outputs.metrics }}
      
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ“¥ Download processed data
      uses: actions/download-artifact@v3
      with:
        name: processed-data-${{ needs.data-pipeline.outputs.data-version }}
        path: ./data/
        
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: ðŸ“¦ Install ML dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/pytorch.txt
        pip install -r requirements/mlflow.txt
        
    - name: ðŸ”§ Setup MLflow environment
      run: |
        export MLFLOW_TRACKING_URI=http://localhost:5000
        echo "MLFLOW_TRACKING_URI=http://localhost:5000" >> $GITHUB_ENV
        
        # MLflow ì„œë²„ ëŒ€ê¸°
        sleep 30
        
    - name: ðŸ¤– Train model
      id: model-train
      run: |
        # TODO: ì‹¤ì œ ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        echo "ðŸ¤– Training ${{ matrix.model_type }} model..."
        
        # ìž„ì‹œë¡œ ë”ë¯¸ ëª¨ë¸ ìƒì„±
        MODEL_VERSION="v$(date +%Y%m%d_%H%M%S)"
        MODEL_URI="models:/${{ matrix.model_type }}/$MODEL_VERSION"
        
        echo "version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        echo "uri=$MODEL_URI" >> $GITHUB_OUTPUT
        echo "metrics={\"rmse\": 0.85, \"mae\": 0.72}" >> $GITHUB_OUTPUT
        
        echo "âœ… Model training completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Model**: ${{ matrix.model_type }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Version**: $MODEL_VERSION" >> $GITHUB_STEP_SUMMARY
        echo "- **URI**: $MODEL_URI" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ“Š Model evaluation
      run: |
        # TODO: ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        echo "ðŸ“Š Evaluating model performance..."
        
        # ìž„ì‹œ í‰ê°€ ê²°ê³¼
        echo "âœ… Model evaluation completed" >> $GITHUB_STEP_SUMMARY
        echo "- **RMSE**: 0.85" >> $GITHUB_STEP_SUMMARY
        echo "- **MAE**: 0.72" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ“¤ Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: model-${{ matrix.model_type }}-${{ steps.model-train.outputs.version }}
        path: |
          models/
          mlartifacts/
        retention-days: 90

  # ==============================================================================
  # 3. ëª¨ë¸ ê²€ì¦ ë° ìŠ¹ê¸‰
  # ==============================================================================
  model-validation:
    name: âœ… Model Validation
    runs-on: ubuntu-latest
    needs: model-training
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ“¥ Download model artifacts
      uses: actions/download-artifact@v3
      with:
        pattern: model-*
        merge-multiple: true
        
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements/base.txt
        pip install -r requirements/pytorch.txt
        pip install -r requirements/mlflow.txt
        
    - name: âœ… Validate models
      run: |
        # TODO: ëª¨ë¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        echo "âœ… Validating trained models..."
        
        # ìž„ì‹œ ê²€ì¦ ê²°ê³¼
        echo "âœ… Model validation completed" >> $GITHUB_STEP_SUMMARY
        echo "- **All models passed validation**" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ† Promote best model
      run: |
        # TODO: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ìœ¼ë¡œ ìŠ¹ê¸‰
        echo "ðŸ† Promoting best performing model..."
        
        echo "âœ… Model promotion completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Production model**: collaborative_filtering" >> $GITHUB_STEP_SUMMARY

  # ==============================================================================
  # 4. ëª¨ë¸ ë°°í¬
  # ==============================================================================
  model-deployment:
    name: ðŸš€ Model Deployment
    runs-on: ubuntu-latest
    needs: [model-training, model-validation]
    
    environment: production
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ“¥ Download model artifacts
      uses: actions/download-artifact@v3
      with:
        pattern: model-*
        merge-multiple: true
        
    - name: ðŸš€ Deploy to model serving
      run: |
        # TODO: ëª¨ë¸ ì„œë¹™ ì‹œìŠ¤í…œì— ë°°í¬
        echo "ðŸš€ Deploying model to serving system..."
        
        # ìž„ì‹œë¡œ ë°°í¬ ì„±ê³µ ì‹œë®¬ë ˆì´ì…˜
        echo "âœ… Model deployment completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Endpoint**: https://api.movie-mlops.com/predict" >> $GITHUB_STEP_SUMMARY
        
    - name: ðŸ§ª Smoke test
      run: |
        # TODO: ë°°í¬ëœ ëª¨ë¸ smoke test
        echo "ðŸ§ª Running smoke tests..."
        
        # ìž„ì‹œë¡œ í…ŒìŠ¤íŠ¸ ì„±ê³µ
        echo "âœ… Smoke tests passed" >> $GITHUB_STEP_SUMMARY

  # ==============================================================================
  # 5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
  # ==============================================================================
  setup-monitoring:
    name: ðŸ“Š Setup Model Monitoring
    runs-on: ubuntu-latest
    needs: model-deployment
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ“Š Configure monitoring
      run: |
        # TODO: ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        echo "ðŸ“Š Setting up model performance monitoring..."
        
        echo "âœ… Monitoring setup completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Grafana Dashboard**: http://localhost:3000/d/model-performance" >> $GITHUB_STEP_SUMMARY
        
  # ==============================================================================
  # 6. ì•Œë¦¼ ë° ë³´ê³ ì„œ
  # ==============================================================================
  ml-report:
    name: ðŸ“‹ ML Pipeline Report
    runs-on: ubuntu-latest
    needs: [data-pipeline, model-training, model-validation, model-deployment, setup-monitoring]
    if: always()
    
    steps:
    - name: ðŸ“‹ Generate ML pipeline report
      run: |
        echo "## ðŸ¤– ML Pipeline Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.data-pipeline.result }}" == "success" ]; then
          echo "âœ… **Data Pipeline**: Success" >> $GITHUB_STEP_SUMMARY
          echo "  - Data Version: ${{ needs.data-pipeline.outputs.data-version }}" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Data Pipeline**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-training.result }}" == "success" ]; then
          echo "âœ… **Model Training**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Model Training**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-validation.result }}" == "success" ]; then
          echo "âœ… **Model Validation**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Model Validation**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.model-deployment.result }}" == "success" ]; then
          echo "âœ… **Model Deployment**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Model Deployment**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.setup-monitoring.result }}" == "success" ]; then
          echo "âœ… **Monitoring Setup**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Monitoring Setup**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“ˆ Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- Monitor model performance in Grafana dashboard" >> $GITHUB_STEP_SUMMARY
        echo "- Check model endpoints for availability" >> $GITHUB_STEP_SUMMARY
        echo "- Review training metrics in MLflow" >> $GITHUB_STEP_SUMMARY
